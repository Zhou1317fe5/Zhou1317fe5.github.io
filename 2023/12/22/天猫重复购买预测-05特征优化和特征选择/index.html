<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="天猫重复购买预测-05特征优化和特征选择代码详解"><meta property="og:type" content="article"><meta property="og:title" content="天猫重复购买预测-05特征优化和特征选择"><meta property="og:url" content="https://zhou1317fe5.github.io/2023/12/22/%E5%A4%A9%E7%8C%AB%E9%87%8D%E5%A4%8D%E8%B4%AD%E4%B9%B0%E9%A2%84%E6%B5%8B-05%E7%89%B9%E5%BE%81%E4%BC%98%E5%8C%96%E5%92%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="天猫重复购买预测-05特征优化和特征选择代码详解"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-12-22T11:30:01.000Z"><meta property="article:modified_time" content="2024-02-16T11:53:46.000Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>天猫重复购买预测-05特征优化和特征选择 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="天猫重复购买预测-05特征优化和特征选择"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-12-22 19:30" pubdate>2023年12月22日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 11k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 89 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">天猫重复购买预测-05特征优化和特征选择</h1><div class="markdown-body"><h1 id="基础代码">1 基础代码</h1><h2 id="导入相关库">1.1 导入相关库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>) <br></code></pre></td></tr></table></figure><h2 id="读取数据">1.2 读取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练数据前 10000行，测试数据前100条</span><br>train_data = pd.read_csv(<span class="hljs-string">&#x27;./data/train_all.csv&#x27;</span>,nrows=<span class="hljs-number">10000</span>)<br>test_data = pd.read_csv(<span class="hljs-string">&#x27;./data/test_all.csv&#x27;</span>,nrows=<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 读取全部数据</span><br><span class="hljs-comment"># train_data = pd.read_csv(&#x27;train_all.csv&#x27;,nrows=None)</span><br><span class="hljs-comment"># test_data = pd.read_csv(&#x27;test_all.csv&#x27;,nrows=None)</span><br></code></pre></td></tr></table></figure><h2 id="获取训练和测试数据">1.3 获取训练和测试数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">features_columns = [col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> train_data.columns <span class="hljs-keyword">if</span> col <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;user_id&#x27;</span>,<span class="hljs-string">&#x27;label&#x27;</span>]]<br>train = train_data[features_columns].values<br>test = test_data[features_columns].values<br>target =train_data[<span class="hljs-string">&#x27;label&#x27;</span>].values<br></code></pre></td></tr></table></figure><h1 id="缺失值补全">2 缺失值补全</h1><p>处理缺失值有很多方法，最常用为以下几种：</p><ol type="1"><li>删除。当数据量较大时，或者缺失数据占比较小时，可以使用这种方法。</li><li>填充。通用的方法是采用平均数、中位数来填充，可以适用插值或者模型预测的方法进行缺失补全。</li><li>不处理。树类模型对缺失值不明感。</li></ol><h4 id="采用中值进行填充">采用中值进行填充</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># from sklearn.preprocessing import Imputer</span><br><span class="hljs-comment"># imputer = Imputer(strategy=&quot;median&quot;)</span><br><br><span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer<br><br>imputer = SimpleImputer(missing_values=np.nan, strategy=<span class="hljs-string">&#x27;mean&#x27;</span>)<br>imputer = imputer.fit(train)<br>train_imputer = imputer.transform(train)<br>test_imputer = imputer.transform(test)<br></code></pre></td></tr></table></figure><h1 id="特征选择">3 特征选择</h1><p>下面将采用前面提到的方法来进行特征选择，然后通过以下代码对比特征选择前后模型的性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">feature_selection</span>(<span class="hljs-params">train, train_sel, target</span>):<br>    clf = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>, max_depth=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">0</span>, n_jobs=-<span class="hljs-number">1</span>)<br>    <br>    scores = cross_val_score(clf, train, target, cv=<span class="hljs-number">5</span>)<br>    scores_sel = cross_val_score(clf, train_sel, target, cv=<span class="hljs-number">5</span>)<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;No Select Accuracy: %0.2f (+/- %0.2f)&quot;</span> % (scores.mean(), scores.std() * <span class="hljs-number">2</span>))     <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Features Select Accuracy: %0.2f (+/- %0.2f)&quot;</span> % (scores.mean(), scores.std() * <span class="hljs-number">2</span>))<br></code></pre></td></tr></table></figure><h2 id="删除方差较小的要素">3.1删除方差较小的要素</h2><p>VarianceThreshold是一种简单的基线特征选择方法。它会删除方差不符合某个阈值的所有要素。默认情况下，它会删除所有零方差要素，即在所有样本中具有相同值的要素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold<br><br>sel = VarianceThreshold(threshold=(<span class="hljs-number">.8</span> * (<span class="hljs-number">1</span> - <span class="hljs-number">.8</span>)))<br>sel = sel.fit(train)<br>train_sel = sel.transform(train)<br>test_sel = sel.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 24)</code></pre><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre><h2 id="单变量特征选择">3.2单变量特征选择</h2><p>通过基于单变量统计检验选择最佳特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> mutual_info_classif<br><br>sel = SelectKBest(mutual_info_classif, k=<span class="hljs-number">2</span>)<br>sel = sel.fit(train, target)<br>train_sel = sel.transform(train)<br>test_sel = sel.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">sel = SelectKBest(mutual_info_classif, k=<span class="hljs-number">10</span>)<br>sel = sel.fit(train, target)<br>train_sel = sel.transform(train)<br>test_sel = sel.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 10)</code></pre><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre><h2 id="递归功能消除">3.3递归功能消除</h2><p>通过递归地训练多个模型来选择特征。首先，它使用整个特征集合训练一个模型，并按照得分最低的特征的顺序依次消除特征，直到达到预定的特征数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFECV<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><br>clf = RandomForestClassifier(n_estimators=<span class="hljs-number">10</span>, max_depth=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">0</span>, n_jobs=-<span class="hljs-number">1</span>)<br>selector = RFECV(clf, step=<span class="hljs-number">1</span>, cv=<span class="hljs-number">2</span>)<br>selector = selector.fit(train, target)<br><span class="hljs-built_in">print</span>(selector.support_)<br><span class="hljs-built_in">print</span>(selector.ranking_)<br></code></pre></td></tr></table></figure><pre><code class="hljs">[False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False  True
  True]
[228 227 226 224 222 219 218 216 215 214 213 212 211 210 206 205 204 203
 201 199 195 192 186 178 174 171 169 168 167 165 164 163 162 160 159 158
 157 156 154 153 152 151 149 148 147 145 144 143 142 140 138 137 136 135
 134 133 132 131 130 129 126 125 124 122 118 117 116 115 114 113 112 111
 109 107 106 105 104 103 102  95  93  91  90  79  78  75  73  72  70  69
  68  62  59  58  57  53  34  30  27   3   8  19   5  15   4  11  13  10
  16  21   2 175 179 187 181 225 223 221 220 217 183 189 207 209 208 193
 197 202 200 198 196 194 191 190 188 185 184 182 180 177 176 173 172 170
  25 166  31 161  35  37 155  39  41 150  43 146  45 141 139  47  49  51
  63 127 128 119 123 121 120  81  83  85  87 110 108  97  99 101 100  98
  96  94  92  89  88  86  84  82  80  77  76  74  71  65  67  66  64  61
  60  55  56  54  52  50  48  46  44  42  40  38  36  33  32  29  28  26
  24  14  12   9   7   6  20  22  17  18  23   1   1]</code></pre><h2 id="使用模型选择特征">3.4使用模型选择特征</h2><p>使用LR拟合的参数进行变量选择（L2范数进行特征选择），LR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> Normalizer<br><br>normalizer = Normalizer()<br>normalizer = normalizer.fit(train)  <br><br>train_norm = normalizer.transform(train)                            <br>test_norm = normalizer.transform(test)<br><br>LR = LogisticRegression(penalty=<span class="hljs-string">&#x27;l2&#x27;</span>,C=<span class="hljs-number">5</span>)<br>LR = LR.fit(train_norm, target)<br>model = SelectFromModel(LR, prefit=<span class="hljs-literal">True</span>)<br>train_sel = model.transform(train)<br>test_sel = model.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 19)</code></pre><p>L2范数选择参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">LR.coef_[<span class="hljs-number">0</span>][:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([ 0.23210864,  0.03214927, -0.00939419,  0.85088717, -0.91507123,
       -0.26081965, -0.86681364,  0.57445561,  0.73849952,  0.00342517])</code></pre><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre><p>使用LR拟合的参数进行变量选择（L1范数进行特征选择），LR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> Normalizer<br><br>normalizer = Normalizer()<br>normalizer = normalizer.fit(train)  <br><br>train_norm = normalizer.transform(train)                            <br>test_norm = normalizer.transform(test)<br><br>LR = LogisticRegression(penalty=<span class="hljs-string">&#x27;l1&#x27;</span>,C=<span class="hljs-number">5</span>,solver=<span class="hljs-string">&#x27;liblinear&#x27;</span>)<br>LR = LR.fit(train_norm, target)<br>model = SelectFromModel(LR, prefit=<span class="hljs-literal">True</span>)<br>train_sel = model.transform(train)<br>test_sel = model.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 12)</code></pre><p>L1范数选择参数。对于α的良好选择，只要满足某些特定条件，LASSO就可以仅使用少量观察来完全恢复精确的非零变量集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">LR.coef_[<span class="hljs-number">0</span>][:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([0.16879959, 0.        , 0.        , 0.56714802, 0.        ,
       0.        , 0.        , 0.78078353, 0.        , 0.        ])</code></pre><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre><h2 id="基于树模型特征选择">3.5基于树模型特征选择</h2><p>树模型基于分裂评价标准所计算的总的评分作为依据进行相关排序，然后进行特征筛选</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> ExtraTreesClassifier<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><br>clf = ExtraTreesClassifier(n_estimators=<span class="hljs-number">50</span>)<br>clf = clf.fit(train, target)<br><br>model = SelectFromModel(clf, prefit=<span class="hljs-literal">True</span>)<br>train_sel = model.transform(train)<br>test_sel = model.transform(test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 72)</code></pre><p>树特征重要性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">clf.feature_importances_[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([0.08131766, 0.01536015, 0.00893797, 0.01597656, 0.01636607,
       0.01680214, 0.01653297, 0.01548492, 0.01723172, 0.00725235])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">df_features_import = pd.DataFrame()<br>df_features_import[<span class="hljs-string">&#x27;features_import&#x27;</span>] = clf.feature_importances_<br>df_features_import[<span class="hljs-string">&#x27;features_name&#x27;</span>] = features_columns<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df_features_import.sort_values([<span class="hljs-string">&#x27;features_import&#x27;</span>],ascending=<span class="hljs-number">0</span>).head(<span class="hljs-number">30</span>)<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>features_import</th><th>features_name</th></tr></thead><tbody><tr><th>0</th><td>0.081318</td><td>merchant_id</td></tr><tr><th>228</th><td>0.075728</td><td>xgb_clf</td></tr><tr><th>227</th><td>0.067072</td><td>lgb_clf</td></tr><tr><th>20</th><td>0.018029</td><td>brand_most_1_cnt</td></tr><tr><th>18</th><td>0.017616</td><td>seller_most_1_cnt</td></tr><tr><th>14</th><td>0.017317</td><td>seller_most_1</td></tr><tr><th>8</th><td>0.017232</td><td>time_stamp_nunique</td></tr><tr><th>21</th><td>0.017172</td><td>action_type_1_cnt</td></tr><tr><th>15</th><td>0.017125</td><td>cat_most_1</td></tr><tr><th>26</th><td>0.016890</td><td>seller_nunique_0</td></tr><tr><th>5</th><td>0.016802</td><td>cat_nunique</td></tr><tr><th>12</th><td>0.016614</td><td>time_stamp_std</td></tr><tr><th>6</th><td>0.016533</td><td>brand_nunique</td></tr><tr><th>4</th><td>0.016366</td><td>seller_nunique</td></tr><tr><th>3</th><td>0.015977</td><td>user_cnt</td></tr><tr><th>16</th><td>0.015876</td><td>brand_most_1</td></tr><tr><th>22</th><td>0.015715</td><td>user_cnt_0</td></tr><tr><th>24</th><td>0.015566</td><td>user_cnt_2</td></tr><tr><th>7</th><td>0.015485</td><td>item_nunique</td></tr><tr><th>1</th><td>0.015360</td><td>age_range</td></tr><tr><th>19</th><td>0.015145</td><td>cat_most_1_cnt</td></tr><tr><th>25</th><td>0.014939</td><td>user_cnt_3</td></tr><tr><th>23</th><td>0.014691</td><td>user_cnt_1</td></tr><tr><th>87</th><td>0.009245</td><td>tfidf_60</td></tr><tr><th>2</th><td>0.008938</td><td>gender</td></tr><tr><th>86</th><td>0.008607</td><td>tfidf_59</td></tr><tr><th>9</th><td>0.007252</td><td>action_type_nunique</td></tr><tr><th>42</th><td>0.006752</td><td>tfidf_15</td></tr><tr><th>30</th><td>0.006479</td><td>tfidf_3</td></tr><tr><th>37</th><td>0.006460</td><td>tfidf_10</td></tr></tbody></table></div><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre><h2 id="lgb特征重要性">3.6 Lgb特征重要性</h2><p>利用LGB模型进行特征选择：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> lightgbm<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br>X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=<span class="hljs-number">0.4</span>, random_state=<span class="hljs-number">0</span>)<br><br>clf = lightgbm<br><br>train_matrix = clf.Dataset(X_train, label=y_train)<br>test_matrix = clf.Dataset(X_test, label=y_test)<br>params = &#123;<br>          <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>          <span class="hljs-comment">#&#x27;boosting_type&#x27;: &#x27;dart&#x27;,</span><br>          <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;multiclass&#x27;</span>,<br>          <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;multi_logloss&#x27;</span>,<br>          <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>          <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">2</span>**<span class="hljs-number">5</span>,<br>          <span class="hljs-string">&#x27;lambda_l2&#x27;</span>: <span class="hljs-number">10</span>,<br>          <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>          <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>          <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>          <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.03</span>,<br>          <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>          <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>          <span class="hljs-string">&quot;num_class&quot;</span>: <span class="hljs-number">2</span>,<br>          <span class="hljs-string">&#x27;silent&#x27;</span>: <span class="hljs-literal">True</span>,<br>          &#125;<br>num_round = <span class="hljs-number">10000</span><br>early_stopping_rounds = <span class="hljs-number">100</span><br>model = clf.train(params, <br>                  train_matrix,<br>                  num_round,<br>                  valid_sets=test_matrix,<br>                  callbacks=[lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lgb_transform</span>(<span class="hljs-params">train, test, model, topK</span>):<br>    train_df = pd.DataFrame(train)<br>    train_df.columns = <span class="hljs-built_in">range</span>(train.shape[<span class="hljs-number">1</span>])<br>    <br>    test_df = pd.DataFrame(test)<br>    test_df.columns = <span class="hljs-built_in">range</span>(test.shape[<span class="hljs-number">1</span>])<br>    <br>    features_import = pd.DataFrame()<br>    features_import[<span class="hljs-string">&#x27;importance&#x27;</span>] = model.feature_importance()<br>    features_import[<span class="hljs-string">&#x27;col&#x27;</span>] = <span class="hljs-built_in">range</span>(train.shape[<span class="hljs-number">1</span>])<br>    <br>    features_import = features_import.sort_values([<span class="hljs-string">&#x27;importance&#x27;</span>],ascending=<span class="hljs-number">0</span>).head(topK)<br>    sel_col = <span class="hljs-built_in">list</span>(features_import.col)<br>    <br>    train_sel = train_df[sel_col]<br>    test_sel = test_df[sel_col]<br>    <span class="hljs-keyword">return</span> train_sel, test_sel<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train_sel, test_sel = lgb_transform(train, test, model, <span class="hljs-number">20</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据未特征筛选维度&#x27;</span>, train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据特征筛选维度后&#x27;</span>, train_sel.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">训练数据未特征筛选维度 (8455, 229)
训练数据特征筛选维度后 (8455, 20)</code></pre><p>lgb特征重要性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model.feature_importance()[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([ 85,  29,   7,  69, 103,  98,  68,  40, 124,   2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#sorted(model.feature_importance(),reverse=True)[:10]</span><br></code></pre></td></tr></table></figure><p>特征选择前后区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_selection(train, train_sel, target)<br></code></pre></td></tr></table></figure><pre><code class="hljs">No Select Accuracy: 0.93 (+/- 0.00)
Features Select Accuracy: 0.93 (+/- 0.00)</code></pre></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>天猫重复购买预测-05特征优化和特征选择</div><div>https://zhou1317fe5.github.io/2023/12/22/天猫重复购买预测-05特征优化和特征选择/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年12月22日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2024/02/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Course1-Week1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%95%E8%A8%80/" title="深度学习-Course1_Week1深度学习引言"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">深度学习-Course1_Week1深度学习引言</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/12/15/%E5%A4%A9%E7%8C%AB%E9%87%8D%E5%A4%8D%E8%B4%AD%E4%B9%B0%E9%A2%84%E6%B5%8B-04%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%81%E9%AA%8C%E8%AF%81%E5%92%8C%E8%AF%84%E6%B5%8B/" title="天猫重复购买预测-04模型训练、验证和评测"><span class="hidden-mobile">天猫重复购买预测-04模型训练、验证和评测</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>