<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="1导入数据分析工具包 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom scipy import statsimport warningswarnings.filterwarnings(&quot;ignore&quot;) %mat"><meta property="og:type" content="article"><meta property="og:title" content="工业蒸汽预测-03特征工程"><meta property="og:url" content="https://zhou1317fe5.github.io/2023/07/31/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="1导入数据分析工具包 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom scipy import statsimport warningswarnings.filterwarnings(&quot;ignore&quot;) %mat"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_8_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_19_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_22_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_26_0.png"><meta property="article:published_time" content="2023-07-31T13:39:14.000Z"><meta property="article:modified_time" content="2025-03-02T12:40:44.229Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_8_0.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>工业蒸汽预测-03特征工程 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="工业蒸汽预测-03特征工程"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-07-31 21:39" pubdate>2023年7月31日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 29k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 243 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">工业蒸汽预测-03特征工程</h1><div class="markdown-body"><h1 id="导入数据分析工具包">1导入数据分析工具包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br> <br>%matplotlib inline<br></code></pre></td></tr></table></figure><h1 id="数据读取">2数据读取</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data_file = <span class="hljs-string">&quot;./data/zhengqi_train.txt&quot;</span><br>test_data_file =  <span class="hljs-string">&quot;./data/zhengqi_test.txt&quot;</span><br><br>train_data = pd.read_csv(train_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>test_data = pd.read_csv(test_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="训练数据总览">3训练数据总览</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data.describe()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>...</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td></tr><tr><th>mean</th><td>0.123048</td><td>0.056068</td><td>0.289720</td><td>-0.067790</td><td>0.012921</td><td>-0.558565</td><td>0.182892</td><td>0.116155</td><td>0.177856</td><td>-0.169452</td><td>...</td><td>0.097648</td><td>0.055477</td><td>0.127791</td><td>0.020806</td><td>0.007801</td><td>0.006715</td><td>0.197764</td><td>0.030658</td><td>-0.130330</td><td>0.126353</td></tr><tr><th>std</th><td>0.928031</td><td>0.941515</td><td>0.911236</td><td>0.970298</td><td>0.888377</td><td>0.517957</td><td>0.918054</td><td>0.955116</td><td>0.895444</td><td>0.953813</td><td>...</td><td>1.061200</td><td>0.901934</td><td>0.873028</td><td>0.902584</td><td>1.006995</td><td>1.003291</td><td>0.985675</td><td>0.970812</td><td>1.017196</td><td>0.983966</td></tr><tr><th>min</th><td>-4.335000</td><td>-5.122000</td><td>-3.420000</td><td>-3.956000</td><td>-4.742000</td><td>-2.182000</td><td>-4.576000</td><td>-5.048000</td><td>-4.692000</td><td>-12.891000</td><td>...</td><td>-2.912000</td><td>-4.507000</td><td>-5.859000</td><td>-4.053000</td><td>-4.627000</td><td>-4.789000</td><td>-5.695000</td><td>-2.608000</td><td>-3.630000</td><td>-3.044000</td></tr><tr><th>25%</th><td>-0.297000</td><td>-0.226250</td><td>-0.313000</td><td>-0.652250</td><td>-0.385000</td><td>-0.853000</td><td>-0.310000</td><td>-0.295000</td><td>-0.159000</td><td>-0.390000</td><td>...</td><td>-0.664000</td><td>-0.283000</td><td>-0.170250</td><td>-0.407250</td><td>-0.499000</td><td>-0.290000</td><td>-0.202500</td><td>-0.413000</td><td>-0.798250</td><td>-0.350250</td></tr><tr><th>50%</th><td>0.359000</td><td>0.272500</td><td>0.386000</td><td>-0.044500</td><td>0.110000</td><td>-0.466000</td><td>0.388000</td><td>0.344000</td><td>0.362000</td><td>0.042000</td><td>...</td><td>-0.023000</td><td>0.053500</td><td>0.299500</td><td>0.039000</td><td>-0.040000</td><td>0.160000</td><td>0.364000</td><td>0.137000</td><td>-0.185500</td><td>0.313000</td></tr><tr><th>75%</th><td>0.726000</td><td>0.599000</td><td>0.918250</td><td>0.624000</td><td>0.550250</td><td>-0.154000</td><td>0.831250</td><td>0.782250</td><td>0.726000</td><td>0.042000</td><td>...</td><td>0.745250</td><td>0.488000</td><td>0.635000</td><td>0.557000</td><td>0.462000</td><td>0.273000</td><td>0.602000</td><td>0.644250</td><td>0.495250</td><td>0.793250</td></tr><tr><th>max</th><td>2.121000</td><td>1.918000</td><td>2.828000</td><td>2.457000</td><td>2.689000</td><td>0.489000</td><td>1.895000</td><td>1.918000</td><td>2.245000</td><td>1.335000</td><td>...</td><td>4.580000</td><td>2.689000</td><td>2.013000</td><td>2.395000</td><td>5.465000</td><td>5.110000</td><td>2.324000</td><td>5.238000</td><td>3.000000</td><td>2.538000</td></tr></tbody></table><p>8 rows × 39 columns</p></div><h1 id="特征工程">4特征工程</h1><h2 id="异常值分析箱型图">4.1异常值分析（箱型图）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">10</span>))<br>plt.boxplot(x=train_data.values,labels=train_data.columns)<br>plt.hlines([-<span class="hljs-number">7.5</span>, <span class="hljs-number">7.5</span>], <span class="hljs-number">0</span>, <span class="hljs-number">40</span>, colors=<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-comment"># 0,40：水平线起始结束位置</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽预测-03特征工程/output_8_0.png" srcset="/img/loading.gif" lazyload></p><p>从箱线图可以看出，有些特征存在明显的异常值、如V9变量。接下来分别把训练集和测试集中的异常值删除。</p><h4 id="代码详解">代码详解：</h4><ol type="1"><li><p><code>plt.boxplot(x=train_data.values,labels=train_data.columns)</code>：使用<code>boxplot</code>函数绘制箱线图。其中，<code>train_data.values</code>是要绘制箱线图的数据，<code>labels=train_data.columns</code>表示箱线图中每个箱子对应的标签是<code>train_data</code>数据集的列名。</p></li><li><p><code>plt.hlines([-7.5, 7.5], 0, 40, colors='r')</code>：使用<code>hlines</code>函数绘制水平线。<code>[-7.5, 7.5]</code>表示要绘制的水平线的位置，0和40分别表示水平线的起始和结束位置，<code>colors='r'</code>表示线条颜色为红色。</p></li></ol><p>该段代码使用matplotlib库绘制了一个箱线图，展示了<code>train_data</code>数据集中各个特征列的分布情况，并在图中添加了两条水平线（-7.5和7.5），用于标记异常值的阈值。</p><h3 id="删除异常值">4.1.1删除异常值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data = train_data[train_data[<span class="hljs-string">&#x27;V9&#x27;</span>]&gt;-<span class="hljs-number">7.5</span>] <span class="hljs-comment"># 保留大于-7.5的值</span><br>test_data = test_data[test_data[<span class="hljs-string">&#x27;V9&#x27;</span>]&gt;-<span class="hljs-number">7.5</span>]<br><br>display(train_data.describe())<br>display(test_data.describe())<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.00000</td><td>...</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td></tr><tr><th>mean</th><td>0.123725</td><td>0.056856</td><td>0.290340</td><td>-0.068364</td><td>0.012254</td><td>-0.558971</td><td>0.183273</td><td>0.116274</td><td>0.178138</td><td>-0.16213</td><td>...</td><td>0.097019</td><td>0.058619</td><td>0.127617</td><td>0.023626</td><td>0.008271</td><td>0.006959</td><td>0.198513</td><td>0.030099</td><td>-0.131957</td><td>0.127451</td></tr><tr><th>std</th><td>0.927984</td><td>0.941269</td><td>0.911231</td><td>0.970357</td><td>0.888037</td><td>0.517871</td><td>0.918211</td><td>0.955418</td><td>0.895552</td><td>0.91089</td><td>...</td><td>1.060824</td><td>0.894311</td><td>0.873300</td><td>0.896509</td><td>1.007175</td><td>1.003411</td><td>0.985058</td><td>0.970258</td><td>1.015666</td><td>0.983144</td></tr><tr><th>min</th><td>-4.335000</td><td>-5.122000</td><td>-3.420000</td><td>-3.956000</td><td>-4.742000</td><td>-2.182000</td><td>-4.576000</td><td>-5.048000</td><td>-4.692000</td><td>-7.07100</td><td>...</td><td>-2.912000</td><td>-4.507000</td><td>-5.859000</td><td>-4.053000</td><td>-4.627000</td><td>-4.789000</td><td>-5.695000</td><td>-2.608000</td><td>-3.630000</td><td>-3.044000</td></tr><tr><th>25%</th><td>-0.292000</td><td>-0.224250</td><td>-0.310000</td><td>-0.652750</td><td>-0.385000</td><td>-0.853000</td><td>-0.310000</td><td>-0.295000</td><td>-0.158750</td><td>-0.39000</td><td>...</td><td>-0.664000</td><td>-0.282000</td><td>-0.170750</td><td>-0.405000</td><td>-0.499000</td><td>-0.290000</td><td>-0.199750</td><td>-0.412750</td><td>-0.798750</td><td>-0.347500</td></tr><tr><th>50%</th><td>0.359500</td><td>0.273000</td><td>0.386000</td><td>-0.045000</td><td>0.109500</td><td>-0.466000</td><td>0.388500</td><td>0.345000</td><td>0.362000</td><td>0.04200</td><td>...</td><td>-0.023000</td><td>0.054500</td><td>0.299500</td><td>0.040000</td><td>-0.040000</td><td>0.160000</td><td>0.364000</td><td>0.137000</td><td>-0.186000</td><td>0.314000</td></tr><tr><th>75%</th><td>0.726000</td><td>0.599000</td><td>0.918750</td><td>0.623500</td><td>0.550000</td><td>-0.154000</td><td>0.831750</td><td>0.782750</td><td>0.726000</td><td>0.04200</td><td>...</td><td>0.745000</td><td>0.488000</td><td>0.635000</td><td>0.557000</td><td>0.462000</td><td>0.273000</td><td>0.602000</td><td>0.643750</td><td>0.493000</td><td>0.793750</td></tr><tr><th>max</th><td>2.121000</td><td>1.918000</td><td>2.828000</td><td>2.457000</td><td>2.689000</td><td>0.489000</td><td>1.895000</td><td>1.918000</td><td>2.245000</td><td>1.33500</td><td>...</td><td>4.580000</td><td>2.689000</td><td>2.013000</td><td>2.395000</td><td>5.465000</td><td>5.110000</td><td>2.324000</td><td>5.238000</td><td>3.000000</td><td>2.538000</td></tr></tbody></table><p>8 rows × 39 columns</p></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V28</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>count</th><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>...</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td></tr><tr><th>mean</th><td>-0.184404</td><td>-0.083912</td><td>-0.434762</td><td>0.101671</td><td>-0.019172</td><td>0.838049</td><td>-0.274092</td><td>-0.173971</td><td>-0.266709</td><td>0.255114</td><td>...</td><td>-0.206871</td><td>-0.146463</td><td>-0.083215</td><td>-0.191729</td><td>-0.030782</td><td>-0.011433</td><td>-0.009985</td><td>-0.296895</td><td>-0.046270</td><td>0.195735</td></tr><tr><th>std</th><td>1.073333</td><td>1.076670</td><td>0.969541</td><td>1.034925</td><td>1.147286</td><td>0.963043</td><td>1.054119</td><td>1.040101</td><td>1.085916</td><td>1.014394</td><td>...</td><td>1.064140</td><td>0.880593</td><td>1.126414</td><td>1.138454</td><td>1.130228</td><td>0.989732</td><td>0.995213</td><td>0.946896</td><td>1.040854</td><td>0.940599</td></tr><tr><th>min</th><td>-4.814000</td><td>-5.488000</td><td>-4.283000</td><td>-3.276000</td><td>-4.921000</td><td>-1.168000</td><td>-5.649000</td><td>-5.625000</td><td>-6.059000</td><td>-6.784000</td><td>...</td><td>-2.435000</td><td>-2.413000</td><td>-4.507000</td><td>-7.698000</td><td>-4.057000</td><td>-4.627000</td><td>-4.789000</td><td>-7.477000</td><td>-2.608000</td><td>-3.346000</td></tr><tr><th>25%</th><td>-0.664000</td><td>-0.451000</td><td>-0.978000</td><td>-0.644000</td><td>-0.497000</td><td>0.122000</td><td>-0.732000</td><td>-0.509000</td><td>-0.775000</td><td>-0.390000</td><td>...</td><td>-0.453000</td><td>-0.818000</td><td>-0.339000</td><td>-0.476000</td><td>-0.472000</td><td>-0.460000</td><td>-0.290000</td><td>-0.349000</td><td>-0.593000</td><td>-0.432000</td></tr><tr><th>50%</th><td>0.065000</td><td>0.195000</td><td>-0.267000</td><td>0.220000</td><td>0.118000</td><td>0.437000</td><td>-0.082000</td><td>0.018000</td><td>-0.004000</td><td>0.401000</td><td>...</td><td>-0.445000</td><td>-0.199000</td><td>0.010000</td><td>0.100000</td><td>0.155000</td><td>-0.040000</td><td>0.160000</td><td>-0.270000</td><td>0.083000</td><td>0.152000</td></tr><tr><th>75%</th><td>0.549000</td><td>0.589000</td><td>0.278000</td><td>0.793000</td><td>0.610000</td><td>1.928000</td><td>0.457000</td><td>0.515000</td><td>0.482000</td><td>0.904000</td><td>...</td><td>-0.434000</td><td>0.468000</td><td>0.447000</td><td>0.471000</td><td>0.627000</td><td>0.419000</td><td>0.273000</td><td>0.364000</td><td>0.651000</td><td>0.797000</td></tr><tr><th>max</th><td>2.100000</td><td>2.120000</td><td>1.946000</td><td>2.603000</td><td>4.475000</td><td>3.176000</td><td>1.528000</td><td>1.394000</td><td>2.408000</td><td>1.766000</td><td>...</td><td>4.656000</td><td>3.022000</td><td>3.139000</td><td>1.428000</td><td>2.299000</td><td>5.465000</td><td>5.110000</td><td>1.671000</td><td>2.861000</td><td>3.021000</td></tr></tbody></table><p>8 rows × 38 columns</p></div><h2 id="特征缩放最大最小值归一化">4.2特征缩放（最大最小值归一化）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing <br><br>features_columns = [col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> train_data.columns <span class="hljs-keyword">if</span> col <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;target&#x27;</span>]]<br><br>min_max_scaler = preprocessing.MinMaxScaler()<br>min_max_scaler = min_max_scaler.fit(train_data[features_columns])<br><br>train_data_scaler = min_max_scaler.transform(train_data[features_columns])<br>test_data_scaler = min_max_scaler.transform(test_data[features_columns])<br><br>train_data_scaler = pd.DataFrame(train_data_scaler)<br>train_data_scaler.columns = features_columns<br><br>test_data_scaler = pd.DataFrame(test_data_scaler)<br>test_data_scaler.columns = features_columns<br><br>train_data_scaler[<span class="hljs-string">&#x27;target&#x27;</span>] = train_data[<span class="hljs-string">&#x27;target&#x27;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">display(train_data_scaler.describe())<br>display(test_data_scaler.describe())<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>...</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2884.000000</td></tr><tr><th>mean</th><td>0.690633</td><td>0.735633</td><td>0.593844</td><td>0.606212</td><td>0.639787</td><td>0.607649</td><td>0.735477</td><td>0.741354</td><td>0.702053</td><td>0.821897</td><td>...</td><td>0.401631</td><td>0.634466</td><td>0.760495</td><td>0.632231</td><td>0.459302</td><td>0.484489</td><td>0.734944</td><td>0.336235</td><td>0.527608</td><td>0.127274</td></tr><tr><th>std</th><td>0.143740</td><td>0.133703</td><td>0.145844</td><td>0.151311</td><td>0.119504</td><td>0.193887</td><td>0.141896</td><td>0.137154</td><td>0.129098</td><td>0.108362</td><td>...</td><td>0.141594</td><td>0.124279</td><td>0.110938</td><td>0.139037</td><td>0.099799</td><td>0.101365</td><td>0.122840</td><td>0.123663</td><td>0.153192</td><td>0.983462</td></tr><tr><th>min</th><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>...</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>-3.044000</td></tr><tr><th>25%</th><td>0.626239</td><td>0.695703</td><td>0.497759</td><td>0.515087</td><td>0.586328</td><td>0.497566</td><td>0.659249</td><td>0.682314</td><td>0.653489</td><td>0.794789</td><td>...</td><td>0.300053</td><td>0.587132</td><td>0.722593</td><td>0.565757</td><td>0.409037</td><td>0.454490</td><td>0.685279</td><td>0.279792</td><td>0.427036</td><td>-0.348500</td></tr><tr><th>50%</th><td>0.727153</td><td>0.766335</td><td>0.609155</td><td>0.609855</td><td>0.652873</td><td>0.642456</td><td>0.767192</td><td>0.774189</td><td>0.728557</td><td>0.846181</td><td>...</td><td>0.385611</td><td>0.633894</td><td>0.782330</td><td>0.634770</td><td>0.454518</td><td>0.499949</td><td>0.755580</td><td>0.349860</td><td>0.519457</td><td>0.313000</td></tr><tr><th>75%</th><td>0.783922</td><td>0.812642</td><td>0.694422</td><td>0.714096</td><td>0.712152</td><td>0.759266</td><td>0.835690</td><td>0.837030</td><td>0.781029</td><td>0.846181</td><td>...</td><td>0.488121</td><td>0.694136</td><td>0.824949</td><td>0.714950</td><td>0.504261</td><td>0.511365</td><td>0.785260</td><td>0.414447</td><td>0.621870</td><td>0.794250</td></tr><tr><th>max</th><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>...</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>2.538000</td></tr></tbody></table><p>8 rows × 39 columns</p></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V28</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>count</th><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>...</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td></tr><tr><th>mean</th><td>0.642905</td><td>0.715637</td><td>0.477791</td><td>0.632726</td><td>0.635558</td><td>1.130681</td><td>0.664798</td><td>0.699688</td><td>0.637926</td><td>0.871534</td><td>...</td><td>0.313556</td><td>0.369132</td><td>0.614756</td><td>0.719928</td><td>0.623793</td><td>0.457349</td><td>0.482778</td><td>0.673164</td><td>0.326501</td><td>0.577034</td></tr><tr><th>std</th><td>0.166253</td><td>0.152936</td><td>0.155176</td><td>0.161379</td><td>0.154392</td><td>0.360555</td><td>0.162899</td><td>0.149311</td><td>0.156540</td><td>0.120675</td><td>...</td><td>0.149752</td><td>0.117538</td><td>0.156533</td><td>0.144621</td><td>0.175284</td><td>0.098071</td><td>0.100537</td><td>0.118082</td><td>0.132661</td><td>0.141870</td></tr><tr><th>min</th><td>-0.074195</td><td>-0.051989</td><td>-0.138124</td><td>0.106035</td><td>-0.024088</td><td>0.379633</td><td>-0.165817</td><td>-0.082831</td><td>-0.197059</td><td>0.034142</td><td>...</td><td>0.000000</td><td>0.066604</td><td>0.000000</td><td>-0.233613</td><td>-0.000620</td><td>0.000000</td><td>0.000000</td><td>-0.222222</td><td>0.000000</td><td>0.042836</td></tr><tr><th>25%</th><td>0.568618</td><td>0.663494</td><td>0.390845</td><td>0.516451</td><td>0.571256</td><td>0.862598</td><td>0.594035</td><td>0.651593</td><td>0.564653</td><td>0.794789</td><td>...</td><td>0.278919</td><td>0.279498</td><td>0.579211</td><td>0.683816</td><td>0.555366</td><td>0.412901</td><td>0.454490</td><td>0.666667</td><td>0.256819</td><td>0.482353</td></tr><tr><th>50%</th><td>0.681537</td><td>0.755256</td><td>0.504641</td><td>0.651177</td><td>0.654017</td><td>0.980532</td><td>0.694483</td><td>0.727247</td><td>0.675796</td><td>0.888889</td><td>...</td><td>0.280045</td><td>0.362120</td><td>0.627710</td><td>0.756987</td><td>0.652605</td><td>0.454518</td><td>0.499949</td><td>0.676518</td><td>0.342977</td><td>0.570437</td></tr><tr><th>75%</th><td>0.756506</td><td>0.811222</td><td>0.591869</td><td>0.740527</td><td>0.720226</td><td>1.538750</td><td>0.777778</td><td>0.798593</td><td>0.745856</td><td>0.948727</td><td>...</td><td>0.281593</td><td>0.451148</td><td>0.688438</td><td>0.804116</td><td>0.725806</td><td>0.500000</td><td>0.511365</td><td>0.755580</td><td>0.415371</td><td>0.667722</td></tr><tr><th>max</th><td>0.996747</td><td>1.028693</td><td>0.858835</td><td>1.022766</td><td>1.240345</td><td>2.005990</td><td>0.943285</td><td>0.924777</td><td>1.023497</td><td>1.051273</td><td>...</td><td>0.997889</td><td>0.792045</td><td>1.062535</td><td>0.925686</td><td>0.985112</td><td>1.000000</td><td>1.000000</td><td>0.918568</td><td>0.697043</td><td>1.003167</td></tr></tbody></table><p>8 rows × 38 columns</p></div><h4 id="代码详解-1">代码详解：</h4><ol type="1"><li><p><code>features_columns = [col for col in train_data.columns if col not in ['target']]</code>：使用列表推导式创建一个列表<code>features_columns</code>，其中包含除了'target'列之外的所有训练数据的特征列。</p></li><li><p><code>min_max_scaler = preprocessing.MinMaxScaler()</code>：创建一个MinMaxScaler对象，用于进行特征缩放。</p></li><li><p><code>min_max_scaler = min_max_scaler.fit(train_data[features_columns])</code>：使用训练数据的特征列拟合（fit）MinMaxScaler对象，计算训练集中每个特征的最小值和最大值。</p></li><li><p><code>train_data_scaler = min_max_scaler.transform(train_data[features_columns])</code>：将训练数据的特征列使用MinMaxScaler进行缩放转换，得到缩放后的训练数据。</p></li><li><p><code>test_data_scaler = min_max_scaler.transform(test_data[features_columns])</code>：将测试数据的特征列使用相同的MinMaxScaler进行缩放转换，得到缩放后的测试数据。这里使用的是在训练数据上拟合的MinMaxScaler对象，保证了训练数据和测试数据的缩放方式一致。</p></li><li><p><code>train_data_scaler = pd.DataFrame(train_data_scaler)</code>：将缩放后的训练数据转换为DataFrame格式。</p></li><li><p><code>train_data_scaler.columns = features_columns</code>：将缩放后的训练数据的列名设置为原始特征列的列名，保持一致性。</p></li><li><p><code>test_data_scaler = pd.DataFrame(test_data_scaler)</code>：将缩放后的测试数据转换为DataFrame格式。</p></li><li><p><code>test_data_scaler.columns = features_columns</code>：将缩放后的测试数据的列名设置为原始特征列的列名，保持一致性。</p></li><li><p><code>train_data_scaler['target'] = train_data['target']</code>：将缩放后的训练数据中的'target'列设置为原始训练数据的'target'列，这样保留了目标变量。</p></li></ol><hr><p><strong>fit与transform：</strong></p><ol type="1"><li>fit方法：<ul><li>fit方法用于从训练数据中学习模型的参数或数据转换所需的统计信息。</li><li>在fit方法中，模型会根据训练数据自动计算并确定转换所需的参数，例如均值、标准差等。</li><li>fit方法通常只针对训练数据集进行调用，以便使模型能够根据训练数据适应最佳的参数设置。</li></ul></li><li>transform方法：<ul><li>transform方法用于将原始数据转换为经过预处理后的数据。</li><li>在transform方法中，模型会根据之前学习到的参数或统计信息，对数据进行相应的转换操作。</li><li>transform方法通常在训练数据和测试数据上分别调用，以便将它们都转换为相同的预处理格式，保证数据的一致性。</li></ul></li></ol><p>fit和transform方法在不同的预处理类中具有相对应的方法名：</p><ul><li><p>MinMaxScaler类，fit方法用于计算每个特征的最小值和最大值，transform方法用于将数据缩放到给定的范围，默认为[0, 1]。</p></li><li><p>StandardScaler类，fit方法用于计算每个特征的均值和标准差，transform方法用于将数据进行标准化处理，使其均值为0，标准差为1。</p></li><li><p>OneHotEncoder类，fit方法用于确定类别特征的所有可能取值，并构建映射关系，transform方法用于将类别特征转换为二进制矩阵表示。</p></li></ul><p>fit方法用于从 ==训练数据== 中 ==学习== 模型的 ==参数== 或统计信息，transform方法用于将原始数据按照之前学习到的参数或统计信息进行转换。在实际应用中，通常先调用fit方法对模型进行训练，然后再调用transform方法对训练数据和测试数据进行相同的数据预处理操作。</p><p>使用MinMaxScaler对数据进行缩放时，通常将其fit在训练集上的原因是为了避免信息泄漏（information leakage）。</p><p>信息泄漏是指在数据预处理过程中，使用了不应该在当前步骤中可用的额外信息。这可能导致模型在实际应用中性能下降，因为会在测试集上产生过于乐观的估计。</p><p>将MinMaxScaler仅拟合（fit）于训练数据的优势有两个：</p><ul><li>模型只能使用训练集的信息进行训练和预测，这符合机器学习的基本原则。模型无法直接访问测试集的任何信息，以确保其在真实世界中的性能。</li><li>防止信息泄漏。如果将MinMaxScaler同时拟合于训练集和测试集，就相当于使用了测试集的信息来进行预处理，将测试集的信息引入到了训练过程中。这可能会导致过于乐观的结果。</li><li>测试集是用于评估模型性能的独立数据集。如果对测试集拟合（fit），则使用不同的预处理参数，那么测试集的数据范围和分布就会与训练集不一致，这可能导致模型在实际应用中表现不佳。</li></ul><hr><p><strong><code>column = train_data.columns.tolist()[:39]</code>与 <code>columns = [col for col in train_data.columns]</code> 这两种获取列名的区别和优劣：</strong></p><ol type="1"><li><code>column = train_data.columns.tolist()[:39]</code>：<ul><li>这种方式将DataFrame的列名转换为一个Python列表。</li><li>优点：简单直接，获取指定数量的列名。</li><li>缺点：只能获取指定数量的列名，不适用于需要选择特定列或基于某些条件筛选列名的情况。</li></ul></li><li><code>columns = [col for col in train_data.columns]</code>：<ul><li>这种方式使用列表推导式将DataFrame的所有列名存储到一个列表中。</li><li>优点：可以获取DataFrame中的所有列名，提供了更大的灵活性。可以通过条件筛选、修改等方式来操作列名。</li><li>缺点：相对于第一种方式来说，代码稍微复杂一些。</li></ul></li></ol><p>所以，选择哪种方式取决于具体的需求：</p><ul><li>如果只需要获取特定数量的列名，且数量固定，可以使用<code>train_data.columns.tolist()[:39]</code>方式，简单且明确。</li><li>如果需要对列名进行更多的操作，如条件筛选、修改等，或者需要获取所有列名，例如<code>col for col in train_data.columns if col not in ['target']</code> 那么使用列表推导式会更灵活。</li></ul><h2 id="查看数据分布情况">4.3查看数据分布情况</h2><p>我们利用KDE分布对比特征变量在训练集和测试集中的分布情况。对比后发现：特征变量V5, V9, V11, V17, V22, V28在训练集和测试集中的分布差异较大，会影响模型的泛化能力，故删除这些特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># KDE分布</span><br>dist_cols = <span class="hljs-number">6</span><br>dist_rows = <span class="hljs-built_in">len</span>(test_data_scaler.columns)<br><br>plt.figure(figsize=(<span class="hljs-number">4</span>*dist_cols,<span class="hljs-number">4</span>*dist_rows))<br><br><br><span class="hljs-keyword">for</span> i, col <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_data_scaler.columns):<br>    ax=plt.subplot(dist_rows,dist_cols,i+<span class="hljs-number">1</span>)<br>    ax = sns.kdeplot(train_data_scaler[col], color=<span class="hljs-string">&quot;Red&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax = sns.kdeplot(test_data_scaler[col], color=<span class="hljs-string">&quot;Blue&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax.set_xlabel(col)<br>    ax.set_ylabel(<span class="hljs-string">&quot;Frequency&quot;</span>)<br>    ax = ax.legend([<span class="hljs-string">&quot;train&quot;</span>,<span class="hljs-string">&quot;test&quot;</span>])<br> <br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-03特征工程/output_19_0.png" srcset="/img/loading.gif" lazyload> ​</p><h4 id="代码解释">代码解释：</h4><p><code>for i, col in enumerate(test_data_scaler.columns)</code>：迭代循环，遍历<code>test_data_scaler.columns</code>中的每一列，并使用<code>enumerate</code>函数同时将列的索引赋值给<code>i</code>，列名赋值给<code>col</code>。</p><p>查看特征'V5', 'V17', 'V28', 'V22', 'V11', 'V9'数据的数据分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">drop_col = <span class="hljs-number">6</span><br>drop_row = <span class="hljs-number">1</span><br><br>plt.figure(figsize=(<span class="hljs-number">5</span>*drop_col,<span class="hljs-number">5</span>*drop_row))<br><br><span class="hljs-keyword">for</span> i, col <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>([<span class="hljs-string">&quot;V5&quot;</span>,<span class="hljs-string">&quot;V9&quot;</span>,<span class="hljs-string">&quot;V11&quot;</span>,<span class="hljs-string">&quot;V17&quot;</span>,<span class="hljs-string">&quot;V22&quot;</span>,<span class="hljs-string">&quot;V28&quot;</span>]):<br>    ax =plt.subplot(drop_row,drop_col,i+<span class="hljs-number">1</span>)<br>    ax = sns.kdeplot(train_data_scaler[col], color=<span class="hljs-string">&quot;Red&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax= sns.kdeplot(test_data_scaler[col], color=<span class="hljs-string">&quot;Blue&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax.set_xlabel(col)<br>    ax.set_ylabel(<span class="hljs-string">&quot;Frequency&quot;</span>)<br>    ax = ax.legend([<span class="hljs-string">&quot;train&quot;</span>,<span class="hljs-string">&quot;test&quot;</span>])<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-03特征工程/output_22_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>这几个特征下，训练集的数据和测试集的数据分布不一致，会影响模型的泛化能力，故删除这些特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data_train_scaler = train_data_scaler.drop([<span class="hljs-string">&#x27;V5&#x27;</span>,<span class="hljs-string">&#x27;V9&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>,<span class="hljs-string">&#x27;V17&#x27;</span>,<span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V28&#x27;</span>],axis=<span class="hljs-number">1</span>)<br>data_train_scaler.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V6</th><th>V7</th><th>V8</th><th>V10</th><th>V12</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>0</th><td>0.759139</td><td>0.729830</td><td>0.524488</td><td>0.680337</td><td>0.698964</td><td>0.427136</td><td>0.385874</td><td>0.613522</td><td>0.221743</td><td>0.698875</td><td>...</td><td>0.406834</td><td>0.641467</td><td>0.666159</td><td>0.679280</td><td>0.00000</td><td>0.000000</td><td>0.074074</td><td>0.000000</td><td>0.018401</td><td>0.175</td></tr><tr><th>1</th><td>0.821406</td><td>0.789631</td><td>0.557939</td><td>0.705130</td><td>0.664244</td><td>0.465152</td><td>0.385874</td><td>0.724232</td><td>0.373887</td><td>0.690502</td><td>...</td><td>0.371596</td><td>0.643552</td><td>0.748349</td><td>0.721619</td><td>0.37495</td><td>0.499949</td><td>0.755580</td><td>0.289702</td><td>0.437406</td><td>0.676</td></tr><tr><th>2</th><td>0.828377</td><td>0.808239</td><td>0.584987</td><td>0.674567</td><td>0.653210</td><td>0.495905</td><td>0.385874</td><td>0.733458</td><td>0.466415</td><td>0.699012</td><td>...</td><td>0.387480</td><td>0.676487</td><td>0.779472</td><td>0.610577</td><td>0.37495</td><td>0.499949</td><td>0.755580</td><td>0.429901</td><td>0.458673</td><td>0.633</td></tr><tr><th>3</th><td>0.785006</td><td>0.779830</td><td>0.592670</td><td>0.642601</td><td>0.718746</td><td>0.521712</td><td>0.425208</td><td>0.734467</td><td>0.350013</td><td>0.706972</td><td>...</td><td>0.390683</td><td>0.684269</td><td>0.779726</td><td>0.722084</td><td>0.37495</td><td>0.477220</td><td>0.755580</td><td>0.374841</td><td>0.530618</td><td>0.206</td></tr><tr><th>4</th><td>0.777416</td><td>0.818182</td><td>0.588988</td><td>0.649462</td><td>0.683488</td><td>0.541338</td><td>0.425208</td><td>0.721638</td><td>0.314675</td><td>0.736206</td><td>...</td><td>0.413107</td><td>0.776126</td><td>0.785950</td><td>0.693393</td><td>0.37495</td><td>0.462067</td><td>0.755580</td><td>0.296712</td><td>0.543288</td><td>0.384</td></tr></tbody></table><p>5 rows × 33 columns</p></div><h2 id="特征相关性">4.4特征相关性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>))  <br>column = train_data_scaler.columns.tolist()  <br>mcorr = train_data_scaler[column].corr(method=<span class="hljs-string">&quot;spearman&quot;</span>)  <br>mask = np.zeros_like(mcorr, dtype=np.<span class="hljs-built_in">bool</span>)  <br>mask[np.triu_indices_from(mask)] = <span class="hljs-literal">True</span>  <br>cmap = sns.diverging_palette(<span class="hljs-number">220</span>, <span class="hljs-number">10</span>, as_cmap=<span class="hljs-literal">True</span>)  <br>g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=<span class="hljs-literal">True</span>, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">&#x27;0.2f&#x27;</span>)  <br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-03特征工程/output_26_0.png" srcset="/img/loading.gif" lazyload> ​</p><h2 id="特征降维">4.5特征降维</h2><h3 id="相关性初筛1">4.5.1相关性初筛1</h3><p>进行特征相关性初筛，计算相关性系数并筛选大于0.1的特征变量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">mcorr=mcorr.<span class="hljs-built_in">abs</span>()<br>numerical_corr=mcorr[mcorr[<span class="hljs-string">&#x27;target&#x27;</span>]&gt;<span class="hljs-number">0.1</span>][<span class="hljs-string">&#x27;target&#x27;</span>]<br><span class="hljs-built_in">print</span>(numerical_corr.sort_values(ascending=<span class="hljs-literal">False</span>))<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">target    1.000000
V0        0.712403
V31       0.711636
V1        0.682909
V8        0.679469
V27       0.657398
V2        0.585850
V16       0.545793
V3        0.501622
V4        0.478683
V12       0.460300
V10       0.448682
V36       0.425991
V37       0.376443
V24       0.305526
V5        0.286076
V6        0.280195
V20       0.278381
V11       0.234551
V15       0.221290
V29       0.190109
V7        0.185321
V19       0.180111
V18       0.149741
V13       0.149199
V17       0.126262
V22       0.112743
V30       0.101378
Name: target, dtype: float64</code></pre><h4 id="代码详解-2">代码详解：</h4><ol type="1"><li><p>使用 <code>mcorr.abs()</code>对相关性矩阵 <code>mcorr</code> 中的各个元素取绝对值。</p></li><li><p><code>mcorr[mcorr['target']&gt;0.1]</code> 从 <code>mcorr</code> 中筛选出目标变量（<code>target</code>）相关性大于 0.1 的特征行，接着 <code>mcorr[mcorr['target']&gt;0.1]['target']</code>提取出 <code>target</code> 列。</p></li><li><p>对 <code>numerical_corr</code> 进行降序排序，<code>.sort_values(ascending=False)</code> 表示按照降序排列，即相关性系数较高的特征显示在前面。</p></li><li><p><code>numerical_corr.sort_values(ascending=False).index</code> 对 <code>numerical_corr</code> 进行降序排序，并提取排序后的索引，并将其赋值给 <code>index0</code>。</p></li><li><p>通过 <code>train_data_scaler[index0]</code> 获取 <code>train_data_scaler</code> 中与 <code>index0</code> 中特征名称索引对应的特征列，并使用 <code>.corr('spearman')</code> 计算这些特征之间的斯皮尔曼相关系数。</p></li></ol><h3 id="相关性初筛2">4.5.2相关性初筛2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">features_corr = numerical_corr.sort_values(ascending=<span class="hljs-literal">False</span>).reset_index()<br>features_corr.columns = [<span class="hljs-string">&#x27;features_and_target&#x27;</span>, <span class="hljs-string">&#x27;corr&#x27;</span>]<br>features_corr_select = features_corr[features_corr[<span class="hljs-string">&#x27;corr&#x27;</span>]&gt;<span class="hljs-number">0.3</span>] <span class="hljs-comment"># 筛选出大于相关性大于0.3的特征</span><br><span class="hljs-built_in">print</span>(features_corr_select)<br>select_features = [col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> features_corr_select[<span class="hljs-string">&#x27;features_and_target&#x27;</span>] <span class="hljs-keyword">if</span> col <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;target&#x27;</span>]]<br>new_train_data_corr_select = train_data_scaler[select_features+[<span class="hljs-string">&#x27;target&#x27;</span>]]<br>new_test_data_corr_select = test_data_scaler[select_features]<br></code></pre></td></tr></table></figure><pre><code class="hljs">   features_and_target      corr
0               target  1.000000
1                   V0  0.712403
2                  V31  0.711636
3                   V1  0.682909
4                   V8  0.679469
5                  V27  0.657398
6                   V2  0.585850
7                  V16  0.545793
8                   V3  0.501622
9                   V4  0.478683
10                 V12  0.460300
11                 V10  0.448682
12                 V36  0.425991
13                 V37  0.376443
14                 V24  0.305526</code></pre><h2 id="多重共线性分析">4.6多重共线性分析</h2><p>多重共线性分析的原则是特征组之间的相关性系数较大，即每个特征变量与其他特征变量之间的相关性系数较大，故可能存在较大的共线性影响，这会导致模型估计不准确。因此，后续要使用PCA对数据进行处理，去除多重共线性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 计算多重共线性</span><br><span class="hljs-keyword">from</span> statsmodels.stats.outliers_influence <span class="hljs-keyword">import</span> variance_inflation_factor <span class="hljs-comment">#多重共线性方差膨胀因子</span><br><br><span class="hljs-comment">#多重共线性</span><br>new_numerical=[<span class="hljs-string">&#x27;V0&#x27;</span>, <span class="hljs-string">&#x27;V2&#x27;</span>, <span class="hljs-string">&#x27;V3&#x27;</span>, <span class="hljs-string">&#x27;V4&#x27;</span>, <span class="hljs-string">&#x27;V5&#x27;</span>, <span class="hljs-string">&#x27;V6&#x27;</span>, <span class="hljs-string">&#x27;V10&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>, <br>                         <span class="hljs-string">&#x27;V13&#x27;</span>, <span class="hljs-string">&#x27;V15&#x27;</span>, <span class="hljs-string">&#x27;V16&#x27;</span>, <span class="hljs-string">&#x27;V18&#x27;</span>, <span class="hljs-string">&#x27;V19&#x27;</span>, <span class="hljs-string">&#x27;V20&#x27;</span>, <span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V24&#x27;</span>,<span class="hljs-string">&#x27;V30&#x27;</span>, <span class="hljs-string">&#x27;V31&#x27;</span>, <span class="hljs-string">&#x27;V37&#x27;</span>]<br>X=np.matrix(train_data_scaler[new_numerical])<br>VIF_list=[variance_inflation_factor(X, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X.shape[<span class="hljs-number">1</span>])]<br>VIF_list<br></code></pre></td></tr></table></figure><pre><code class="hljs">[216.73387180903222,
 114.38118723828812,
 27.863778129686356,
 201.96436579080174,
 78.93722825798903,
 151.06983667656212,
 14.519604941508451,
 82.69750284665385,
 28.479378440614585,
 27.759176471505945,
 526.6483470743831,
 23.50166642638334,
 19.920315849901424,
 24.640481765008683,
 11.816055964845381,
 4.958208708452915,
 37.09877416736591,
 298.26442986612767,
 47.854002539887034]</code></pre><p>说明：new_numerical的特征变量可以根据相关性矩阵看出并过滤筛选，剔除那些与其他特征高度相关的特征，然后，使用剩余的特征矩阵来计算每个特征的VIF值，以评估自变量之间的多重共线性程度。</p><h4 id="代码详解-3">代码详解：</h4><ol type="1"><li><p><code>new_numerical=[ ]</code>：定义了一个包含特征列名称的列表<code>new_numerical</code>，这些特征将被用于计算VIF。</p></li><li><p><code>X=np.matrix(train_data_scaler[new_numerical])</code>：将训练数据<code>train_data_scaler</code>中<code>new_numerical</code>列表中的特征列用 <code>np.matrix</code> 转换为二维矩阵<code>X</code>。该矩阵将作为VIF计算的输入。</p></li><li><p><code>VIF_list=[variance_inflation_factor(X, i) for i in range(X.shape[1])]</code>：使用列表推导式计算VIF列表。对于矩阵<code>X</code>的每一列（即特征），调用<code>variance_inflation_factor</code>函数来计算VIF，并将结果添加到<code>VIF_list</code>中。<code>range(X.shape[1])</code>生成了一个表示列索引的迭代器。（下方详解variance_inflation_factor）</p></li><li><p><code>VIF_list</code>：输出VIF列表，该列表包含了每个特征的方差膨胀因子。</p></li></ol><hr><p><strong>variance_inflation_factor用法</strong></p><p><code>variance_inflation_factor</code> 是一个用于计算方差膨胀因子（Variance Inflation Factor，VIF）的函数。方差膨胀因子是用于检测多重共线性（multicollinearity）问题的一种统计指标。</p><p>多重共线性指的是在回归分析中，自变量之间存在高度线性相关性的情况。它会导致回归模型中的估计不稳定，使得对自变量的解释变得困难。方差膨胀因子通过衡量每个自变量对其他自变量的线性相关性来检测多重共线性。</p><p><code>variance_inflation_factor</code> 函数通常需要传入两个参数：</p><ol type="1"><li><code>X</code>：一个二维数组或数据帧，表示自变量矩阵。每一列代表一个自变量。</li><li><code>idx</code>：一个整数，表示要计算方差膨胀因子的自变量的索引。</li></ol><p>以下是 <code>variance_inflation_factor</code> 函数的用法示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> statsmodels.stats.outliers_influence <span class="hljs-keyword">import</span> variance_inflation_factor<br><br><span class="hljs-comment"># 假设 X 是自变量矩阵，其中每一列代表一个自变量</span><br>vif = variance_inflation_factor(X, idx)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Variance inflation factor for variable <span class="hljs-subst">&#123;idx&#125;</span>: <span class="hljs-subst">&#123;vif&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>这段代码计算自变量矩阵 <code>X</code> 中给定索引 <code>idx</code> 的自变量的方差膨胀因子，并将结果打印输出。</p><p>方差膨胀因子的常见阈值为 5 或 10。当方差膨胀因子超过这个阈值时，表示该自变量与其他自变量存在高度线性相关性，可能会导致多重共线性问题。一般而言，方差膨胀因子越大，说明自变量之间的相关性越高。</p><h2 id="pca处理">4.7PCA处理</h2><p>利用PCA方法去除数据的多重共线性，并进行降维。</p><p>在scikit-learn（sklearn）库中，PCA被实现<code>sklearn.decomposition.PCA</code>类，主要参数<code>n_components</code>指定降维后的特征数量或保留的信息量的比例。可以设置为一个整数来指定具体的特征数量，也可以设置为一个0到1之间的浮点数来表示保留的信息量比例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA   <span class="hljs-comment">#主成分分析法</span><br><br><span class="hljs-comment">#PCA方法降维</span><br><span class="hljs-comment">#保持90%的信息</span><br>pca = PCA(n_components=<span class="hljs-number">0.9</span>)<br>new_train_pca_90 = pca.fit_transform(train_data_scaler.iloc[:,<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>])<br>new_test_pca_90 = pca.transform(test_data_scaler)<br><br>new_train_pca_90 = pd.DataFrame(new_train_pca_90)<br>new_test_pca_90 = pd.DataFrame(new_test_pca_90)<br><br>new_train_pca_90[<span class="hljs-string">&#x27;target&#x27;</span>] = train_data_scaler[<span class="hljs-string">&#x27;target&#x27;</span>]<br><br><span class="hljs-comment"># 查看原数据信息并与PCA处理后的数据进行对比</span><br>display(new_train_pca_90.describe())<br>display(train_data_scaler.describe())<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2884.000000</td></tr><tr><th>mean</th><td>2.089242e-17</td><td>-1.012126e-16</td><td>1.057905e-17</td><td>-1.002894e-16</td><td>8.509402e-17</td><td>-5.249131e-17</td><td>5.271732e-17</td><td>6.668166e-17</td><td>-4.468205e-17</td><td>9.163379e-17</td><td>7.636149e-18</td><td>1.237075e-16</td><td>-5.053900e-18</td><td>-5.874257e-17</td><td>-2.122542e-17</td><td>1.230265e-16</td><td>0.127274</td></tr><tr><th>std</th><td>3.998976e-01</td><td>3.500240e-01</td><td>2.938631e-01</td><td>2.728023e-01</td><td>2.077128e-01</td><td>1.951842e-01</td><td>1.877104e-01</td><td>1.607670e-01</td><td>1.512707e-01</td><td>1.443772e-01</td><td>1.368790e-01</td><td>1.286192e-01</td><td>1.193301e-01</td><td>1.149758e-01</td><td>1.133507e-01</td><td>1.019259e-01</td><td>0.983462</td></tr><tr><th>min</th><td>-1.071795e+00</td><td>-9.429479e-01</td><td>-9.948314e-01</td><td>-7.103087e-01</td><td>-7.703987e-01</td><td>-5.340294e-01</td><td>-5.993766e-01</td><td>-5.870755e-01</td><td>-6.282818e-01</td><td>-4.902583e-01</td><td>-6.341045e-01</td><td>-5.906753e-01</td><td>-4.175153e-01</td><td>-4.310613e-01</td><td>-4.170535e-01</td><td>-3.601627e-01</td><td>-3.044000</td></tr><tr><th>25%</th><td>-2.804085e-01</td><td>-2.613727e-01</td><td>-2.090797e-01</td><td>-1.945196e-01</td><td>-1.315620e-01</td><td>-1.264097e-01</td><td>-1.236360e-01</td><td>-1.016452e-01</td><td>-9.662098e-02</td><td>-9.297088e-02</td><td>-8.202809e-02</td><td>-7.721868e-02</td><td>-7.139961e-02</td><td>-7.474073e-02</td><td>-7.709743e-02</td><td>-6.603914e-02</td><td>-0.348500</td></tr><tr><th>50%</th><td>-1.417104e-02</td><td>-1.277241e-02</td><td>2.112166e-02</td><td>-2.337401e-02</td><td>-5.122797e-03</td><td>-1.355336e-02</td><td>-1.747870e-04</td><td>-4.656359e-03</td><td>2.572054e-03</td><td>-1.479172e-03</td><td>7.286444e-03</td><td>-5.745946e-03</td><td>-4.140670e-03</td><td>1.054915e-03</td><td>-1.758387e-03</td><td>-7.533392e-04</td><td>0.313000</td></tr><tr><th>75%</th><td>2.287306e-01</td><td>2.317720e-01</td><td>2.069571e-01</td><td>1.657590e-01</td><td>1.281660e-01</td><td>9.993122e-02</td><td>1.272081e-01</td><td>9.657222e-02</td><td>1.002626e-01</td><td>9.059634e-02</td><td>8.833765e-02</td><td>7.148033e-02</td><td>6.786199e-02</td><td>7.574868e-02</td><td>7.116829e-02</td><td>6.357449e-02</td><td>0.794250</td></tr><tr><th>max</th><td>1.597730e+00</td><td>1.382802e+00</td><td>1.010250e+00</td><td>1.448007e+00</td><td>1.034061e+00</td><td>1.358962e+00</td><td>6.191589e-01</td><td>7.370089e-01</td><td>6.449125e-01</td><td>5.839586e-01</td><td>6.405187e-01</td><td>6.780732e-01</td><td>5.156118e-01</td><td>4.978126e-01</td><td>4.673189e-01</td><td>4.570870e-01</td><td>2.538000</td></tr></tbody></table></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>...</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2886.000000</td><td>2884.000000</td></tr><tr><th>mean</th><td>0.690633</td><td>0.735633</td><td>0.593844</td><td>0.606212</td><td>0.639787</td><td>0.607649</td><td>0.735477</td><td>0.741354</td><td>0.702053</td><td>0.821897</td><td>...</td><td>0.401631</td><td>0.634466</td><td>0.760495</td><td>0.632231</td><td>0.459302</td><td>0.484489</td><td>0.734944</td><td>0.336235</td><td>0.527608</td><td>0.127274</td></tr><tr><th>std</th><td>0.143740</td><td>0.133703</td><td>0.145844</td><td>0.151311</td><td>0.119504</td><td>0.193887</td><td>0.141896</td><td>0.137154</td><td>0.129098</td><td>0.108362</td><td>...</td><td>0.141594</td><td>0.124279</td><td>0.110938</td><td>0.139037</td><td>0.099799</td><td>0.101365</td><td>0.122840</td><td>0.123663</td><td>0.153192</td><td>0.983462</td></tr><tr><th>min</th><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>...</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>-3.044000</td></tr><tr><th>25%</th><td>0.626239</td><td>0.695703</td><td>0.497759</td><td>0.515087</td><td>0.586328</td><td>0.497566</td><td>0.659249</td><td>0.682314</td><td>0.653489</td><td>0.794789</td><td>...</td><td>0.300053</td><td>0.587132</td><td>0.722593</td><td>0.565757</td><td>0.409037</td><td>0.454490</td><td>0.685279</td><td>0.279792</td><td>0.427036</td><td>-0.348500</td></tr><tr><th>50%</th><td>0.727153</td><td>0.766335</td><td>0.609155</td><td>0.609855</td><td>0.652873</td><td>0.642456</td><td>0.767192</td><td>0.774189</td><td>0.728557</td><td>0.846181</td><td>...</td><td>0.385611</td><td>0.633894</td><td>0.782330</td><td>0.634770</td><td>0.454518</td><td>0.499949</td><td>0.755580</td><td>0.349860</td><td>0.519457</td><td>0.313000</td></tr><tr><th>75%</th><td>0.783922</td><td>0.812642</td><td>0.694422</td><td>0.714096</td><td>0.712152</td><td>0.759266</td><td>0.835690</td><td>0.837030</td><td>0.781029</td><td>0.846181</td><td>...</td><td>0.488121</td><td>0.694136</td><td>0.824949</td><td>0.714950</td><td>0.504261</td><td>0.511365</td><td>0.785260</td><td>0.414447</td><td>0.621870</td><td>0.794250</td></tr><tr><th>max</th><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>...</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>2.538000</td></tr></tbody></table><p>8 rows × 39 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#PCA方法降维</span><br><span class="hljs-comment">#保留16个主成分</span><br>pca = PCA(n_components=<span class="hljs-number">16</span>)<br>new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:,<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>])<br>new_test_pca_16 = pca.transform(test_data_scaler)<br>new_train_pca_16 = pd.DataFrame(new_train_pca_16)<br>new_test_pca_16 = pd.DataFrame(new_test_pca_16)<br>new_train_pca_16[<span class="hljs-string">&#x27;target&#x27;</span>] = train_data_scaler[<span class="hljs-string">&#x27;target&#x27;</span>]<br><br>display(new_train_pca_16.describe())<br>display(new_test_pca_16.describe())<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2.886000e+03</td><td>2884.000000</td></tr><tr><th>mean</th><td>-8.025530e-17</td><td>9.902951e-17</td><td>2.481268e-17</td><td>-9.296098e-17</td><td>6.399362e-17</td><td>-2.711122e-17</td><td>8.112207e-17</td><td>3.819036e-17</td><td>-6.028134e-17</td><td>7.289445e-17</td><td>1.754800e-17</td><td>1.437164e-16</td><td>-1.772471e-17</td><td>-4.583132e-17</td><td>-4.687240e-18</td><td>1.133413e-16</td><td>0.127274</td></tr><tr><th>std</th><td>3.998976e-01</td><td>3.500240e-01</td><td>2.938631e-01</td><td>2.728023e-01</td><td>2.077128e-01</td><td>1.951842e-01</td><td>1.877104e-01</td><td>1.607670e-01</td><td>1.512707e-01</td><td>1.443772e-01</td><td>1.368790e-01</td><td>1.286192e-01</td><td>1.193301e-01</td><td>1.149758e-01</td><td>1.133504e-01</td><td>1.019258e-01</td><td>0.983462</td></tr><tr><th>min</th><td>-1.071795e+00</td><td>-9.429479e-01</td><td>-9.948314e-01</td><td>-7.103086e-01</td><td>-7.703992e-01</td><td>-5.340298e-01</td><td>-5.993763e-01</td><td>-5.870643e-01</td><td>-6.282915e-01</td><td>-4.902772e-01</td><td>-6.340438e-01</td><td>-5.906787e-01</td><td>-4.175381e-01</td><td>-4.310506e-01</td><td>-4.168836e-01</td><td>-3.602406e-01</td><td>-3.044000</td></tr><tr><th>25%</th><td>-2.804085e-01</td><td>-2.613727e-01</td><td>-2.090798e-01</td><td>-1.945196e-01</td><td>-1.315621e-01</td><td>-1.264102e-01</td><td>-1.236360e-01</td><td>-1.016531e-01</td><td>-9.661879e-02</td><td>-9.296451e-02</td><td>-8.202614e-02</td><td>-7.723983e-02</td><td>-7.137032e-02</td><td>-7.476121e-02</td><td>-7.689358e-02</td><td>-6.605108e-02</td><td>-0.348500</td></tr><tr><th>50%</th><td>-1.417105e-02</td><td>-1.277241e-02</td><td>2.112167e-02</td><td>-2.337400e-02</td><td>-5.122561e-03</td><td>-1.355336e-02</td><td>-1.746698e-04</td><td>-4.655969e-03</td><td>2.574279e-03</td><td>-1.483695e-03</td><td>7.272187e-03</td><td>-5.778147e-03</td><td>-4.141567e-03</td><td>1.056716e-03</td><td>-1.924285e-03</td><td>-7.935672e-04</td><td>0.313000</td></tr><tr><th>75%</th><td>2.287306e-01</td><td>2.317720e-01</td><td>2.069571e-01</td><td>1.657590e-01</td><td>1.281662e-01</td><td>9.993117e-02</td><td>1.272076e-01</td><td>9.657352e-02</td><td>1.002620e-01</td><td>9.059130e-02</td><td>8.833726e-02</td><td>7.147819e-02</td><td>6.780737e-02</td><td>7.573818e-02</td><td>7.113472e-02</td><td>6.362983e-02</td><td>0.794250</td></tr><tr><th>max</th><td>1.597730e+00</td><td>1.382802e+00</td><td>1.010250e+00</td><td>1.448007e+00</td><td>1.034058e+00</td><td>1.358961e+00</td><td>6.191591e-01</td><td>7.370478e-01</td><td>6.449824e-01</td><td>5.839721e-01</td><td>6.405928e-01</td><td>6.781944e-01</td><td>5.156549e-01</td><td>4.978232e-01</td><td>4.677552e-01</td><td>4.569075e-01</td><td>2.538000</td></tr></tbody></table></div><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><th>count</th><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td></tr><tr><th>mean</th><td>0.381177</td><td>0.081992</td><td>0.281879</td><td>-0.197930</td><td>-0.100701</td><td>-0.142780</td><td>0.004071</td><td>-0.060480</td><td>-0.154322</td><td>0.086993</td><td>-0.100815</td><td>0.046543</td><td>0.019935</td><td>0.165712</td><td>-0.091402</td><td>0.098503</td></tr><tr><th>std</th><td>0.476428</td><td>0.401721</td><td>0.286971</td><td>0.469295</td><td>0.247697</td><td>0.240629</td><td>0.181197</td><td>0.182679</td><td>0.205765</td><td>0.194124</td><td>0.169021</td><td>0.150554</td><td>0.186972</td><td>0.133136</td><td>0.113115</td><td>0.156939</td></tr><tr><th>min</th><td>-0.669864</td><td>-0.811128</td><td>-0.867655</td><td>-1.464873</td><td>-0.835855</td><td>-0.885696</td><td>-0.598268</td><td>-1.178334</td><td>-1.263819</td><td>-0.551279</td><td>-0.907768</td><td>-0.552060</td><td>-0.647384</td><td>-0.249090</td><td>-0.530208</td><td>-0.404869</td></tr><tr><th>25%</th><td>0.038180</td><td>-0.212454</td><td>0.115846</td><td>-0.574960</td><td>-0.255649</td><td>-0.276799</td><td>-0.115316</td><td>-0.174018</td><td>-0.310445</td><td>-0.047362</td><td>-0.204719</td><td>-0.060321</td><td>-0.107933</td><td>0.071293</td><td>-0.168086</td><td>-0.011253</td></tr><tr><th>50%</th><td>0.287710</td><td>0.014673</td><td>0.282676</td><td>-0.087425</td><td>-0.125262</td><td>-0.150075</td><td>0.003478</td><td>-0.053806</td><td>-0.175642</td><td>0.107260</td><td>-0.107033</td><td>0.036827</td><td>0.034512</td><td>0.148576</td><td>-0.087650</td><td>0.084981</td></tr><tr><th>75%</th><td>0.684349</td><td>0.348803</td><td>0.478167</td><td>0.170079</td><td>0.031784</td><td>-0.028064</td><td>0.116061</td><td>0.062062</td><td>-0.015697</td><td>0.235243</td><td>0.002403</td><td>0.142344</td><td>0.149126</td><td>0.261064</td><td>-0.018204</td><td>0.207740</td></tr><tr><th>max</th><td>2.265144</td><td>1.727923</td><td>1.228726</td><td>1.300934</td><td>0.893993</td><td>1.232575</td><td>0.635610</td><td>0.468097</td><td>0.639576</td><td>0.758273</td><td>0.691010</td><td>0.793413</td><td>0.627588</td><td>0.665948</td><td>0.301437</td><td>0.631095</td></tr></tbody></table></div><h1 id="模型初步训练">5模型初步训练</h1><h2 id="切分数据集">切分数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <span class="hljs-comment"># 切分数据</span><br><br><span class="hljs-comment">#采用 pca 保留16维特征的数据</span><br>new_train_pca_16 = new_train_pca_16.fillna(<span class="hljs-number">0</span>) <span class="hljs-comment"># 缺失值填充为0</span><br>train = new_train_pca_16[new_test_pca_16.columns] <span class="hljs-comment"># 特征</span><br>target = new_train_pca_16[<span class="hljs-string">&#x27;target&#x27;</span>] <span class="hljs-comment"># 标签</span><br><br><span class="hljs-comment"># 切分数据 训练数据80% 验证数据20%</span><br>train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p><code>train_data,test_data,train_target,test_target</code> 顺序一定不能错，依次为：训练集特征、测试集特征、训练集标签、测试集标签</p><h2 id="多元线性回归模型">5.1 多元线性回归模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression  <span class="hljs-comment">#线性回归</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error <span class="hljs-comment">#评价指标</span><br><br>clf = LinearRegression()<br>clf.fit(train_data, train_target)<br>test_pred = clf.predict(test_data)<br>score = mean_squared_error(test_target, test_pred)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;LinearRegression:   &quot;</span>, score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">LinearRegression:    0.27167848406515294</code></pre><h4 id="代码详解-4">代码详解：</h4><p><code>mean_squared_error</code>是一个用于计算均方误差（Mean Squared Error, MSE）的函数。它衡量了预测值与真实值之间的平均平方差。</p><p>函数语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mean_squared_error(y_true, y_pred, squared=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>y_true</code>：真实的目标变量值，也就是真实的标签值。</li><li><code>y_pred</code>：预测的目标变量值，也就是模型的预测结果。</li><li><code>squared</code>：可选参数，默认为<code>True</code>。如果设置为<code>False</code>，将返回均方根误差（RMSE），即平方根值。</li></ul><p>函数返回一个浮点数，表示计算得到的均方误差或均方根误差。</p><h2 id="k近邻回归">5.2 K近邻回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor  <span class="hljs-comment">#K近邻回归</span><br><br>clf = KNeighborsRegressor(n_neighbors=<span class="hljs-number">3</span>) <span class="hljs-comment"># 3个聚类</span><br>clf.fit(train_data, train_target)<br>score = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;KNeighborsRegressor:   &quot;</span>, score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">KNeighborsRegressor:    0.2677332937331796</code></pre><h2 id="决策树回归">5.3 决策树回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor     <span class="hljs-comment">#决策树回归</span><br><br>clf = DecisionTreeRegressor() <br>clf.fit(train_data, train_target)<br>score = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;DecisionTreeRegressor:   &quot;</span>, score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">DecisionTreeRegressor:    0.5939244757785467</code></pre><h2 id="随机森林回归">5.4 随机森林回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor <span class="hljs-comment">#随机森林回归</span><br><br>clf = RandomForestRegressor(n_estimators=<span class="hljs-number">200</span>) <span class="hljs-comment"># 200棵树模型</span><br>clf.fit(train_data, train_target)<br>score = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RandomForestRegressor:   &quot;</span>, score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">RandomForestRegressor:    0.2512481316266003</code></pre></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>工业蒸汽预测-03特征工程</div><div>https://zhou1317fe5.github.io/2023/07/31/工业蒸汽预测-03特征工程/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年7月31日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/08/01/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-04%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/" title="工业蒸汽预测-04模型训练"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">工业蒸汽预测-04模型训练</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/07/29/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-02%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/" title="工业蒸汽预测-02数据探索"><span class="hidden-mobile">工业蒸汽预测-02数据探索</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>