<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="1导入数据探索的工具包 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns # 数据可视化。其中boxplot用于绘制箱形图from scipy import statsimport warningswarnings.filterwarning"><meta property="og:type" content="article"><meta property="og:title" content="工业蒸汽预测-02数据探索"><meta property="og:url" content="https://zhou1317fe5.github.io/2023/07/29/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-02%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="1导入数据探索的工具包 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns # 数据可视化。其中boxplot用于绘制箱形图from scipy import statsimport warningswarnings.filterwarning"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-02%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_20_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_23_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_28_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_31_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_35_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_38_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_40_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_45_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_46_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_52_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_54_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_58_0.png"><meta property="og:image" content="c:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/1.png"><meta property="og:image" content="c:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/2.png"><meta property="og:image" content="c:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/3.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_60_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_75_0.png"><meta property="og:image" content="c:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/4.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%2002%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_79_0.png"><meta property="article:published_time" content="2023-07-29T02:13:04.000Z"><meta property="article:modified_time" content="2023-07-29T02:26:25.437Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-02%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/output_20_1.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>工业蒸汽预测-02数据探索 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="工业蒸汽预测-02数据探索"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-07-29 10:13" pubdate>2023年7月29日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 35k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 295 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">工业蒸汽预测-02数据探索</h1><div class="markdown-body"><h2 id="导入数据探索的工具包">1导入数据探索的工具包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns <span class="hljs-comment"># 数据可视化。其中boxplot用于绘制箱形图</span><br><br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br> <br>%matplotlib inline<br></code></pre></td></tr></table></figure><h2 id="读取数据">2读取数据</h2><p>使用Pandas库<code>read_csv()</code>函数进行数据读取，由于读取的是文本文件(.txt)，需要设置分割符为‘</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data_file = <span class="hljs-string">&quot;./data/zhengqi_train.txt&quot;</span><br>test_data_file =  <span class="hljs-string">&quot;./data/zhengqi_test.txt&quot;</span><br><br>train_data = pd.read_csv(train_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>test_data = pd.read_csv(test_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="查看数据信息">3查看数据信息</h2><h3 id="查看数据基本信息">3.1查看数据基本信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练集</span><br>train_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 2888 entries, 0 to 2887
Data columns (total 39 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   V0      2888 non-null   float64
 1   V1      2888 non-null   float64
 2   V2      2888 non-null   float64
 3   V3      2888 non-null   float64
 4   V4      2888 non-null   float64
 5   V5      2888 non-null   float64
 6   V6      2888 non-null   float64
 7   V7      2888 non-null   float64
 8   V8      2888 non-null   float64
 9   V9      2888 non-null   float64
 10  V10     2888 non-null   float64
 11  V11     2888 non-null   float64
 12  V12     2888 non-null   float64
 13  V13     2888 non-null   float64
 14  V14     2888 non-null   float64
 15  V15     2888 non-null   float64
 16  V16     2888 non-null   float64
 17  V17     2888 non-null   float64
 18  V18     2888 non-null   float64
 19  V19     2888 non-null   float64
 20  V20     2888 non-null   float64
 21  V21     2888 non-null   float64
 22  V22     2888 non-null   float64
 23  V23     2888 non-null   float64
 24  V24     2888 non-null   float64
 25  V25     2888 non-null   float64
 26  V26     2888 non-null   float64
 27  V27     2888 non-null   float64
 28  V28     2888 non-null   float64
 29  V29     2888 non-null   float64
 30  V30     2888 non-null   float64
 31  V31     2888 non-null   float64
 32  V32     2888 non-null   float64
 33  V33     2888 non-null   float64
 34  V34     2888 non-null   float64
 35  V35     2888 non-null   float64
 36  V36     2888 non-null   float64
 37  V37     2888 non-null   float64
 38  target  2888 non-null   float64
dtypes: float64(39)
memory usage: 880.1 KB</code></pre><ol type="1"><li>此训练集数据共有2888个样本，数据中有V0-V37共计38个特征变量，变量类型都为数值类型，所有数据特征没有缺失值数据；</li><li>数据字段由于采用了脱敏处理，删除了特征数据的具体含义；</li><li>target字段为标签变量</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 测试集</span><br>test_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1925 entries, 0 to 1924
Data columns (total 38 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   V0      1925 non-null   float64
 1   V1      1925 non-null   float64
 2   V2      1925 non-null   float64
 3   V3      1925 non-null   float64
 4   V4      1925 non-null   float64
 5   V5      1925 non-null   float64
 6   V6      1925 non-null   float64
 7   V7      1925 non-null   float64
 8   V8      1925 non-null   float64
 9   V9      1925 non-null   float64
 10  V10     1925 non-null   float64
 11  V11     1925 non-null   float64
 12  V12     1925 non-null   float64
 13  V13     1925 non-null   float64
 14  V14     1925 non-null   float64
 15  V15     1925 non-null   float64
 16  V16     1925 non-null   float64
 17  V17     1925 non-null   float64
 18  V18     1925 non-null   float64
 19  V19     1925 non-null   float64
 20  V20     1925 non-null   float64
 21  V21     1925 non-null   float64
 22  V22     1925 non-null   float64
 23  V23     1925 non-null   float64
 24  V24     1925 non-null   float64
 25  V25     1925 non-null   float64
 26  V26     1925 non-null   float64
 27  V27     1925 non-null   float64
 28  V28     1925 non-null   float64
 29  V29     1925 non-null   float64
 30  V30     1925 non-null   float64
 31  V31     1925 non-null   float64
 32  V32     1925 non-null   float64
 33  V33     1925 non-null   float64
 34  V34     1925 non-null   float64
 35  V35     1925 non-null   float64
 36  V36     1925 non-null   float64
 37  V37     1925 non-null   float64
dtypes: float64(38)
memory usage: 571.6 KB</code></pre><ol type="1"><li>测试集数据共有1925个样本，数据中有V0-V37共计38个特征变量，变量类型都为数值类型，无缺失值。</li><li>测试集中没有target字段（标签变量），需要我们预测并提交。</li></ol><h3 id="查看数据统计信息">3.2查看数据统计信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练集</span><br>train_data.describe()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>count</th><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>...</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td><td>2888.000000</td></tr><tr><th>mean</th><td>0.123048</td><td>0.056068</td><td>0.289720</td><td>-0.067790</td><td>0.012921</td><td>-0.558565</td><td>0.182892</td><td>0.116155</td><td>0.177856</td><td>-0.169452</td><td>...</td><td>0.097648</td><td>0.055477</td><td>0.127791</td><td>0.020806</td><td>0.007801</td><td>0.006715</td><td>0.197764</td><td>0.030658</td><td>-0.130330</td><td>0.126353</td></tr><tr><th>std</th><td>0.928031</td><td>0.941515</td><td>0.911236</td><td>0.970298</td><td>0.888377</td><td>0.517957</td><td>0.918054</td><td>0.955116</td><td>0.895444</td><td>0.953813</td><td>...</td><td>1.061200</td><td>0.901934</td><td>0.873028</td><td>0.902584</td><td>1.006995</td><td>1.003291</td><td>0.985675</td><td>0.970812</td><td>1.017196</td><td>0.983966</td></tr><tr><th>min</th><td>-4.335000</td><td>-5.122000</td><td>-3.420000</td><td>-3.956000</td><td>-4.742000</td><td>-2.182000</td><td>-4.576000</td><td>-5.048000</td><td>-4.692000</td><td>-12.891000</td><td>...</td><td>-2.912000</td><td>-4.507000</td><td>-5.859000</td><td>-4.053000</td><td>-4.627000</td><td>-4.789000</td><td>-5.695000</td><td>-2.608000</td><td>-3.630000</td><td>-3.044000</td></tr><tr><th>25%</th><td>-0.297000</td><td>-0.226250</td><td>-0.313000</td><td>-0.652250</td><td>-0.385000</td><td>-0.853000</td><td>-0.310000</td><td>-0.295000</td><td>-0.159000</td><td>-0.390000</td><td>...</td><td>-0.664000</td><td>-0.283000</td><td>-0.170250</td><td>-0.407250</td><td>-0.499000</td><td>-0.290000</td><td>-0.202500</td><td>-0.413000</td><td>-0.798250</td><td>-0.350250</td></tr><tr><th>50%</th><td>0.359000</td><td>0.272500</td><td>0.386000</td><td>-0.044500</td><td>0.110000</td><td>-0.466000</td><td>0.388000</td><td>0.344000</td><td>0.362000</td><td>0.042000</td><td>...</td><td>-0.023000</td><td>0.053500</td><td>0.299500</td><td>0.039000</td><td>-0.040000</td><td>0.160000</td><td>0.364000</td><td>0.137000</td><td>-0.185500</td><td>0.313000</td></tr><tr><th>75%</th><td>0.726000</td><td>0.599000</td><td>0.918250</td><td>0.624000</td><td>0.550250</td><td>-0.154000</td><td>0.831250</td><td>0.782250</td><td>0.726000</td><td>0.042000</td><td>...</td><td>0.745250</td><td>0.488000</td><td>0.635000</td><td>0.557000</td><td>0.462000</td><td>0.273000</td><td>0.602000</td><td>0.644250</td><td>0.495250</td><td>0.793250</td></tr><tr><th>max</th><td>2.121000</td><td>1.918000</td><td>2.828000</td><td>2.457000</td><td>2.689000</td><td>0.489000</td><td>1.895000</td><td>1.918000</td><td>2.245000</td><td>1.335000</td><td>...</td><td>4.580000</td><td>2.689000</td><td>2.013000</td><td>2.395000</td><td>5.465000</td><td>5.110000</td><td>2.324000</td><td>5.238000</td><td>3.000000</td><td>2.538000</td></tr></tbody></table><p>8 rows × 39 columns</p></div><p>上面数据显示了数据的统计信息，例如样本数count，数据的平均值mean，标准差std，最小值min，最大值max等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 测试集</span><br>test_data.describe()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V28</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>count</th><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>...</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td><td>1925.000000</td></tr><tr><th>mean</th><td>-0.184404</td><td>-0.083912</td><td>-0.434762</td><td>0.101671</td><td>-0.019172</td><td>0.838049</td><td>-0.274092</td><td>-0.173971</td><td>-0.266709</td><td>0.255114</td><td>...</td><td>-0.206871</td><td>-0.146463</td><td>-0.083215</td><td>-0.191729</td><td>-0.030782</td><td>-0.011433</td><td>-0.009985</td><td>-0.296895</td><td>-0.046270</td><td>0.195735</td></tr><tr><th>std</th><td>1.073333</td><td>1.076670</td><td>0.969541</td><td>1.034925</td><td>1.147286</td><td>0.963043</td><td>1.054119</td><td>1.040101</td><td>1.085916</td><td>1.014394</td><td>...</td><td>1.064140</td><td>0.880593</td><td>1.126414</td><td>1.138454</td><td>1.130228</td><td>0.989732</td><td>0.995213</td><td>0.946896</td><td>1.040854</td><td>0.940599</td></tr><tr><th>min</th><td>-4.814000</td><td>-5.488000</td><td>-4.283000</td><td>-3.276000</td><td>-4.921000</td><td>-1.168000</td><td>-5.649000</td><td>-5.625000</td><td>-6.059000</td><td>-6.784000</td><td>...</td><td>-2.435000</td><td>-2.413000</td><td>-4.507000</td><td>-7.698000</td><td>-4.057000</td><td>-4.627000</td><td>-4.789000</td><td>-7.477000</td><td>-2.608000</td><td>-3.346000</td></tr><tr><th>25%</th><td>-0.664000</td><td>-0.451000</td><td>-0.978000</td><td>-0.644000</td><td>-0.497000</td><td>0.122000</td><td>-0.732000</td><td>-0.509000</td><td>-0.775000</td><td>-0.390000</td><td>...</td><td>-0.453000</td><td>-0.818000</td><td>-0.339000</td><td>-0.476000</td><td>-0.472000</td><td>-0.460000</td><td>-0.290000</td><td>-0.349000</td><td>-0.593000</td><td>-0.432000</td></tr><tr><th>50%</th><td>0.065000</td><td>0.195000</td><td>-0.267000</td><td>0.220000</td><td>0.118000</td><td>0.437000</td><td>-0.082000</td><td>0.018000</td><td>-0.004000</td><td>0.401000</td><td>...</td><td>-0.445000</td><td>-0.199000</td><td>0.010000</td><td>0.100000</td><td>0.155000</td><td>-0.040000</td><td>0.160000</td><td>-0.270000</td><td>0.083000</td><td>0.152000</td></tr><tr><th>75%</th><td>0.549000</td><td>0.589000</td><td>0.278000</td><td>0.793000</td><td>0.610000</td><td>1.928000</td><td>0.457000</td><td>0.515000</td><td>0.482000</td><td>0.904000</td><td>...</td><td>-0.434000</td><td>0.468000</td><td>0.447000</td><td>0.471000</td><td>0.627000</td><td>0.419000</td><td>0.273000</td><td>0.364000</td><td>0.651000</td><td>0.797000</td></tr><tr><th>max</th><td>2.100000</td><td>2.120000</td><td>1.946000</td><td>2.603000</td><td>4.475000</td><td>3.176000</td><td>1.528000</td><td>1.394000</td><td>2.408000</td><td>1.766000</td><td>...</td><td>4.656000</td><td>3.022000</td><td>3.139000</td><td>1.428000</td><td>2.299000</td><td>5.465000</td><td>5.110000</td><td>1.671000</td><td>2.861000</td><td>3.021000</td></tr></tbody></table><p>8 rows × 38 columns</p></div><h3 id="查看数据字段信息">3.3查看数据字段信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>0</th><td>0.566</td><td>0.016</td><td>-0.143</td><td>0.407</td><td>0.452</td><td>-0.901</td><td>-1.812</td><td>-2.360</td><td>-0.436</td><td>-2.114</td><td>...</td><td>0.136</td><td>0.109</td><td>-0.615</td><td>0.327</td><td>-4.627</td><td>-4.789</td><td>-5.101</td><td>-2.608</td><td>-3.508</td><td>0.175</td></tr><tr><th>1</th><td>0.968</td><td>0.437</td><td>0.066</td><td>0.566</td><td>0.194</td><td>-0.893</td><td>-1.566</td><td>-2.360</td><td>0.332</td><td>-2.114</td><td>...</td><td>-0.128</td><td>0.124</td><td>0.032</td><td>0.600</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>-0.335</td><td>-0.730</td><td>0.676</td></tr><tr><th>2</th><td>1.013</td><td>0.568</td><td>0.235</td><td>0.370</td><td>0.112</td><td>-0.797</td><td>-1.367</td><td>-2.360</td><td>0.396</td><td>-2.114</td><td>...</td><td>-0.009</td><td>0.361</td><td>0.277</td><td>-0.116</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>0.765</td><td>-0.589</td><td>0.633</td></tr><tr><th>3</th><td>0.733</td><td>0.368</td><td>0.283</td><td>0.165</td><td>0.599</td><td>-0.679</td><td>-1.200</td><td>-2.086</td><td>0.403</td><td>-2.114</td><td>...</td><td>0.015</td><td>0.417</td><td>0.279</td><td>0.603</td><td>-0.843</td><td>-0.065</td><td>0.364</td><td>0.333</td><td>-0.112</td><td>0.206</td></tr><tr><th>4</th><td>0.684</td><td>0.638</td><td>0.260</td><td>0.209</td><td>0.337</td><td>-0.454</td><td>-1.073</td><td>-2.086</td><td>0.314</td><td>-2.114</td><td>...</td><td>0.183</td><td>1.078</td><td>0.328</td><td>0.418</td><td>-0.843</td><td>-0.215</td><td>0.364</td><td>-0.280</td><td>-0.028</td><td>0.384</td></tr></tbody></table><p>5 rows × 39 columns</p></div><p>上面显示训练集前5条数据的基本信息，可以看到数据都是浮点型数据，数据都是数值型连续型特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_data.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V28</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>0</th><td>0.368</td><td>0.380</td><td>-0.225</td><td>-0.049</td><td>0.379</td><td>0.092</td><td>0.550</td><td>0.551</td><td>0.244</td><td>0.904</td><td>...</td><td>-0.449</td><td>0.047</td><td>0.057</td><td>-0.042</td><td>0.847</td><td>0.534</td><td>-0.009</td><td>-0.190</td><td>-0.567</td><td>0.388</td></tr><tr><th>1</th><td>0.148</td><td>0.489</td><td>-0.247</td><td>-0.049</td><td>0.122</td><td>-0.201</td><td>0.487</td><td>0.493</td><td>-0.127</td><td>0.904</td><td>...</td><td>-0.443</td><td>0.047</td><td>0.560</td><td>0.176</td><td>0.551</td><td>0.046</td><td>-0.220</td><td>0.008</td><td>-0.294</td><td>0.104</td></tr><tr><th>2</th><td>-0.166</td><td>-0.062</td><td>-0.311</td><td>0.046</td><td>-0.055</td><td>0.063</td><td>0.485</td><td>0.493</td><td>-0.227</td><td>0.904</td><td>...</td><td>-0.458</td><td>-0.398</td><td>0.101</td><td>0.199</td><td>0.634</td><td>0.017</td><td>-0.234</td><td>0.008</td><td>0.373</td><td>0.569</td></tr><tr><th>3</th><td>0.102</td><td>0.294</td><td>-0.259</td><td>0.051</td><td>-0.183</td><td>0.148</td><td>0.474</td><td>0.504</td><td>0.010</td><td>0.904</td><td>...</td><td>-0.456</td><td>-0.398</td><td>1.007</td><td>0.137</td><td>1.042</td><td>-0.040</td><td>-0.290</td><td>0.008</td><td>-0.666</td><td>0.391</td></tr><tr><th>4</th><td>0.300</td><td>0.428</td><td>0.208</td><td>0.051</td><td>-0.033</td><td>0.116</td><td>0.408</td><td>0.497</td><td>0.155</td><td>0.904</td><td>...</td><td>-0.458</td><td>-0.776</td><td>0.291</td><td>0.370</td><td>0.181</td><td>-0.040</td><td>-0.290</td><td>0.008</td><td>-0.140</td><td>-0.497</td></tr></tbody></table><p>5 rows × 38 columns</p></div><h2 id="可视化数据分布">4可视化数据分布</h2><h3 id="箱形图">4.1箱形图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先绘制训练集中特征变量V0的箱形图：</span><br>fig = plt.figure(figsize=(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>))  <span class="hljs-comment"># 指定绘图对象宽度和高度</span><br>sns.boxplot(train_data[<span class="hljs-string">&#x27;V0&#x27;</span>],orient=<span class="hljs-string">&quot;v&quot;</span>, width=<span class="hljs-number">0.5</span>) <br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;AxesSubplot:&gt;</code></pre><p><img src="/img/工业蒸汽预测-02数据探索/output_20_1.png" srcset="/img/loading.gif" lazyload></p><p>从图中可以看出有偏离值，许多数据点位于下四分位点以下。</p><p>代码详解：</p><ol type="1"><li><p><code>fig = plt.figure(figsize=(4, 6))</code> 创建一个画布，并指定宽度为4，高度为6。<code>plt</code> 是 matplotlib 库的一个模块，用于绘制数据可视化图形。</p></li><li><p><code>sns.boxplot(train_data['V0'],orient="v", width=0.5)</code> 绘制箱形图。<code>sns</code> 是 seaborn 库的一个模块，用于数据可视化。<code>boxplot</code> 是用于绘制箱形图的函数。<code>train_data['V0']</code> 表示从训练集中获取特征变量 V0 的数据进行绘制。<code>orient="v"</code> 表示将箱形图垂直绘制，即以竖直方向为主轴。<code>width=0.5</code> 表示箱形图的宽度为0.5。</p></li></ol><p>箱形图是一种用于展示数据分布和离群值的图形。它由一个矩形框和两条线（即“须”上限、下限）组成。矩形框表示数据的四分位数范围（上下四分位数之间的距离），中间的线表示中位数，须表示数据的整体分布情况。箱形图可以帮助我们观察数据的偏态、集中趋势以及离群值等信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># V0-V37的箱形图：</span><br>column = train_data.columns.tolist()[:<span class="hljs-number">39</span>]  <span class="hljs-comment"># 列表头,共39列，V0-target</span><br>fig = plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">40</span>))  <span class="hljs-comment"># 指定绘图对象宽度和高度</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">38</span>):<br>    plt.subplot(<span class="hljs-number">13</span>, <span class="hljs-number">3</span>, i + <span class="hljs-number">1</span>)  <span class="hljs-comment"># 13行3列子图</span><br>    sns.boxplot(train_data[column[i]], orient=<span class="hljs-string">&quot;h&quot;</span>, width=<span class="hljs-number">0.5</span>)  <span class="hljs-comment"># 箱式图</span><br>    plt.ylabel(column[i], fontsize=<span class="hljs-number">8</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽%2002数据探索/output_23_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>从图中发现数据存在许多偏离较大的异常值，可以考虑移除。</p><p>代码详解：</p><ol type="1"><li><p><code>column = train_data.columns.tolist()[:39]</code> 获取训练集数据中前39（包含）列（即V0到target）的列名，并将其存储在列表 <code>column</code> 中。<code>train_data.columns</code> 返回数据集的所有列名，<code>tolist()</code> 将其转换为列表，<code>[:39]</code> 表示取列表中的前39个元素。</p></li><li><p><code>fig = plt.figure(figsize=(20, 40))</code> 创建一个画布，并指定宽度为20，高度为40。</p></li><li><p><code>for i in range(38):</code> 循环遍历从0到37的整数，对应特征变量 V0 到 V37。</p></li><li><p><code>plt.subplot(13, 3, i + 1)</code> 创建一个子图，将画布分为13行3列的网格，选中当前子图(i+1)进行绘制。<code>i + 1</code> 表示子图的编号，从1开始。</p></li><li><p><code>sns.boxplot(train_data[column[i]], orient="h", width=0.5)</code> 绘制箱形图。<code>train_data[column[i]]</code> 表示从训练集中获取第i个特征变量的数据进行绘制。<code>orient="h"</code> 表示将箱形图水平绘制，即以水平方向为主轴。<code>width=0.5</code> 表示箱形图的宽度为0.5。</p></li><li><p><code>plt.ylabel(column[i], fontsize=8)</code> 在每个子图上添加y轴标签，标签内容为对应的特征变量名称 <code>column[i]</code>，并设置字体大小为8。</p></li><li><p><code>plt.show()</code> 展示绘制的箱形图。</p></li></ol><h3 id="直方图和q-q图">4.2直方图和Q-Q图</h3><p>Q-Q图是指数据的分位数和正态分布的分位数对比参照的图，如果数据符合正态分布，则所有的点都会落在直线上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看特征变量‘V0’的数据分布直方图，并绘制Q-Q图查看数据是否近似于正态分布</span><br><br>plt.figure(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">2.5</span>))<br><br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>sns.distplot(train_data[<span class="hljs-string">&#x27;V0&#x27;</span>],fit=stats.norm)<br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>res = stats.probplot(train_data[<span class="hljs-string">&#x27;V0&#x27;</span>], plot=plt)<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_28_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>可以看到，训练集中特征变量V0的分布不是正态分布。</p><p>代码详解：</p><ol type="1"><li><p><code>plt.figure(figsize=(10,5))</code> 创建一个宽度为10，高度为5的画布对象。<code>figsize=(10,5)</code> 指定了画布的尺寸。</p></li><li><p><code>ax=plt.subplot(1,2,1)</code> 创建一个子图对象，并指定它位于画布的第1行，第2列中。这里的 <code>(1,2,1)</code> 表示将画布分为1行2列的网格，并选中第1个位置的子图。</p></li><li><p><code>sns.distplot(train_data['V0'],fit=stats.norm)</code> 在第一个子图中绘制特征变量 'V0' 的直方图。<code>train_data['V0']</code> 表示从训练集中获取 'V0' 特征变量的数据进行绘制。<code>sns.distplot()</code> 是 seaborn 库中的函数，用于绘制直方图并拟合参数化的概率密度函数（默认为正态分布，通过 <code>fit=stats.norm</code> 指定，表示使用正态分布拟合）。</p></li><li><p><code>ax=plt.subplot(1,2,2)</code> 创建第二个子图，并指定它位于画布的第1行，第2列中。这里的 <code>(1,2,2)</code> 表示将画布分为1行2列的网格，并选中第2个位置的子图。</p></li><li><p><code>res = stats.probplot(train_data['V0'], plot=plt)</code> 在第二个子图中绘制特征变量 'V0' 的概率图。<code>stats.probplot()</code> 是 scipy 库（科学计算库）中的函数，用于绘制概率图。它可以判断数据是否符合某种理论分布（这里使用了默认的正态分布）。<code>plot=plt</code> 表示将概率图绘制在指定的子图上。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看所有数据的直方图和Q-Q图</span><br>train_cols = <span class="hljs-number">6</span> <span class="hljs-comment"># 画布列数</span><br>train_rows = <span class="hljs-built_in">len</span>(train_data.columns) <span class="hljs-comment"># 画布行数</span><br>plt.figure(figsize=(<span class="hljs-number">5</span>*train_cols,<span class="hljs-number">5</span>*train_rows))<br><br>i=<span class="hljs-number">0</span> <span class="hljs-comment"># 一次循环两个自增，所以初始为0</span><br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> train_data.columns:<br>    i+=<span class="hljs-number">1</span><br>    ax=plt.subplot(train_rows,train_cols,i)<br>    sns.distplot(train_data[col],fit=stats.norm)<br>    <br>    i+=<span class="hljs-number">1</span><br>    ax=plt.subplot(train_rows,train_cols,i)<br>    res = stats.probplot(train_data[col], plot=plt)<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_31_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>由上面的数据分布图信息可以看出，很多特征变量（如'V1','V9','V24','V28'等）的数据分布不是正态的，数据并不跟随对角线，后续可以使用数据变换对数据进行转换。</p><p>代码解释：</p><p>简单的图可以通过<code>plt.figure(figsize=(10, 5))</code>直接指定画布的大小。</p><p>在展示多个子图时，直接指定画布大小可能会导致子图之间的重叠或缺乏足够的空间来显示所有子图。从而导致布局混乱或信息重叠。</p><p>使用<code>plt.figure(figsize=(5*train_cols, 5*train_rows))</code>的方式更加灵活，它会自动根据数据集中的特征变量数量来计算所需的行数和列数，并相应地调整画布的大小。这样可以确保每个子图都有足够的空间进行展示，并且整体布局更加均衡和清晰。</p><h3 id="kde图">4.3KDE图</h3><p>KDE(Kernel Density Estimation,核密度估计)可以理解为是对直方图的加窗平滑。可以查看并对比训练集和测试集中特征变量的分布情况，发现两个数据集中分布不一致的特征变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对比同一特征变量‘V0’下，训练集数据和测试集数据的分布情况，查看数据分布是否一致</span><br>plt.figure(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">2.5</span>),dpi=<span class="hljs-number">150</span>)<br>ax = sns.kdeplot(train_data[<span class="hljs-string">&#x27;V0&#x27;</span>], color=<span class="hljs-string">&quot;Red&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>ax = sns.kdeplot(test_data[<span class="hljs-string">&#x27;V0&#x27;</span>], color=<span class="hljs-string">&quot;Blue&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;V0&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&quot;Frequency&quot;</span>)<br>ax = ax.legend([<span class="hljs-string">&quot;train&quot;</span>,<span class="hljs-string">&quot;test&quot;</span>])<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_35_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>可以看到，V0在两个数据集中的分布基本一致。</p><p>代码详解：</p><ol type="1"><li><p><code>plt.figure(figsize=(8,4), dpi=150)</code>：创建一个画布，指定尺寸为宽度8英寸，高度4英寸，dpi（每英寸像素点数）为150，数值越高质量越好，不指定有默认。</p></li><li><p><code>ax = sns.kdeplot(train_data['V0'], color="Red", shade=True)</code>：使用 Seaborn 库的 <code>kdeplot</code> 函数绘制训练数据集中特征变量 <code>'V0'</code> 的核密度估计曲线。<code>color="Red"</code> 指定曲线的颜色为红色，<code>shade=True</code> 表示曲线下方填充阴影以突出密度分布。</p></li><li><p><code>ax = sns.kdeplot(test_data['V0'], color="Blue", shade=True)</code>：类似地，使用 <code>kdeplot</code> 函数在同一图形上绘制测试数据集中特征变量 <code>'V0'</code> 的核密度估计曲线。这里设置曲线颜色为蓝色。</p></li><li><p><code>ax.set_xlabel('V0')</code>：设置 x 轴的标签为 <code>'V0'</code>。</p></li><li><p><code>ax.set_ylabel("Frequency")</code>：设置 y 轴的标签为 <code>'Frequency'</code>。</p></li><li><p><code>ax = ax.legend(["train","test"])</code>：添加图例。该语句首先通过 <code>ax.legend()</code> 方法在当前的轴对象 <code>ax</code> 上添加图例，然后使用 <code>["train", "test"]</code> 指定图例的标签。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看所有变量在训练集和测试集的KDE分布情况，分析并寻找出数据分布不一致的特征变量。</span><br>dist_cols = <span class="hljs-number">6</span><br>dist_rows = <span class="hljs-built_in">len</span>(test_data.columns)<br>plt.figure(figsize=(<span class="hljs-number">4</span>*dist_cols,<span class="hljs-number">4</span>*dist_rows))<br><br>i=<span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> test_data.columns:<br>    ax=plt.subplot(dist_rows,dist_cols,i)<br>    ax = sns.kdeplot(train_data[col], color=<span class="hljs-string">&quot;Red&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax = sns.kdeplot(test_data[col], color=<span class="hljs-string">&quot;Blue&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax.set_xlabel(col)<br>    ax.set_ylabel(<span class="hljs-string">&quot;Frequency&quot;</span>)<br>    ax = ax.legend([<span class="hljs-string">&quot;train&quot;</span>,<span class="hljs-string">&quot;test&quot;</span>])<br>    <br>    i+=<span class="hljs-number">1</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_38_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>可以发现，特征变量V5,V9,V11,V17,V22,V28在训练集与测试集中的分布不一致</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看特征V5,V9,V11,V17,V22,V28数据的数据分布</span><br>drop_col = <span class="hljs-number">6</span><br>drop_row = <span class="hljs-number">1</span><br><br>plt.figure(figsize=(<span class="hljs-number">5</span>*drop_col,<span class="hljs-number">5</span>*drop_row))<br><br>i=<span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;V5&quot;</span>,<span class="hljs-string">&quot;V9&quot;</span>,<span class="hljs-string">&quot;V11&quot;</span>,<span class="hljs-string">&quot;V17&quot;</span>,<span class="hljs-string">&quot;V22&quot;</span>,<span class="hljs-string">&quot;V28&quot;</span>]:<br>    ax =plt.subplot(drop_row,drop_col,i)<br>    ax = sns.kdeplot(train_data[col], color=<span class="hljs-string">&quot;Red&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax = sns.kdeplot(test_data[col], color=<span class="hljs-string">&quot;Blue&quot;</span>, shade=<span class="hljs-literal">True</span>)<br>    ax.set_xlabel(col)<br>    ax.set_ylabel(<span class="hljs-string">&quot;Frequency&quot;</span>)<br>    ax = ax.legend([<span class="hljs-string">&quot;train&quot;</span>,<span class="hljs-string">&quot;test&quot;</span>])<br>    <br>    i+=<span class="hljs-number">1</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_40_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>由上图的数据分布可以看到特征'V5','V9','V11','V17','V22','V28' 训练集数据与测试集数据分布不一致，会导致模型泛化能力差，采用删除此类特征方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">drop_columns = [<span class="hljs-string">&#x27;V5&#x27;</span>,<span class="hljs-string">&#x27;V9&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>,<span class="hljs-string">&#x27;V17&#x27;</span>,<span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V28&#x27;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#合并训练集和测试集数据，并可视化训练集和测试集数据特征分布图</span><br></code></pre></td></tr></table></figure><h3 id="线性回归关系图">4.4线性回归关系图</h3><p>线性回归关系图主要用于分析变量之间的线性回归关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看‘V0’与&#x27;target&#x27;变量的线性回归关系</span><br>fcols = <span class="hljs-number">2</span><br>frows = <span class="hljs-number">1</span><br>plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">4</span>))<br><br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>sns.regplot(x=<span class="hljs-string">&#x27;V0&#x27;</span>, y=<span class="hljs-string">&#x27;target&#x27;</span>, data=train_data, ax=ax, <br>            scatter_kws=&#123;<span class="hljs-string">&#x27;marker&#x27;</span>:<span class="hljs-string">&#x27;.&#x27;</span>,<span class="hljs-string">&#x27;s&#x27;</span>:<span class="hljs-number">3</span>,<span class="hljs-string">&#x27;alpha&#x27;</span>:<span class="hljs-number">0.3</span>&#125;,<br>            line_kws=&#123;<span class="hljs-string">&#x27;color&#x27;</span>:<span class="hljs-string">&#x27;k&#x27;</span>&#125;);<br>plt.xlabel(<span class="hljs-string">&#x27;V0&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;target&#x27;</span>)<br><br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>sns.distplot(train_data[<span class="hljs-string">&#x27;V0&#x27;</span>].dropna())<br>plt.xlabel(<span class="hljs-string">&#x27;V0&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_45_0.png" srcset="/img/loading.gif" lazyload> ​</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看所有特征变量与&#x27;target&#x27;变量的线性回归关系</span><br>fcols = <span class="hljs-number">6</span><br>frows = <span class="hljs-built_in">len</span>(test_data.columns)<br>plt.figure(figsize=(<span class="hljs-number">5</span>*fcols,<span class="hljs-number">4</span>*frows))<br><br>i=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> test_data.columns:<br>    i+=<span class="hljs-number">1</span><br>    ax=plt.subplot(frows,fcols,i)<br>    sns.regplot(x=col, y=<span class="hljs-string">&#x27;target&#x27;</span>, data=train_data, ax=ax, <br>                scatter_kws=&#123;<span class="hljs-string">&#x27;marker&#x27;</span>:<span class="hljs-string">&#x27;.&#x27;</span>,<span class="hljs-string">&#x27;s&#x27;</span>:<span class="hljs-number">3</span>,<span class="hljs-string">&#x27;alpha&#x27;</span>:<span class="hljs-number">0.3</span>&#125;,<br>                line_kws=&#123;<span class="hljs-string">&#x27;color&#x27;</span>:<span class="hljs-string">&#x27;k&#x27;</span>&#125;);<br>    plt.xlabel(col)<br>    plt.ylabel(<span class="hljs-string">&#x27;target&#x27;</span>)<br>    <br>    i+=<span class="hljs-number">1</span><br>    ax=plt.subplot(frows,fcols,i)<br>    sns.distplot(train_data[col].dropna())<br>    plt.xlabel(col)<br>    <br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_46_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>代码解释：</p><p>散点图： 使用 Seaborn 库中的 <code>regplot</code> 函数来绘制自变量 <code>col</code> 与因变量 <code>'target'</code> 之间的散点图，并拟合一条线性回归线。</p><ul><li><code>x=col</code> 表示自变量的数据是 <code>col</code>，即当前循环遍历到的特征变量。</li><li><code>y='target'</code> 表示因变量的数据是 <code>'target'</code>，即目标变量。</li><li><code>data=train_data</code> 表示数据集是 <code>train_data</code>，即训练数据集。</li><li><code>ax=ax</code> 表示将子图对象 <code>ax</code> 分配给 <code>regplot</code> 函数来绘制子图。</li><li><code>scatter_kws=&#123;'marker':'.','s':3,'alpha':0.3&#125;</code> 设置散点图的样式参数。这里使用了小圆点作为散点图的标记，设置了透明度（<code>alpha</code>）、大小（<code>s</code>）和颜色（默认颜色）。</li><li><code>line_kws=&#123;'color':'k'&#125;</code> 设置回归线的样式参数。这里将回归线的颜色设置为黑色（<code>'k'</code> 是黑色的简写）。</li></ul><p>直方图： <code>sns.distplot(train_data[col].dropna())</code>绘制特征变量 <code>col</code>的直方图和核密度估计曲线。<code>dropna()</code>函数用于移除其中的缺失值（NaN值）。</p><h2 id="查看特征变量的相关性">5查看特征变量的相关性</h2><p>对特征变量的相关性进行分析，可以发现特征变量和目标变量及特征变量之间的关系，为在特征工程中提取特征做准备。</p><h3 id="计算相关性系数">5.1计算相关性系数</h3><p>在删除训练集和测试集中分布不一致的特征变量，如V5,V9,V11,V17,V22,V28之后，计算剩余特征变量及taret变量的相关性系数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># pd.set_option (&#x27;display.max_columns&#x27;,10) # 显示最大列数，为10列，其他折叠起来</span><br><span class="hljs-comment"># pd.set_option(&#x27;display.max_rows&#x27;,10) # 显示最大行数，为10行，其他折叠起来</span><br><br>data_train1 = train_data.drop([<span class="hljs-string">&#x27;V5&#x27;</span>,<span class="hljs-string">&#x27;V9&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>,<span class="hljs-string">&#x27;V17&#x27;</span>,<span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V28&#x27;</span>],axis=<span class="hljs-number">1</span>)<br><br>train_corr = data_train1.corr()<br>train_corr<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V6</th><th>V7</th><th>V8</th><th>V10</th><th>V12</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>V0</th><td>1.000000</td><td>0.908607</td><td>0.463643</td><td>0.409576</td><td>0.781212</td><td>0.189267</td><td>0.141294</td><td>0.794013</td><td>0.298443</td><td>0.751830</td><td>...</td><td>0.302145</td><td>0.156968</td><td>0.675003</td><td>0.050951</td><td>0.056439</td><td>-0.019342</td><td>0.138933</td><td>0.231417</td><td>-0.494076</td><td>0.873212</td></tr><tr><th>V1</th><td>0.908607</td><td>1.000000</td><td>0.506514</td><td>0.383924</td><td>0.657790</td><td>0.276805</td><td>0.205023</td><td>0.874650</td><td>0.310120</td><td>0.656186</td><td>...</td><td>0.147096</td><td>0.175997</td><td>0.769745</td><td>0.085604</td><td>0.035129</td><td>-0.029115</td><td>0.146329</td><td>0.235299</td><td>-0.494043</td><td>0.871846</td></tr><tr><th>V2</th><td>0.463643</td><td>0.506514</td><td>1.000000</td><td>0.410148</td><td>0.057697</td><td>0.615938</td><td>0.477114</td><td>0.703431</td><td>0.346006</td><td>0.059941</td><td>...</td><td>-0.275764</td><td>0.175943</td><td>0.653764</td><td>0.033942</td><td>0.050309</td><td>-0.025620</td><td>0.043648</td><td>0.316462</td><td>-0.734956</td><td>0.638878</td></tr><tr><th>V3</th><td>0.409576</td><td>0.383924</td><td>0.410148</td><td>1.000000</td><td>0.315046</td><td>0.233896</td><td>0.197836</td><td>0.411946</td><td>0.321262</td><td>0.306397</td><td>...</td><td>0.117610</td><td>0.043966</td><td>0.421954</td><td>-0.092423</td><td>-0.007159</td><td>-0.031898</td><td>0.080034</td><td>0.324475</td><td>-0.229613</td><td>0.512074</td></tr><tr><th>V4</th><td>0.781212</td><td>0.657790</td><td>0.057697</td><td>0.315046</td><td>1.000000</td><td>-0.117529</td><td>-0.052370</td><td>0.449542</td><td>0.141129</td><td>0.927685</td><td>...</td><td>0.659093</td><td>0.022807</td><td>0.447016</td><td>-0.026186</td><td>0.062367</td><td>0.028659</td><td>0.100010</td><td>0.113609</td><td>-0.031054</td><td>0.603984</td></tr><tr><th>V6</th><td>0.189267</td><td>0.276805</td><td>0.615938</td><td>0.233896</td><td>-0.117529</td><td>1.000000</td><td>0.917502</td><td>0.468233</td><td>0.415660</td><td>-0.087312</td><td>...</td><td>-0.467980</td><td>0.188907</td><td>0.546535</td><td>0.144550</td><td>0.054210</td><td>-0.002914</td><td>0.044992</td><td>0.433804</td><td>-0.404817</td><td>0.370037</td></tr><tr><th>V7</th><td>0.141294</td><td>0.205023</td><td>0.477114</td><td>0.197836</td><td>-0.052370</td><td>0.917502</td><td>1.000000</td><td>0.389987</td><td>0.310982</td><td>-0.036791</td><td>...</td><td>-0.311363</td><td>0.170113</td><td>0.475254</td><td>0.122707</td><td>0.034508</td><td>-0.019103</td><td>0.111166</td><td>0.340479</td><td>-0.292285</td><td>0.287815</td></tr><tr><th>V8</th><td>0.794013</td><td>0.874650</td><td>0.703431</td><td>0.411946</td><td>0.449542</td><td>0.468233</td><td>0.389987</td><td>1.000000</td><td>0.419703</td><td>0.420557</td><td>...</td><td>-0.011091</td><td>0.150258</td><td>0.878072</td><td>0.038430</td><td>0.026843</td><td>-0.036297</td><td>0.179167</td><td>0.326586</td><td>-0.553121</td><td>0.831904</td></tr><tr><th>V10</th><td>0.298443</td><td>0.310120</td><td>0.346006</td><td>0.321262</td><td>0.141129</td><td>0.415660</td><td>0.310982</td><td>0.419703</td><td>1.000000</td><td>0.140462</td><td>...</td><td>-0.105042</td><td>-0.036705</td><td>0.560213</td><td>-0.093213</td><td>0.016739</td><td>-0.026994</td><td>0.026846</td><td>0.922190</td><td>-0.045851</td><td>0.394767</td></tr><tr><th>V12</th><td>0.751830</td><td>0.656186</td><td>0.059941</td><td>0.306397</td><td>0.927685</td><td>-0.087312</td><td>-0.036791</td><td>0.420557</td><td>0.140462</td><td>1.000000</td><td>...</td><td>0.666775</td><td>0.028866</td><td>0.441963</td><td>-0.007658</td><td>0.046674</td><td>0.010122</td><td>0.081963</td><td>0.112150</td><td>-0.054827</td><td>0.594189</td></tr><tr><th>V13</th><td>0.185144</td><td>0.157518</td><td>0.204762</td><td>-0.003636</td><td>0.075993</td><td>0.138367</td><td>0.110973</td><td>0.153299</td><td>-0.059553</td><td>0.098771</td><td>...</td><td>0.008235</td><td>0.027328</td><td>0.113743</td><td>0.130598</td><td>0.157513</td><td>0.116944</td><td>0.219906</td><td>-0.024751</td><td>-0.379714</td><td>0.203373</td></tr><tr><th>V14</th><td>-0.004144</td><td>-0.006268</td><td>-0.106282</td><td>-0.232677</td><td>0.023853</td><td>0.072911</td><td>0.163931</td><td>0.008138</td><td>-0.077543</td><td>0.020069</td><td>...</td><td>0.056814</td><td>-0.004057</td><td>0.010989</td><td>0.106581</td><td>0.073535</td><td>0.043218</td><td>0.233523</td><td>-0.086217</td><td>0.010553</td><td>0.008424</td></tr><tr><th>V15</th><td>0.314520</td><td>0.164702</td><td>-0.224573</td><td>0.143457</td><td>0.615704</td><td>-0.431542</td><td>-0.291272</td><td>0.018366</td><td>-0.046737</td><td>0.642081</td><td>...</td><td>0.951314</td><td>-0.111311</td><td>0.011768</td><td>-0.104618</td><td>0.050254</td><td>0.048602</td><td>0.100817</td><td>-0.051861</td><td>0.245635</td><td>0.154020</td></tr><tr><th>V16</th><td>0.347357</td><td>0.435606</td><td>0.782474</td><td>0.394517</td><td>0.023818</td><td>0.847119</td><td>0.752683</td><td>0.680031</td><td>0.546975</td><td>0.025736</td><td>...</td><td>-0.342210</td><td>0.154794</td><td>0.778538</td><td>0.041474</td><td>0.028878</td><td>-0.054775</td><td>0.082293</td><td>0.551880</td><td>-0.420053</td><td>0.536748</td></tr><tr><th>V18</th><td>0.148622</td><td>0.123862</td><td>0.132105</td><td>0.022868</td><td>0.136022</td><td>0.110570</td><td>0.098691</td><td>0.093682</td><td>-0.024693</td><td>0.119833</td><td>...</td><td>0.053958</td><td>0.470341</td><td>0.079718</td><td>0.411967</td><td>0.512139</td><td>0.365410</td><td>0.152088</td><td>0.019603</td><td>-0.181937</td><td>0.170721</td></tr><tr><th>V19</th><td>-0.100294</td><td>-0.092673</td><td>-0.161802</td><td>-0.246008</td><td>-0.205729</td><td>0.215290</td><td>0.158371</td><td>-0.144693</td><td>0.074903</td><td>-0.148319</td><td>...</td><td>-0.205409</td><td>0.100133</td><td>-0.131542</td><td>0.144018</td><td>-0.021517</td><td>-0.079753</td><td>-0.220737</td><td>0.087605</td><td>0.012115</td><td>-0.114976</td></tr><tr><th>V20</th><td>0.462493</td><td>0.459795</td><td>0.298385</td><td>0.289594</td><td>0.291309</td><td>0.136091</td><td>0.089399</td><td>0.412868</td><td>0.207612</td><td>0.271559</td><td>...</td><td>0.016233</td><td>0.086165</td><td>0.326863</td><td>0.050699</td><td>0.009358</td><td>-0.000979</td><td>0.048981</td><td>0.161315</td><td>-0.322006</td><td>0.444965</td></tr><tr><th>V21</th><td>-0.029285</td><td>-0.012911</td><td>-0.030932</td><td>0.114373</td><td>0.174025</td><td>-0.051806</td><td>-0.065300</td><td>-0.047839</td><td>0.082288</td><td>0.144371</td><td>...</td><td>0.157097</td><td>-0.077945</td><td>0.053025</td><td>-0.159128</td><td>-0.087561</td><td>-0.053707</td><td>-0.199398</td><td>0.047340</td><td>0.315470</td><td>-0.010063</td></tr><tr><th>V23</th><td>0.231136</td><td>0.222574</td><td>0.065509</td><td>0.081374</td><td>0.196530</td><td>0.069901</td><td>0.125180</td><td>0.174124</td><td>-0.066537</td><td>0.180049</td><td>...</td><td>0.116122</td><td>0.363963</td><td>0.129783</td><td>0.367086</td><td>0.183666</td><td>0.196681</td><td>0.635252</td><td>-0.035949</td><td>-0.187582</td><td>0.226331</td></tr><tr><th>V24</th><td>-0.324959</td><td>-0.233556</td><td>0.010225</td><td>-0.237326</td><td>-0.529866</td><td>0.072418</td><td>-0.030292</td><td>-0.136898</td><td>-0.029420</td><td>-0.550881</td><td>...</td><td>-0.642370</td><td>0.033532</td><td>-0.202097</td><td>0.060608</td><td>-0.134320</td><td>-0.095588</td><td>-0.243738</td><td>-0.041325</td><td>-0.137614</td><td>-0.264815</td></tr><tr><th>V25</th><td>-0.200706</td><td>-0.070627</td><td>0.481785</td><td>-0.100569</td><td>-0.444375</td><td>0.438610</td><td>0.316744</td><td>0.173320</td><td>0.079805</td><td>-0.448877</td><td>...</td><td>-0.575154</td><td>0.088238</td><td>0.201243</td><td>0.065501</td><td>-0.013312</td><td>-0.030747</td><td>-0.093948</td><td>0.069302</td><td>-0.246742</td><td>-0.019373</td></tr><tr><th>V26</th><td>-0.125140</td><td>-0.043012</td><td>0.035370</td><td>-0.027685</td><td>-0.080487</td><td>0.106055</td><td>0.160566</td><td>0.015724</td><td>0.072366</td><td>-0.124111</td><td>...</td><td>-0.133694</td><td>-0.057247</td><td>0.062879</td><td>-0.004545</td><td>-0.034596</td><td>0.051294</td><td>0.085576</td><td>0.064963</td><td>0.010880</td><td>-0.046724</td></tr><tr><th>V27</th><td>0.733198</td><td>0.824198</td><td>0.726250</td><td>0.392006</td><td>0.412083</td><td>0.474441</td><td>0.424185</td><td>0.901100</td><td>0.246085</td><td>0.374380</td><td>...</td><td>-0.032772</td><td>0.208074</td><td>0.790239</td><td>0.095127</td><td>0.030135</td><td>-0.036123</td><td>0.159884</td><td>0.226713</td><td>-0.617771</td><td>0.812585</td></tr><tr><th>V29</th><td>0.302145</td><td>0.147096</td><td>-0.275764</td><td>0.117610</td><td>0.659093</td><td>-0.467980</td><td>-0.311363</td><td>-0.011091</td><td>-0.105042</td><td>0.666775</td><td>...</td><td>1.000000</td><td>-0.122817</td><td>-0.004364</td><td>-0.110699</td><td>0.035272</td><td>0.035392</td><td>0.078588</td><td>-0.099309</td><td>0.285581</td><td>0.123329</td></tr><tr><th>V30</th><td>0.156968</td><td>0.175997</td><td>0.175943</td><td>0.043966</td><td>0.022807</td><td>0.188907</td><td>0.170113</td><td>0.150258</td><td>-0.036705</td><td>0.028866</td><td>...</td><td>-0.122817</td><td>1.000000</td><td>0.114318</td><td>0.695725</td><td>0.083693</td><td>-0.028573</td><td>-0.027987</td><td>0.006961</td><td>-0.256814</td><td>0.187311</td></tr><tr><th>V31</th><td>0.675003</td><td>0.769745</td><td>0.653764</td><td>0.421954</td><td>0.447016</td><td>0.546535</td><td>0.475254</td><td>0.878072</td><td>0.560213</td><td>0.441963</td><td>...</td><td>-0.004364</td><td>0.114318</td><td>1.000000</td><td>0.016782</td><td>0.016733</td><td>-0.047273</td><td>0.152314</td><td>0.510851</td><td>-0.357785</td><td>0.750297</td></tr><tr><th>V32</th><td>0.050951</td><td>0.085604</td><td>0.033942</td><td>-0.092423</td><td>-0.026186</td><td>0.144550</td><td>0.122707</td><td>0.038430</td><td>-0.093213</td><td>-0.007658</td><td>...</td><td>-0.110699</td><td>0.695725</td><td>0.016782</td><td>1.000000</td><td>0.105255</td><td>0.069300</td><td>0.016901</td><td>-0.054411</td><td>-0.162417</td><td>0.066606</td></tr><tr><th>V33</th><td>0.056439</td><td>0.035129</td><td>0.050309</td><td>-0.007159</td><td>0.062367</td><td>0.054210</td><td>0.034508</td><td>0.026843</td><td>0.016739</td><td>0.046674</td><td>...</td><td>0.035272</td><td>0.083693</td><td>0.016733</td><td>0.105255</td><td>1.000000</td><td>0.719126</td><td>0.167597</td><td>0.031586</td><td>-0.062715</td><td>0.077273</td></tr><tr><th>V34</th><td>-0.019342</td><td>-0.029115</td><td>-0.025620</td><td>-0.031898</td><td>0.028659</td><td>-0.002914</td><td>-0.019103</td><td>-0.036297</td><td>-0.026994</td><td>0.010122</td><td>...</td><td>0.035392</td><td>-0.028573</td><td>-0.047273</td><td>0.069300</td><td>0.719126</td><td>1.000000</td><td>0.233616</td><td>-0.019032</td><td>-0.006854</td><td>-0.006034</td></tr><tr><th>V35</th><td>0.138933</td><td>0.146329</td><td>0.043648</td><td>0.080034</td><td>0.100010</td><td>0.044992</td><td>0.111166</td><td>0.179167</td><td>0.026846</td><td>0.081963</td><td>...</td><td>0.078588</td><td>-0.027987</td><td>0.152314</td><td>0.016901</td><td>0.167597</td><td>0.233616</td><td>1.000000</td><td>0.025401</td><td>-0.077991</td><td>0.140294</td></tr><tr><th>V36</th><td>0.231417</td><td>0.235299</td><td>0.316462</td><td>0.324475</td><td>0.113609</td><td>0.433804</td><td>0.340479</td><td>0.326586</td><td>0.922190</td><td>0.112150</td><td>...</td><td>-0.099309</td><td>0.006961</td><td>0.510851</td><td>-0.054411</td><td>0.031586</td><td>-0.019032</td><td>0.025401</td><td>1.000000</td><td>-0.039478</td><td>0.319309</td></tr><tr><th>V37</th><td>-0.494076</td><td>-0.494043</td><td>-0.734956</td><td>-0.229613</td><td>-0.031054</td><td>-0.404817</td><td>-0.292285</td><td>-0.553121</td><td>-0.045851</td><td>-0.054827</td><td>...</td><td>0.285581</td><td>-0.256814</td><td>-0.357785</td><td>-0.162417</td><td>-0.062715</td><td>-0.006854</td><td>-0.077991</td><td>-0.039478</td><td>1.000000</td><td>-0.565795</td></tr><tr><th>target</th><td>0.873212</td><td>0.871846</td><td>0.638878</td><td>0.512074</td><td>0.603984</td><td>0.370037</td><td>0.287815</td><td>0.831904</td><td>0.394767</td><td>0.594189</td><td>...</td><td>0.123329</td><td>0.187311</td><td>0.750297</td><td>0.066606</td><td>0.077273</td><td>-0.006034</td><td>0.140294</td><td>0.319309</td><td>-0.565795</td><td>1.000000</td></tr></tbody></table><p>33 rows × 33 columns</p></div><h3 id="相关性热力图">5.2相关性热力图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 画出相关性热力图</span><br>ax = plt.subplots(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>))<span class="hljs-comment">#调整画布大小</span><br><br>ax = sns.heatmap(train_corr, vmax=<span class="hljs-number">.8</span>, square=<span class="hljs-literal">True</span>, annot=<span class="hljs-literal">True</span>)<span class="hljs-comment">#画热力图   annot=True 显示系数</span><br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_52_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>代码解释：</p><p>使用Seaborn库中的<code>heatmap()</code>函数来绘制相关性热力图。</p><ul><li><code>ax = sns.heatmap(train_corr, vmax=.8, square=True, annot=True)</code> 在当前图像对象中绘制热力图。<code>train_corr</code>先前计算的相关系数矩阵。<code>vmax</code>参数用于设置颜色映射的最大值，即相关系数的范围。<code>square=True</code>将使得热力图的每个方块为正方形。<code>annot=True</code>表示在热力图中显示相关系数的数值。</li></ul><p><code>vmax</code>参数用于设置颜色映射的最大值，即相关系数的上限。通过将<code>vmax</code>设置为0.8，意味着相关系数的范围将被限制在0到0.8之间。任何具有相关系数大于0.8的值都将被映射为最浅的颜色。</p><p>通常，颜色映射是根据相关系数的值来定义的，例如，浅色可能表示正相关，深色可能表示负相关，中间色调可能表示无相关性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 找出相关程度</span><br>data_train1 = train_data.drop([<span class="hljs-string">&#x27;V5&#x27;</span>,<span class="hljs-string">&#x27;V9&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>,<span class="hljs-string">&#x27;V17&#x27;</span>,<span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V28&#x27;</span>],axis=<span class="hljs-number">1</span>)<br><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>))  <span class="hljs-comment"># 指定绘图对象宽度和高度</span><br>colnm = data_train1.columns.tolist()  <span class="hljs-comment"># 列表头</span><br>mcorr = data_train1[colnm].corr(method=<span class="hljs-string">&quot;spearman&quot;</span>)  <span class="hljs-comment"># 相关系数矩阵，即给出了任意两个变量之间的相关系数</span><br>mask = np.zeros_like(mcorr, dtype=np.<span class="hljs-built_in">bool</span>)  <span class="hljs-comment"># 构造与mcorr同维数矩阵 为bool型</span><br>mask[np.triu_indices_from(mask)] = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 角分线右侧为True</span><br>cmap = sns.diverging_palette(<span class="hljs-number">220</span>, <span class="hljs-number">10</span>, as_cmap=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 返回matplotlib colormap对象</span><br>g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=<span class="hljs-literal">True</span>, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">&#x27;0.2f&#x27;</span>)  <span class="hljs-comment"># 热力图（看两两相似度）</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_54_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>上图为所有特征变量和target变量两两之间的相关系数，由此可以看出各个特征变量V0-V37之间的相关性以及特征变量V0-V37与target的相关性。</p><p>代码详解：</p><ol type="1"><li><p><code>mcorr = data_train1[colnm].corr(method="spearman")</code>计算了给定变量列表<code>[colnm]</code>中两两变量之间的相关系数矩阵，使用Spearman秩相关系数方法，该方法更适用于非线性关系的数据，而且对异常值的影响较小。</p></li><li><p><code>np.zeros_like(mcorr, dtype=np.bool)</code>构建了一个与相关系数矩阵 <code>mcorr</code> 维度相同的布尔型矩阵 <code>mask</code>，并将其所有元素初始化为False。这个矩阵 <code>mask</code> 将用于在热力图中标记需要遮挡的区域。<code>np.zeros_like</code>用于创建一个与给定数组（或者与给定数组形状相同）具有相同形状的全零数组。</p></li><li><p><code>mask[np.triu_indices_from(mask)] = True</code>将对角线右上方的元素设为True，在热力图中这些区域将被遮挡起来，只显示对角线左下方的相关系数。</p></li></ol><ul><li><code>np.triu_indices_from()</code> 函数用于获取一个上三角矩阵的索引。</li><li><code>np.triu_indices_from(mask)</code>我们可以获取 mask 矩阵中上三角区域的所有元素的索引。然后，将这些索引对应的位置在 mask 矩阵中设置为 <code>True</code>，表示需要将相关系数矩阵中对应的元素掩盖起来。</li></ul><ol start="4" type="1"><li><code>cmap = sns.diverging_palette(220, 10, as_cmap=True)</code>利用Seaborn库中的<code>diverging_palette</code>函数创建了一个颜色映射(color map)对象 <code>cmap</code>，用于渲染热力图的颜色。</li></ol><ul><li><code>sns.diverging_palette()</code> 函数用于生成一个离散的、具有对比度的颜色调色板。它接受三个参数：<code>start</code>、<code>end</code> 和 <code>as_cmap</code>。</li><li><code>start</code> 和 <code>end</code> 是起始颜色和结束颜色的色调值（hue），取值范围为 [0, 360]。在这里，起始颜色的色调值为 220，结束颜色的色调值为 10。这意味着生成的调色板将从蓝绿色渐变到橙红色。</li><li><code>as_cmap=True</code> 表示将调色板转换为 colormap 对象，以便在绘图时使用。</li></ul><ol start="5" type="1"><li><code>g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=True, annot=True, fmt='0.2f')</code>生成热力图。其中，<code>mcorr</code>为相关系数矩阵，<code>mask</code>用于指定需要遮挡的区域，<code>cmap</code>为颜色映射对象，<code>square=True</code>表示将热力图显示为正方形，<code>annot=True</code>表示在热力图中显示相关系数的数值，<code>fmt='0.2f'</code>指定数值显示格式为保留两位小数。</li></ol><h3 id="根据相关系数筛选特征变量">5.3根据相关系数筛选特征变量</h3><p>以方便我们后续做特征工程及模型分析。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先寻找K个与target变量最相关的特征变量</span><br>k = <span class="hljs-number">10</span> <span class="hljs-comment"># number of variables for heatmap</span><br>cols = train_corr.nlargest(k, <span class="hljs-string">&#x27;target&#x27;</span>)[<span class="hljs-string">&#x27;target&#x27;</span>].index <span class="hljs-comment"># 返回特征名</span><br><br>cm = np.corrcoef(train_data[cols].values.T)<br>hm = plt.subplots(figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">6</span>))<span class="hljs-comment">#调整画布大小</span><br><span class="hljs-comment">#hm1 = sns.heatmap(cm, cbar=True, annot=True, square=True) # 与hm结果相同，只是无标签.cbar=True 是在绘制相关性热力图时，添加了一个颜色条（color bar）来表示相关系数的范围。</span><br><span class="hljs-comment">#g = sns.heatmap(train_data[cols].corr(),annot=True,square=True,cmap=&quot;RdYlGn&quot;) # 与hm结果相同，只是配色不同. cmap=&quot;RdYlGn&quot; 指定颜色映射为 &quot;RdYlGn&quot;。</span><br>hm = sns.heatmap(train_data[cols].corr(),annot=<span class="hljs-literal">True</span>,square=<span class="hljs-literal">True</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_58_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>代码详解：</p><ol type="1"><li><code>train_corr.nlargest(k, 'target')['target'].index</code> 用于找到与目标变量相关性最高的k个特征变量，从<code>train_corr</code>中找到与<code>target</code>相关性最高的10个变量。</li></ol><ul><li><p><code>nlargest(n, columns, keep='first')</code>:<code>n</code>：要获取的最大值的数量。<code>columns</code>：指定要比较大小的列或列的列表。<code>keep</code>：（可选参数）设置用于处理重复值的策略。默认值为 'first'，表示保留第一个出现的最大值。还可以选择 'last'，表示保留最后一个出现的最大值。</p></li><li><p><code>train_corr.nlargest(k, 'target')</code> 返回了一个 DataFrame，其中包含了与目标变量 'target' 最相关的 K 个特征变量,返回整行。 <img src="C:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/1.png" srcset="/img/loading.gif" lazyload></p></li><li><p><code>['target']</code> 从这个 DataFrame 中选择了名为 'target' 的列，并返回一个 Series 对象。 <img src="C:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/2.png" srcset="/img/loading.gif" lazyload></p></li><li><p><code>.index</code> 调用了 Series 对象的 index 属性，用于获取该 Series 的索引。在这个上下文中，.index 返回了与目标变量最相关的 K 个特征变量所对应的列的索引。 <img src="C:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/3.png" srcset="/img/loading.gif" lazyload></p></li></ul><ol start="2" type="1"><li><code>np.corrcoef(train_data[cols].values.T)</code> 计算<code>train_data</code>中<code>cols</code>所对应的特征变量之间的相关系数。</li></ol><ul><li><p><code>corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue)</code> 函数常用的是前三个参数，x和y分别是需要计算相关系数的两个随机变量，当rowvar为True(默认情况)时，每一行代表一个随机变量，否则每一列代表一个随机变量。所以需要用<code>.T</code>进行转置。</p></li><li><p><code>np.corrcoef(train_data[cols].values.T)</code>和<code>train_data[cols].corr()</code> 返回的数值都是一样的。最主要的区别是前者返回的类型是NumPy 数组，后者为 Pandas DataFrame</p></li></ul><ol start="3" type="1"><li><p><code>hm1 = sns.heatmap(cm, cbar=True, annot=True, square=True)</code> # cbar=True 添加颜色条（color bar）来表示相关系数的范围。</p></li><li><p><code>g = sns.heatmap(train_data[cols].corr(),annot=True,square=True,cmap="RdYlGn")</code> cmap="RdYlGn" 指定颜色映射为 "RdYlGn"。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 然后找出与arget变量的相关系数大于0.5的特征变量：</span><br>threshold = <span class="hljs-number">0.5</span><br><br>corrmat = train_data.corr()<br>top_corr_features = corrmat.index[<span class="hljs-built_in">abs</span>(corrmat[<span class="hljs-string">&quot;target&quot;</span>])&gt;threshold]<br>plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">8</span>))<br>g = sns.heatmap(train_data[top_corr_features].corr(),annot=<span class="hljs-literal">True</span>,cmap=<span class="hljs-string">&quot;RdYlGn&quot;</span>)<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽%2002数据探索/output_60_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>代码解释：</p><ol type="1"><li><p><code>corrmat["target"]</code>：从相关性矩阵 <code>corrmat</code> 中选择名为 "target" 的列，得到一个包含所有特征与目标变量的相关系数的 Series 对象。</p></li><li><p><code>abs(corrmat["target"]) &gt; threshold</code>：计算相关系数的绝对值，并将结果与阈值 <code>threshold</code> 进行比较，得到一个布尔类型的 Series 对象，表示哪些特征与目标变量的相关系数大于阈值。</p></li><li><p><code>corrmat.index[abs(corrmat["target"])&gt;threshold]</code>：根据上述布尔索引，从相关性矩阵的索引中选择相应的特征名。这将得到一个包含与目标变量的相关系数大于阈值的特征名的索引对象。<code>.index[]</code> 返回索引值。</p></li></ol><p>可以发现，与target变量的相关系数大于0.5的特征变量被直观地筛选出来。这一方法可以简单、直观地判断哪些特征变量线性相关，相关系数越大，就认为这些特征变量对target变量的线性影响越大。</p><p>说明：相关性选择主要用于判别线性相关对于target变量如果存在更复杂的函数形式的影响则建议使用树模型的特征重要性去选择</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用相关系数阈值移除相关特征：</span><br>threshold = <span class="hljs-number">0.5</span><br><br><span class="hljs-comment"># Absolute value correlation matrix</span><br>corr_matrix = data_train1.corr().<span class="hljs-built_in">abs</span>()<br>drop_col=corr_matrix[corr_matrix[<span class="hljs-string">&quot;target&quot;</span>]&lt;threshold].index<br><span class="hljs-comment">#data_all.drop(drop_col, axis=1, inplace=True)</span><br></code></pre></td></tr></table></figure><p>由于'V14', 'V21', 'V25', 'V26', 'V32', 'V33', 'V34'特征的相关系数值小于0.5，故认为这些特征与最终的预测target值不相关，删除这些特征变量；其可以发现一些不重要的特征并快速删除，方便快速分析重要特征。这里先不删除这些特征（注释的代码行用于删除特征），因为后续分析还会用到。</p><h3 id="box-cox变换">5.4Box-Cox变换</h3><p>由于线性回归是基于正态分布的，因此在进行统计分析时，需要转换数据使其符合正态分布。</p><p>Box-Cox 变换是一种常见的数据转换技术，用于将非正态分布的数据<strong>转换为近似正态分布</strong>的数据。这一变换可以使线性回归模型在满足线性、正态性、独立性及方差齐性的同时，又不丢失信息。在对数据做Box-Cox变换之后，可以在一定程度上减小不可观测的误差和预测变量的相关性，这有<strong>利于线性模型的拟合及分析出特征的相关性</strong>。</p><p>在做Box-Cox变换之前，需要对数据做归一化预处理。在归一化时，对数据进行合并操作可以使训练数据和测试数据一致。这种方式可以在线下分析建模中使用，而线上部署只需采用训练数据的归一化即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">drop_columns.clear()  <span class="hljs-comment"># 用于清空列表中的所有元素。</span><br>drop_columns = [<span class="hljs-string">&#x27;V5&#x27;</span>,<span class="hljs-string">&#x27;V9&#x27;</span>,<span class="hljs-string">&#x27;V11&#x27;</span>,<span class="hljs-string">&#x27;V17&#x27;</span>,<span class="hljs-string">&#x27;V22&#x27;</span>,<span class="hljs-string">&#x27;V28&#x27;</span>]<br><br><span class="hljs-comment"># 合并训练集和测试集的数据</span><br>train_x =  train_data.drop([<span class="hljs-string">&#x27;target&#x27;</span>], axis=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment">#data_all=pd.concat([train_data,test_data],axis=0,ignore_index=True)</span><br>data_all = pd.concat([train_x,test_data]) <br><br><br>data_all.drop(drop_columns,axis=<span class="hljs-number">1</span>,inplace=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">#View data</span><br>data_all.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V6</th><th>V7</th><th>V8</th><th>V10</th><th>V12</th><th>...</th><th>V27</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>0</th><td>0.566</td><td>0.016</td><td>-0.143</td><td>0.407</td><td>0.452</td><td>-1.812</td><td>-2.360</td><td>-0.436</td><td>-0.940</td><td>-0.073</td><td>...</td><td>0.168</td><td>0.136</td><td>0.109</td><td>-0.615</td><td>0.327</td><td>-4.627</td><td>-4.789</td><td>-5.101</td><td>-2.608</td><td>-3.508</td></tr><tr><th>1</th><td>0.968</td><td>0.437</td><td>0.066</td><td>0.566</td><td>0.194</td><td>-1.566</td><td>-2.360</td><td>0.332</td><td>0.188</td><td>-0.134</td><td>...</td><td>0.338</td><td>-0.128</td><td>0.124</td><td>0.032</td><td>0.600</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>-0.335</td><td>-0.730</td></tr><tr><th>2</th><td>1.013</td><td>0.568</td><td>0.235</td><td>0.370</td><td>0.112</td><td>-1.367</td><td>-2.360</td><td>0.396</td><td>0.874</td><td>-0.072</td><td>...</td><td>0.326</td><td>-0.009</td><td>0.361</td><td>0.277</td><td>-0.116</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>0.765</td><td>-0.589</td></tr><tr><th>3</th><td>0.733</td><td>0.368</td><td>0.283</td><td>0.165</td><td>0.599</td><td>-1.200</td><td>-2.086</td><td>0.403</td><td>0.011</td><td>-0.014</td><td>...</td><td>0.277</td><td>0.015</td><td>0.417</td><td>0.279</td><td>0.603</td><td>-0.843</td><td>-0.065</td><td>0.364</td><td>0.333</td><td>-0.112</td></tr><tr><th>4</th><td>0.684</td><td>0.638</td><td>0.260</td><td>0.209</td><td>0.337</td><td>-1.073</td><td>-2.086</td><td>0.314</td><td>-0.251</td><td>0.199</td><td>...</td><td>0.332</td><td>0.183</td><td>1.078</td><td>0.328</td><td>0.418</td><td>-0.843</td><td>-0.215</td><td>0.364</td><td>-0.280</td><td>-0.028</td></tr></tbody></table><p>5 rows × 32 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对合并后的每列数据进行归一化：</span><br>cols_numeric=<span class="hljs-built_in">list</span>(data_all.columns)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">scale_minmax</span>(<span class="hljs-params">col</span>):<br>    <span class="hljs-keyword">return</span> (col-col.<span class="hljs-built_in">min</span>())/(col.<span class="hljs-built_in">max</span>()-col.<span class="hljs-built_in">min</span>())<br><br>data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax,axis=<span class="hljs-number">0</span>)<br>data_all[cols_numeric].describe()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V6</th><th>V7</th><th>V8</th><th>V10</th><th>V12</th><th>...</th><th>V27</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th></tr></thead><tbody><tr><th>count</th><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>...</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td><td>4813.000000</td></tr><tr><th>mean</th><td>0.694172</td><td>0.721357</td><td>0.602300</td><td>0.603139</td><td>0.523743</td><td>0.748823</td><td>0.745740</td><td>0.715607</td><td>0.348518</td><td>0.578507</td><td>...</td><td>0.881401</td><td>0.388683</td><td>0.589459</td><td>0.792709</td><td>0.628824</td><td>0.458493</td><td>0.483790</td><td>0.762873</td><td>0.332385</td><td>0.545795</td></tr><tr><th>std</th><td>0.144198</td><td>0.131443</td><td>0.140628</td><td>0.152462</td><td>0.106430</td><td>0.132560</td><td>0.132577</td><td>0.118105</td><td>0.134882</td><td>0.105088</td><td>...</td><td>0.128221</td><td>0.133475</td><td>0.130786</td><td>0.102976</td><td>0.155003</td><td>0.099095</td><td>0.101020</td><td>0.102037</td><td>0.127456</td><td>0.150356</td></tr><tr><th>min</th><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>...</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr><tr><th>25%</th><td>0.626676</td><td>0.679416</td><td>0.514414</td><td>0.503888</td><td>0.478182</td><td>0.683324</td><td>0.696938</td><td>0.664934</td><td>0.284327</td><td>0.532892</td><td>...</td><td>0.888575</td><td>0.292445</td><td>0.550092</td><td>0.761816</td><td>0.562461</td><td>0.409037</td><td>0.454490</td><td>0.727273</td><td>0.270584</td><td>0.445647</td></tr><tr><th>50%</th><td>0.729488</td><td>0.752497</td><td>0.617072</td><td>0.614270</td><td>0.535866</td><td>0.774125</td><td>0.771974</td><td>0.742884</td><td>0.366469</td><td>0.591635</td><td>...</td><td>0.916015</td><td>0.375734</td><td>0.594428</td><td>0.815055</td><td>0.643056</td><td>0.454518</td><td>0.499949</td><td>0.800020</td><td>0.347056</td><td>0.539317</td></tr><tr><th>75%</th><td>0.790195</td><td>0.799553</td><td>0.700464</td><td>0.710474</td><td>0.585036</td><td>0.842259</td><td>0.836405</td><td>0.790835</td><td>0.432965</td><td>0.641971</td><td>...</td><td>0.932555</td><td>0.471837</td><td>0.650798</td><td>0.852229</td><td>0.719777</td><td>0.500000</td><td>0.511365</td><td>0.800020</td><td>0.414861</td><td>0.643061</td></tr><tr><th>max</th><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>...</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td><td>1.000000</td></tr></tbody></table><p>8 rows × 32 columns</p></div><p>代码解释：</p><ol type="1"><li><code>cols_numeric=list(data_all.columns)</code><ul><li>将<code>data_all</code>中的所有列名保存在<code>cols_numeric</code>列表中。</li></ul></li><li><code>def scale_minmax(col):</code><ul><li>定义<code>scale_minmax</code>的函数，输入参数<code>col</code>表示数据的某一列。即使传入的是整个列，Pandas库的向量化操作会自动将这些操作应用到列中的每个元素上，从而实现对每个元素的归一化处理。</li></ul></li><li><code>return (col-col.min())/(col.max()-col.min())</code><ul><li>计算数据列<code>col</code>的归一化值。它用数据列中每个元素减去该列的最小值，然后除以该列的最大值与最小值之差，从而实现归一化处理。</li></ul></li><li><code>data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax,axis=0)</code><ul><li>进行广播，将归一化处理的结果应用到<code>data_all</code>数据框的所有数值型列上。</li><li><code>data_all[cols_numeric]</code>表示选择<code>data_all</code>数据框中<code>cols_numeric</code>列表中的列。</li><li><code>.apply(scale_minmax, axis=0)</code>将<code>scale_minmax</code>函数应用到每列数据上，并指定<code>axis=0</code>以逐列进行操作。</li></ul></li></ol><p>也可以<strong>分开</strong>对训练数据和测试数据进行归一化处理，不过这种方式需要建立在训练数据和测试数据分布一致的前提下，建议在<strong>数据量大</strong>的情况下使用（数据量大，一般分布比较一致)，能加快归一化的速度。而数据量较小会存在分布差异较大的情况，此时，在数据分析和线下建模中应该将数据统一归一化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练集测试集分开归一化</span><br>train_data_process = train_data[cols_numeric]<br>train_data_process = train_data_process[cols_numeric].apply(scale_minmax,axis=<span class="hljs-number">0</span>)<br><br>test_data_process = test_data[cols_numeric]<br>test_data_process = test_data_process[cols_numeric].apply(scale_minmax,axis=<span class="hljs-number">0</span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Box-Cox变换（特征太多，分左右两部分绘制）</span><br>cols_numeric_left = cols_numeric[<span class="hljs-number">0</span>:<span class="hljs-number">13</span>]<br>cols_numeric_right = cols_numeric[<span class="hljs-number">13</span>:]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cols_numeric_left<br></code></pre></td></tr></table></figure><pre><code class="hljs">[&#39;V0&#39;,
 &#39;V1&#39;,
 &#39;V2&#39;,
 &#39;V3&#39;,
 &#39;V4&#39;,
 &#39;V6&#39;,
 &#39;V7&#39;,
 &#39;V8&#39;,
 &#39;V10&#39;,
 &#39;V12&#39;,
 &#39;V13&#39;,
 &#39;V14&#39;,
 &#39;V15&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">np.corrcoef(train_data_process[<span class="hljs-string">&#x27;V0&#x27;</span>], train_data[<span class="hljs-string">&#x27;target&#x27;</span>])<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([[1.        , 0.87321202],
       [0.87321202, 1.        ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## Check effect of Box-Cox transforms on distributions of continuous variables</span><br><br>train_data_process = pd.concat([train_data_process, train_data[<span class="hljs-string">&#x27;target&#x27;</span>]], axis=<span class="hljs-number">1</span>)<span class="hljs-comment"># 合并训练集</span><br><br>fcols = <span class="hljs-number">6</span><br>frows = <span class="hljs-built_in">len</span>(cols_numeric_left)<br>plt.figure(figsize=(<span class="hljs-number">4</span>*fcols,<span class="hljs-number">4</span>*frows)) <br>i=<span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> var <span class="hljs-keyword">in</span> cols_numeric_left:<br>    dat = train_data_process[[var, <span class="hljs-string">&#x27;target&#x27;</span>]].dropna()<br>        <br>    <span class="hljs-comment">### 原数据直方图、Q-Q图、散点图    </span><br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    sns.distplot(dat[var] , fit=stats.norm);<br>    plt.title(var+<span class="hljs-string">&#x27; Original&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    _=stats.probplot(dat[var], plot=plt)<br>    plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(dat[var]))) <span class="hljs-comment"># 下方有用法详解</span><br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    plt.plot(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>    plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>])) <span class="hljs-comment"># 下方有用法详解</span><br> <br>    <span class="hljs-comment">### Box-Cox变换，并绘制直方图、Q-Q图、散点图</span><br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class="hljs-number">1</span>)<br>    trans_var = scale_minmax(trans_var)      <br>    sns.distplot(trans_var , fit=stats.norm);<br>    plt.title(var+<span class="hljs-string">&#x27; Tramsformed&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    _=stats.probplot(trans_var, plot=plt)<br>    plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(trans_var)))<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    plt.plot(trans_var, dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>    plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(trans_var,dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽%2002数据探索/output_75_0.png" srcset="/img/loading.gif" lazyload> ​</p><p>代码详解：</p><ul><li><p><code>plt.title()</code>：这是Matplotlib库中的一个函数，用于设置当前子图的标题。它接受一个字符串作为参数，表示要设置的标题内容。</p></li><li><p><code>'skew=' + '&#123;:.4f&#125;'.format(stats.skew(dat[var]))</code>：这是一个字符串格式化操作，用于构造标题内容。其中包含了以下几个部分：</p><ul><li><code>'skew='</code>：这是一个固定的字符串，用于标识标题内容中的部分。</li><li><code>'&#123;:.4f&#125;'</code>：这是一个格式化字符串，表示将要显示的数值（即偏度值）的格式。<code>&#123;:.4f&#125;</code>中的<code>4</code>表示小数点后四位，<code>.f</code>表示浮点数。</li><li><code>format(stats.skew(dat[var]))</code>：这是一个格式化操作，用于将实际的数值（<code>stats.skew(dat[var])</code>）应用到格式化字符串中。</li></ul></li><li><p><code>stats.skew(dat[var])</code>：这是SciPy库中的<code>stats.skew()</code>函数，用于计算给定数据集（<code>dat[var]</code>）的偏度值。偏度是衡量数据分布偏斜程度的统计量，负值表示左偏（左侧的尾部更长），正值表示右偏（右侧的尾部更长），0表示对称分布。</p></li></ul><p><code>&#123;:.4f&#125;</code>是一种格式化字符串的方法，用于将浮点数进行格式化输出。</p><ol type="1"><li>具体用法：<ul><li><code>&#123;&#125;</code>：花括号内放置要格式化的值的占位符。</li><li><code>:</code> ：表示格式说明符的开始。</li><li><code>.4f</code>：表示使用浮点数格式化，并保留小数点后四位。</li></ul></li><li><code>:</code> 的用处：<ul><li>在格式说明符中，冒号（<code>:</code>）用来分隔格式说明符的各个部分。</li><li>在 <code>&#123;&#125;</code> 内的冒号后面，可以添加格式说明符，对应要格式化的值按照指定的格式输出。</li></ul></li><li>中间可以填哪些参数，表示什么：<ul><li>宽度参数：如 <code>&#123;:&lt;10&#125;</code> 表示左对齐并占用 10 个字符的宽度。</li><li>对齐参数：如 <code>&#123;:&gt;10&#125;</code> 表示右对齐并占用 10 个字符的宽度。</li><li>精度参数：如 <code>&#123;:.2f&#125;</code> 表示保留两位小数。</li><li>类型参数：如 <code>&#123;:s&#125;</code> 表示字符串类型，<code>&#123;:d&#125;</code> 表示整数类型，<code>&#123;:f&#125;</code> 表示浮点数类型等。</li></ul></li></ol><p>总结起来，冒号（<code>:</code>）在格式化字符串中的作用是分隔格式说明符的各个部分。精度参数和类型参数是冒号后面的部分，用于指定格式化的精度和类型。</p><p><code>[0][1]</code> 是用于获取 <code>np.corrcoef(dat[var],dat['target'])</code> 返回的相关系数矩阵中的特定元素的索引表示方式。</p><p><code>np.corrcoef(dat[var], dat['target'])</code> 用于计算 <code>dat[var]</code> 和 <code>dat['target']</code> 之间的相关系数矩阵。</p><ul><li>相关系数矩阵是一个二维矩阵，其中每个元素是两个变量之间的相关系数。例如： <img src="C:/Users/Admin/Desktop/%25E5%25B7%25A5%25E4%25B8%259A%25E8%2592%25B8%25E6%25B1%25BD%25E9%25A2%2584%25E6%25B5%258B-02%25E6%2595%25B0%25E6%258D%25AE%25E6%258E%25A2%25E7%25B4%25A2/img/4.png" srcset="/img/loading.gif" lazyload></li><li>在这种情况下，<code>[0][1]</code> 表示相关系数矩阵的第一行第二列的元素。其中，第一行对应于 <code>dat[var]</code> 与 <code>dat[var]</code>自身的相关系数，而第二列对应于 <code>dat[var]</code> 与 <code>dat['target']</code> 的相关系数。</li></ul><p>因此，<code>plt.title('corr='+'&#123;:.2f&#125;'.format(np.corrcoef(dat[var],dat['target'])[0][1]))</code> 中的 <code>[0][1]</code> 表示提取相关系数矩阵中与 <code>dat[var]</code> 与 <code>dat['target']</code> 相关系数对应的值，并将其格式化为小数点后两位的字符串。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## Check effect of Box-Cox transforms on distributions of continuous variables</span><br><br>fcols = <span class="hljs-number">6</span><br>frows = <span class="hljs-built_in">len</span>(cols_numeric_right)<br>plt.figure(figsize=(<span class="hljs-number">4</span>*fcols,<span class="hljs-number">4</span>*frows))<br>i=<span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> var <span class="hljs-keyword">in</span> cols_numeric_right:<br>    dat = train_data_process[[var, <span class="hljs-string">&#x27;target&#x27;</span>]].dropna() <br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    sns.distplot(dat[var] , fit=stats.norm);<br>    plt.title(var+<span class="hljs-string">&#x27; Original&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    _=stats.probplot(dat[var], plot=plt)<br>    plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(dat[var])))<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    plt.plot(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>    plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br> <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class="hljs-number">1</span>)<br>    trans_var = scale_minmax(trans_var)      <br>    sns.distplot(trans_var , fit=stats.norm);<br>    plt.title(var+<span class="hljs-string">&#x27; Tramsformed&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    _=stats.probplot(trans_var, plot=plt)<br>    plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(trans_var)))<br>    plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>    i+=<span class="hljs-number">1</span><br>    plt.subplot(frows,fcols,i)<br>    plt.plot(trans_var, dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>    plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(trans_var,dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽%2002数据探索/output_79_0.png" srcset="/img/loading.gif" lazyload> ​</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>工业蒸汽预测-02数据探索</div><div>https://zhou1317fe5.github.io/2023/07/29/工业蒸汽预测-02数据探索/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年7月29日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2023/07/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A007-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" title="机器学习07-强化学习"><span class="hidden-mobile">机器学习07-强化学习</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>