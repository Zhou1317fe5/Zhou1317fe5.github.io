<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="1 基础步骤 1.1 导包 12345678910111213141516171819import warningswarnings.filterwarnings(&quot;ignore&quot;)import matplotlib.pyplot as pltplt.rcParams.update(&amp;#123;&amp;#x27;figure.max_open_warning&amp;#x27;: 0&amp;#"><meta property="og:type" content="article"><meta property="og:title" content="工业蒸汽预测-07模型融合"><meta property="og:url" content="https://zhou1317fe5.github.io/2023/09/19/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="1 基础步骤 1.1 导包 12345678910111213141516171819import warningswarnings.filterwarnings(&quot;ignore&quot;)import matplotlib.pyplot as pltplt.rcParams.update(&amp;#123;&amp;#x27;figure.max_open_warning&amp;#x27;: 0&amp;#"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_11_0.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_17_1-169517575505519.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_19_1-169517575505520.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_27_1-169517575505521.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_34_2.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_34_3-169517575505523.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_40_2.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_40_3-169517575505525.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_42_1-169517575505526.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_44_2.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_44_3-169517575505529.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_46_2.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_46_3-169517575505530.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_48_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_50_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_52_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_59_0.png"><meta property="article:published_time" content="2023-09-19T08:35:47.000Z"><meta property="article:modified_time" content="2023-09-20T02:12:44.859Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-07%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/output_11_0.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>工业蒸汽预测-07模型融合 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="工业蒸汽预测-07模型融合"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-09-19 16:35" pubdate>2023年9月19日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 41k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 344 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">工业蒸汽预测-07模型融合</h1><div class="markdown-body"><h1 id="基础步骤">1 基础步骤</h1><h2 id="导包">1.1 导包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams.update(&#123;<span class="hljs-string">&#x27;figure.max_open_warning&#x27;</span>: <span class="hljs-number">0</span>&#125;)<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br><span class="hljs-comment"># modelling</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV, RepeatedKFold, cross_val_score,cross_val_predict,KFold<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> make_scorer,mean_squared_error<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression, Lasso, Ridge, ElasticNet<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> LinearSVR, SVR<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor, GradientBoostingRegressor,AdaBoostRegressor<br><span class="hljs-keyword">from</span> xgboost <span class="hljs-keyword">import</span> XGBRegressor<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> PolynomialFeatures,MinMaxScaler,StandardScaler<br></code></pre></td></tr></table></figure><h2 id="导入数据">1.2 导入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#load_dataset</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/zhengqi_train.txt&quot;</span>)  <span class="hljs-keyword">as</span> fr:<br>    data_train=pd.read_table(fr,sep=<span class="hljs-string">&quot;\t&quot;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/zhengqi_test.txt&quot;</span>) <span class="hljs-keyword">as</span> fr_test:<br>    data_test=pd.read_table(fr_test,sep=<span class="hljs-string">&quot;\t&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="合并数据">1.3 合并数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#merge train_set and test_set</span><br>data_train[<span class="hljs-string">&quot;oringin&quot;</span>]=<span class="hljs-string">&quot;train&quot;</span><br>data_test[<span class="hljs-string">&quot;oringin&quot;</span>]=<span class="hljs-string">&quot;test&quot;</span><br>data_all=pd.concat([data_train,data_test],axis=<span class="hljs-number">0</span>,ignore_index=<span class="hljs-literal">True</span>)<br>data_all<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th><th>oringin</th></tr></thead><tbody><tr><th>0</th><td>0.566</td><td>0.016</td><td>-0.143</td><td>0.407</td><td>0.452</td><td>-0.901</td><td>-1.812</td><td>-2.360</td><td>-0.436</td><td>-2.114</td><td>...</td><td>0.109</td><td>-0.615</td><td>0.327</td><td>-4.627</td><td>-4.789</td><td>-5.101</td><td>-2.608</td><td>-3.508</td><td>0.175</td><td>train</td></tr><tr><th>1</th><td>0.968</td><td>0.437</td><td>0.066</td><td>0.566</td><td>0.194</td><td>-0.893</td><td>-1.566</td><td>-2.360</td><td>0.332</td><td>-2.114</td><td>...</td><td>0.124</td><td>0.032</td><td>0.600</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>-0.335</td><td>-0.730</td><td>0.676</td><td>train</td></tr><tr><th>2</th><td>1.013</td><td>0.568</td><td>0.235</td><td>0.370</td><td>0.112</td><td>-0.797</td><td>-1.367</td><td>-2.360</td><td>0.396</td><td>-2.114</td><td>...</td><td>0.361</td><td>0.277</td><td>-0.116</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>0.765</td><td>-0.589</td><td>0.633</td><td>train</td></tr><tr><th>3</th><td>0.733</td><td>0.368</td><td>0.283</td><td>0.165</td><td>0.599</td><td>-0.679</td><td>-1.200</td><td>-2.086</td><td>0.403</td><td>-2.114</td><td>...</td><td>0.417</td><td>0.279</td><td>0.603</td><td>-0.843</td><td>-0.065</td><td>0.364</td><td>0.333</td><td>-0.112</td><td>0.206</td><td>train</td></tr><tr><th>4</th><td>0.684</td><td>0.638</td><td>0.260</td><td>0.209</td><td>0.337</td><td>-0.454</td><td>-1.073</td><td>-2.086</td><td>0.314</td><td>-2.114</td><td>...</td><td>1.078</td><td>0.328</td><td>0.418</td><td>-0.843</td><td>-0.215</td><td>0.364</td><td>-0.280</td><td>-0.028</td><td>0.384</td><td>train</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>4808</th><td>-1.362</td><td>-1.553</td><td>-3.096</td><td>-0.444</td><td>0.381</td><td>1.375</td><td>-4.854</td><td>-5.331</td><td>-4.074</td><td>-3.838</td><td>...</td><td>-4.488</td><td>-5.793</td><td>-4.050</td><td>-1.187</td><td>-0.852</td><td>-2.131</td><td>-2.564</td><td>0.597</td><td>NaN</td><td>test</td></tr><tr><th>4809</th><td>-2.698</td><td>-3.452</td><td>-3.620</td><td>-1.066</td><td>-1.385</td><td>1.378</td><td>-4.927</td><td>-5.103</td><td>-4.393</td><td>-1.683</td><td>...</td><td>-0.613</td><td>-7.698</td><td>-0.674</td><td>-1.187</td><td>-0.852</td><td>-2.131</td><td>-2.564</td><td>1.215</td><td>NaN</td><td>test</td></tr><tr><th>4810</th><td>-2.615</td><td>-3.564</td><td>-3.402</td><td>-0.422</td><td>-1.272</td><td>1.121</td><td>-4.223</td><td>-4.315</td><td>-5.196</td><td>-3.407</td><td>...</td><td>0.125</td><td>-6.111</td><td>0.275</td><td>-1.851</td><td>-1.548</td><td>-1.537</td><td>-2.544</td><td>1.612</td><td>NaN</td><td>test</td></tr><tr><th>4811</th><td>-2.661</td><td>-3.646</td><td>-3.271</td><td>-0.699</td><td>-1.270</td><td>1.116</td><td>-3.716</td><td>-3.809</td><td>-4.735</td><td>-2.976</td><td>...</td><td>1.086</td><td>-5.268</td><td>0.683</td><td>-1.645</td><td>-1.471</td><td>-1.537</td><td>-2.549</td><td>1.431</td><td>NaN</td><td>test</td></tr><tr><th>4812</th><td>-2.321</td><td>-3.037</td><td>-3.214</td><td>-1.594</td><td>-0.910</td><td>1.259</td><td>-3.616</td><td>-3.747</td><td>-4.368</td><td>-2.976</td><td>...</td><td>-0.774</td><td>-5.211</td><td>1.618</td><td>-1.703</td><td>-1.471</td><td>-1.537</td><td>-1.123</td><td>1.988</td><td>NaN</td><td>test</td></tr></tbody></table><p>4813 rows × 40 columns</p></div><h2 id="删除相关特征">1.4 删除相关特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data_all.drop([<span class="hljs-string">&quot;V5&quot;</span>,<span class="hljs-string">&quot;V9&quot;</span>,<span class="hljs-string">&quot;V11&quot;</span>,<span class="hljs-string">&quot;V17&quot;</span>,<span class="hljs-string">&quot;V22&quot;</span>,<span class="hljs-string">&quot;V28&quot;</span>],axis=<span class="hljs-number">1</span>,inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="数据归一化">1.5 数据归一化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># normalise numeric columns</span><br>cols_numeric=<span class="hljs-built_in">list</span>(data_all.columns)<br>cols_numeric.remove(<span class="hljs-string">&quot;oringin&quot;</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">scale_minmax</span>(<span class="hljs-params">col</span>):<br>    <span class="hljs-keyword">return</span> (col-col.<span class="hljs-built_in">min</span>())/(col.<span class="hljs-built_in">max</span>()-col.<span class="hljs-built_in">min</span>())<br>scale_cols = [col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> cols_numeric <span class="hljs-keyword">if</span> col!=<span class="hljs-string">&#x27;target&#x27;</span>]<br>data_all[scale_cols] = data_all[scale_cols].apply(scale_minmax,axis=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="画图探查特征和标签相关信息">1.6 画图：探查特征和标签相关信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Check effect of Box-Cox transforms on distributions of continuous variables</span><br><br>fcols = <span class="hljs-number">6</span><br>frows = <span class="hljs-built_in">len</span>(cols_numeric)-<span class="hljs-number">1</span><br>plt.figure(figsize=(<span class="hljs-number">4</span>*fcols,<span class="hljs-number">4</span>*frows))<br>i=<span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> var <span class="hljs-keyword">in</span> cols_numeric:<br>    <span class="hljs-keyword">if</span> var!=<span class="hljs-string">&#x27;target&#x27;</span>:<br>        dat = data_all[[var, <span class="hljs-string">&#x27;target&#x27;</span>]].dropna() <span class="hljs-comment"># 获取var列和target列。双重方括号[[  ]]用于选择多个列。</span><br>        <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        sns.distplot(dat[var] , fit=stats.norm);<br>        plt.title(var+<span class="hljs-string">&#x27; Original&#x27;</span>)<br>        plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        _=stats.probplot(dat[var], plot=plt)<br>        plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(dat[var])))<br>        plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        plt.plot(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>        plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(dat[var], dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br> <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class="hljs-number">1</span>)<br>        trans_var = scale_minmax(trans_var)      <br>        sns.distplot(trans_var , fit=stats.norm);<br>        plt.title(var+<span class="hljs-string">&#x27; Tramsformed&#x27;</span>)<br>        plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        _=stats.probplot(trans_var, plot=plt)<br>        plt.title(<span class="hljs-string">&#x27;skew=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(stats.skew(trans_var)))<br>        plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        plt.ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>        <br>        i+=<span class="hljs-number">1</span><br>        plt.subplot(frows,fcols,i)<br>        plt.plot(trans_var, dat[<span class="hljs-string">&#x27;target&#x27;</span>],<span class="hljs-string">&#x27;.&#x27;</span>,alpha=<span class="hljs-number">0.5</span>)<br>        plt.title(<span class="hljs-string">&#x27;corr=&#x27;</span>+<span class="hljs-string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(trans_var,dat[<span class="hljs-string">&#x27;target&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽预测-07模型融合/output_11_0.png" srcset="/img/loading.gif" lazyload></p><h2 id="box-cox变换">1.7 Box-Cox变换</h2><p>对特征进行Box-Cox变换，使其满足正态性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cols_transform=data_all.columns[<span class="hljs-number">0</span>:-<span class="hljs-number">2</span>]<br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> cols_transform:   <br>    <span class="hljs-comment"># transform column</span><br>    data_all.loc[:,col], _ = stats.boxcox(data_all.loc[:,col]+<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h4 id="代码解释">代码解释</h4><ol type="1"><li><p><code>cols_transform = data_all.columns[0:-2]</code>：获取<code>data_all</code>数据集中的所有列名，并使用切片操作<code>[0:-2]</code>选择从第一列到倒数第三列的所有列。</p></li><li><p><code>data_all.loc[:, col], _ = stats.boxcox(data_all.loc[:, col] + 1)</code>：应用了Box-Cox变换来转换指定的列<code>col</code>。<code>data_all.loc[:, col]</code>用于选择DataFrame中的特定列。<code>stats.boxcox()</code>接受一个一维数组作为输入，并返回Box-Cox变换后的结果和变换参数。在这里，原始列的值会先加1（避免零值），然后应用Box-Cox变换。转换后的结果会更新到<code>data_all</code>中的相应列，而下划线<code>_</code>表示不需要使用的变换参数则被忽略。</p></li></ol><h2 id="分位数计算和绘图">1.8 分位数计算和绘图</h2><p>标签数据统计转换后的数据，计算分位数画图展示（基于正态分布）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(data_all.target.describe())<br><br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>sns.distplot(data_all.target.dropna() , fit=stats.norm);<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>_=stats.probplot(data_all.target.dropna(), plot=plt)<br></code></pre></td></tr></table></figure><pre><code class="hljs">count    2888.000000
mean        0.126353
std         0.983966
min        -3.044000
25%        -0.350250
50%         0.313000
75%         0.793250
max         2.538000
Name: target, dtype: float64</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_17_1-169517575505519.png" srcset="/img/loading.gif" lazyload></p><h2 id="标签数据对数变换">1.9 标签数据对数变换</h2><p>标签数据对数变换数据，使数据更符合正态</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Log Transform SalePrice to improve normality</span><br>sp = data_train.target<br>data_train.target1 =np.power(<span class="hljs-number">1.5</span>,sp)<br><span class="hljs-built_in">print</span>(data_train.target1.describe())<br><br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>sns.distplot(data_train.target1.dropna(),fit=stats.norm);<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>_=stats.probplot(data_train.target1.dropna(), plot=plt)<br></code></pre></td></tr></table></figure><pre><code class="hljs">count    2888.000000
mean        1.129957
std         0.394110
min         0.291057
25%         0.867609
50%         1.135315
75%         1.379382
max         2.798463
Name: target, dtype: float64</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_19_1-169517575505520.png" srcset="/img/loading.gif" lazyload></p><h4 id="代码解释-1">代码解释</h4><ol type="1"><li><p><code>sp = data_train.target</code>：将<code>data_train</code>中的目标变量列赋值给变量<code>sp</code>。</p></li><li><p><code>data_train.target1 = np.power(1.5, sp)</code>：将对数变换应用于目标变量<code>sp</code>，使用了<code>np.power()</code>函数来计算1.5的<code>sp</code>次方，也就是对目标变量进行了一个指数转换。转换后的结果存储在<code>data_train</code>数据集中一个名为<code>target1</code>的新列中。</p></li><li><p><code>print(data_train.target1.describe())</code>：打印转换后的目标变量<code>target1</code>的描述统计信息，包括均值、标准差和分位数等。</p></li><li><p><code>plt.figure(figsize=(12,4))</code>：创建一个图形窗口，设置大小为（12,4）。</p></li><li><p><code>plt.subplot(1,2,1)</code>：在图形窗口中创建一个子图，总共有1行2列，当前子图位于第1个位置。</p></li><li><p><code>sns.distplot(data_train.target1.dropna(), fit=stats.norm)</code>：绘制直方图和核密度估计图，其中<code>data_train.target1.dropna()</code>是转换后的目标变量数据，<code>fit=stats.norm</code>表示通过正态分布拟合曲线来比较数据的分布情况。</p></li><li><p><code>plt.subplot(1,2,2)</code>：在图形窗口中创建一个子图，总共有1行2列，当前子图位于第2个位置。</p></li><li><p><code>_=stats.probplot(data_train.target1.dropna(), plot=plt)</code>：使用<code>stats.probplot()</code>函数绘制Q-Q图，用于检验数据是否服从正态分布。<code>data_train.target1.dropna()</code>是转换后的目标变量数据，<code>plot=plt</code>表示将Q-Q图绘制在指定的子图上。</p></li></ol><h1 id="获取训练和测试数据">2 获取训练和测试数据</h1><p>原先将训练集和测试集进行合并处理，现在进行拆分。使用简单交叉验证方法对模型进行验证，划为训练数据为70%，验证数据为30%</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># function to get training samples</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_training_data</span>():<br>    <span class="hljs-comment"># extract training samples</span><br>    <span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>    df_train = data_all[data_all[<span class="hljs-string">&quot;oringin&quot;</span>]==<span class="hljs-string">&quot;train&quot;</span>]<br>    df_train[<span class="hljs-string">&quot;label&quot;</span>]=data_train.target1<br>    <span class="hljs-comment"># split SalePrice and features</span><br>    y = df_train.target<br>    X = df_train.drop([<span class="hljs-string">&quot;oringin&quot;</span>,<span class="hljs-string">&quot;target&quot;</span>,<span class="hljs-string">&quot;label&quot;</span>],axis=<span class="hljs-number">1</span>)<br>    X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=<span class="hljs-number">0.3</span>,random_state=<span class="hljs-number">100</span>)<br>    <span class="hljs-keyword">return</span> X_train,X_valid,y_train,y_valid<br><br><span class="hljs-comment"># extract test data (without SalePrice)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_test_data</span>():<br>    df_test = data_all[data_all[<span class="hljs-string">&quot;oringin&quot;</span>]==<span class="hljs-string">&quot;test&quot;</span>].reset_index(drop=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> df_test.drop([<span class="hljs-string">&quot;oringin&quot;</span>,<span class="hljs-string">&quot;target&quot;</span>],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h1 id="模型评价函数">3 模型评价函数</h1><p>将RMSE和MSE作为模型性能的评价指标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> make_scorer<br><span class="hljs-comment"># metric for evaluation 自定义</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rmse</span>(<span class="hljs-params">y_true, y_pred</span>):<br>    diff = y_pred - y_true<br>    sum_sq = <span class="hljs-built_in">sum</span>(diff**<span class="hljs-number">2</span>)    <br>    n = <span class="hljs-built_in">len</span>(y_pred)   <br>    <span class="hljs-keyword">return</span> np.sqrt(sum_sq/n)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mse</span>(<span class="hljs-params">y_ture,y_pred</span>):<br>    <span class="hljs-keyword">return</span> mean_squared_error(y_ture,y_pred)<br><br><span class="hljs-comment"># scorer to be used in sklearn model fitting</span><br>rmse_scorer = make_scorer(rmse, greater_is_better=<span class="hljs-literal">False</span>) <span class="hljs-comment"># greater_is_better=False 意味着rmse越小越好</span><br>mse_scorer = make_scorer(mse, greater_is_better=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><h1 id="处理异常数据">4 处理异常数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># function to detect outliers based on the predictions of a model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_outliers</span>(<span class="hljs-params">model, X, y, sigma=<span class="hljs-number">3</span></span>):<br><br>    <span class="hljs-comment"># predict y values using model</span><br>    <span class="hljs-keyword">try</span>:<br>        y_pred = pd.Series(model.predict(X), index=y.index)<br>    <span class="hljs-comment"># if predicting fails, try fitting the model first</span><br>    <span class="hljs-keyword">except</span>:<br>        model.fit(X,y)<br>        y_pred = pd.Series(model.predict(X), index=y.index)<br>        <br>    <span class="hljs-comment"># calculate residuals between the model prediction and true y values</span><br>    resid = y - y_pred<br>    mean_resid = resid.mean()<br>    std_resid = resid.std()<br><br>    <span class="hljs-comment"># calculate z statistic, define outliers to be where |z|&gt;sigma</span><br>    z = (resid - mean_resid)/std_resid    <br>    outliers = z[<span class="hljs-built_in">abs</span>(z)&gt;sigma].index<br>    <br>    <span class="hljs-comment"># print and plot the results</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;R2=&#x27;</span>,model.score(X,y))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;rmse=&#x27;</span>,rmse(y, y_pred))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mse=&quot;</span>,mean_squared_error(y,y_pred))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---------------------------------------&#x27;</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mean of residuals:&#x27;</span>,mean_resid)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;std of residuals:&#x27;</span>,std_resid)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---------------------------------------&#x27;</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(outliers),<span class="hljs-string">&#x27;outliers:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(outliers.tolist())<br><br>    plt.figure(figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>))<br>    ax_131 = plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br>    plt.plot(y,y_pred,<span class="hljs-string">&#x27;.&#x27;</span>)<br>    plt.plot(y.loc[outliers],y_pred.loc[outliers],<span class="hljs-string">&#x27;ro&#x27;</span>)<br>    plt.legend([<span class="hljs-string">&#x27;Accepted&#x27;</span>,<span class="hljs-string">&#x27;Outlier&#x27;</span>])<br>    plt.xlabel(<span class="hljs-string">&#x27;y&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;y_pred&#x27;</span>);<br><br>    ax_132=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>)<br>    plt.plot(y,y-y_pred,<span class="hljs-string">&#x27;.&#x27;</span>)<br>    plt.plot(y.loc[outliers],y.loc[outliers]-y_pred.loc[outliers],<span class="hljs-string">&#x27;ro&#x27;</span>)<br>    plt.legend([<span class="hljs-string">&#x27;Accepted&#x27;</span>,<span class="hljs-string">&#x27;Outlier&#x27;</span>])<br>    plt.xlabel(<span class="hljs-string">&#x27;y&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;y - y_pred&#x27;</span>);<br><br>    ax_133=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br>    z.plot.hist(bins=<span class="hljs-number">50</span>,ax=ax_133)<br>    z.loc[outliers].plot.hist(color=<span class="hljs-string">&#x27;r&#x27;</span>,bins=<span class="hljs-number">50</span>,ax=ax_133)<br>    plt.legend([<span class="hljs-string">&#x27;Accepted&#x27;</span>,<span class="hljs-string">&#x27;Outlier&#x27;</span>])<br>    plt.xlabel(<span class="hljs-string">&#x27;z&#x27;</span>)<br>    <br>    plt.savefig(<span class="hljs-string">&#x27;outliers.png&#x27;</span>)<br>    <br>    <span class="hljs-keyword">return</span> outliers<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># get training data</span><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Ridge<br>X_train, X_valid,y_train,y_valid = get_training_data()<br>test=get_test_data()<br><br><span class="hljs-comment"># find and remove outliers using a Ridge model</span><br>outliers = find_outliers(Ridge(), X_train, y_train)<br><br><span class="hljs-comment"># permanently remove these outliers from the data</span><br><span class="hljs-comment">#df_train = data_all[data_all[&quot;oringin&quot;]==&quot;train&quot;]</span><br><span class="hljs-comment">#df_train[&quot;label&quot;]=data_train.target1</span><br><span class="hljs-comment">#df_train=df_train.drop(outliers)</span><br>X_outliers=X_train.loc[outliers]<br>y_outliers=y_train.loc[outliers]<br>X_t=X_train.drop(outliers)<br>y_t=y_train.drop(outliers)<br></code></pre></td></tr></table></figure><pre><code class="hljs">R2= 0.8794138468263233
rmse= 0.34510338853546346
mse= 0.11909634877865903
---------------------------------------
mean of residuals: -2.96425702171071e-16
std of residuals: 0.3451887995969211
---------------------------------------
23 outliers:
[2655, 2159, 1164, 2863, 1145, 2697, 2528, 2645, 691, 1085, 1874, 2647, 776, 2625, 884, 2696, 2668, 1310, 1901, 2769, 2002, 2669, 1040]</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_27_1-169517575505521.png" srcset="/img/loading.gif" lazyload></p><h1 id="网格搜索训练模型">5 网格搜索训练模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_trainning_data_omitoutliers</span>():<br>    y1=y_t.copy()<br>    X1=X_t.copy()<br>    <span class="hljs-keyword">return</span> X1,y1<br></code></pre></td></tr></table></figure><p>使用网格搜索训练模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">model, param_grid=[], X=[], y=[], </span><br><span class="hljs-params">                splits=<span class="hljs-number">5</span>, repeats=<span class="hljs-number">5</span></span>):<br><br>    <span class="hljs-comment"># get unmodified training data, unless data to use already specified </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y)==<span class="hljs-number">0</span>:<br>        X,y = get_trainning_data_omitoutliers()<br>        <span class="hljs-comment">#poly_trans=PolynomialFeatures(degree=2)</span><br>        <span class="hljs-comment">#X=poly_trans.fit_transform(X)</span><br>        <span class="hljs-comment">#X=MinMaxScaler().fit_transform(X)</span><br>    <br>    <span class="hljs-comment"># create cross-validation method</span><br>    rkfold = RepeatedKFold(n_splits=splits, n_repeats=repeats)<br>    <br>    <span class="hljs-comment"># perform a grid search if param_grid given</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(param_grid)&gt;<span class="hljs-number">0</span>:<br>        <span class="hljs-comment"># setup grid search parameters</span><br>        gsearch = GridSearchCV(model, param_grid, cv=rkfold,<br>                               scoring=<span class="hljs-string">&quot;neg_mean_squared_error&quot;</span>,<br>                               verbose=<span class="hljs-number">1</span>, return_train_score=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># search the grid</span><br>        gsearch.fit(X,y)<br><br>        <span class="hljs-comment"># extract best model from the grid</span><br>        model = gsearch.best_estimator_        <br>        best_idx = gsearch.best_index_ <span class="hljs-comment"># 获取最佳模型的索引</span><br> <br>        <span class="hljs-comment"># get cv-scores for best model</span><br>        grid_results = pd.DataFrame(gsearch.cv_results_) <span class="hljs-comment"># .cv_results_ 每个参数组合的得分、标准差等信息       </span><br>        cv_mean = <span class="hljs-built_in">abs</span>(grid_results.loc[best_idx,<span class="hljs-string">&#x27;mean_test_score&#x27;</span>])<br>        cv_std = grid_results.loc[best_idx,<span class="hljs-string">&#x27;std_test_score&#x27;</span>]<br><br>    <span class="hljs-comment"># no grid search, just cross-val score for given model    </span><br>    <span class="hljs-keyword">else</span>:<br>        grid_results = []<br>        cv_results = cross_val_score(model, X, y, scoring=<span class="hljs-string">&quot;neg_mean_squared_error&quot;</span>, cv=rkfold)<br>        cv_mean = <span class="hljs-built_in">abs</span>(np.mean(cv_results))<br>        cv_std = np.std(cv_results)<br>    <br>    <span class="hljs-comment"># combine mean and std cv-score in to a pandas series</span><br>    cv_score = pd.Series(&#123;<span class="hljs-string">&#x27;mean&#x27;</span>:cv_mean,<span class="hljs-string">&#x27;std&#x27;</span>:cv_std&#125;)<br><br>    <span class="hljs-comment"># predict y using the fitted model</span><br>    y_pred = model.predict(X)<br>    <br>    <span class="hljs-comment"># print stats on model performance         </span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;----------------------&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(model)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;----------------------&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;score=&#x27;</span>,model.score(X,y))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;rmse=&#x27;</span>,rmse(y, y_pred))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mse=&#x27;</span>,mse(y, y_pred))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;cross_val: mean=&#x27;</span>,cv_mean,<span class="hljs-string">&#x27;, std=&#x27;</span>,cv_std)<br>    <br>    <span class="hljs-comment"># residual plots</span><br>    y_pred = pd.Series(y_pred,index=y.index)<br>    resid = y - y_pred<br>    mean_resid = resid.mean()<br>    std_resid = resid.std()<br>    z = (resid - mean_resid)/std_resid    <br>    n_outliers = <span class="hljs-built_in">sum</span>(<span class="hljs-built_in">abs</span>(z)&gt;<span class="hljs-number">3</span>)<br>    <br>    plt.figure(figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>))<br>    ax_131 = plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br>    plt.plot(y,y_pred,<span class="hljs-string">&#x27;.&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;y&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;y_pred&#x27;</span>);<br>    plt.title(<span class="hljs-string">&#x27;corr = &#123;:.3f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.corrcoef(y,y_pred)[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br>    ax_132=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>)<br>    plt.plot(y,y-y_pred,<span class="hljs-string">&#x27;.&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;y&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;y - y_pred&#x27;</span>);<br>    plt.title(<span class="hljs-string">&#x27;std resid = &#123;:.3f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(std_resid))<br>    <br>    ax_133=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br>    z.plot.hist(bins=<span class="hljs-number">50</span>,ax=ax_133)<br>    plt.xlabel(<span class="hljs-string">&#x27;z&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;&#123;:.0f&#125; samples with z&gt;3&#x27;</span>.<span class="hljs-built_in">format</span>(n_outliers))<br><br>    <span class="hljs-keyword">return</span> model, cv_score, grid_results<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># places to store optimal models and scores</span><br>opt_models = <span class="hljs-built_in">dict</span>()<br>score_models = pd.DataFrame(columns=[<span class="hljs-string">&#x27;mean&#x27;</span>,<span class="hljs-string">&#x27;std&#x27;</span>])<br><br><span class="hljs-comment"># no. k-fold splits</span><br>splits=<span class="hljs-number">5</span><br><span class="hljs-comment"># no. k-fold iterations</span><br>repeats=<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><h1 id="单一模型训练">6 单一模型训练</h1><h2 id="岭回归">6.1 岭回归</h2><p>使用岭回归模型对数据进行预测，采用RMSE,MSE等指标对模型性能进行评价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;Ridge&#x27;</span><br><br>opt_models[model] = Ridge()<br>alph_range = np.arange(<span class="hljs-number">0.25</span>,<span class="hljs-number">6</span>,<span class="hljs-number">0.25</span>)<br>param_grid = &#123;<span class="hljs-string">&#x27;alpha&#x27;</span>: alph_range&#125;<br><br>opt_models[model],cv_score,grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=repeats)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br><br>plt.figure()<br>plt.errorbar(alph_range, <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;mean_test_score&#x27;</span>]),<br>             <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*repeats))<br>plt.xlabel(<span class="hljs-string">&#x27;alpha&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;score&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 25 folds for each of 23 candidates, totalling 575 fits
----------------------
Ridge(alpha=0.25)
----------------------
score= 0.8963563380306225
rmse= 0.31899649233050603
mse= 0.1017587621191668
cross_val: mean= 0.10644934256965052 , std= 0.005302313654798051





Text(0, 0.5, &#39;score&#39;)</code></pre><p>​<br><img src="/img/工业蒸汽预测-07模型融合/output_34_2.png" srcset="/img/loading.gif" lazyload> ​</p><p><img src="/img/工业蒸汽预测-07模型融合/output_34_3-169517575505523.png" srcset="/img/loading.gif" lazyload></p><p>上面的图形主要反映了模型预测的准确度及拟合情况，后面的模型也将进行类似的可视化分析。这里对图形展示的信息进行介绍，从左至右依次如下：</p><pre><code class="hljs">(1)真实值（横轴：y)与模型预测值（竖轴：y pred)的散点图，图形上方显示了相关性数值，其越接近1越好。对于岭回归模型，相关性数值为0.947，预测值与真实值比较一致。

(2)其为在交叉验证训练模型时，真实值（横轴：y)与模型预测值和真实值的残差（竖轴：y-y_pred)的散点图，图形上方显示了方差，其越小说明模型越稳定。可以看到，对于岭回归模型，在真实值y=-3附近的预测值有较大的偏差，同时，方差为0.319，较为稳定。

(3)图是由模型预测值和真实值的残差（横轴：z=(resid-mean resid)/std resid)与落在按z轴划分区间的频率（竖轴：频数）所画的直方图，图形上方显示了预测值与真实值的残差大于三倍标准差的数，其越小越好，越大说明预测中有些样本的偏差很大。对于岭回归模型，预测值与真实值的残差大于三倍标准差的数为5个，模型对偏差大的数据有较好的包容性。

(4)岭回归模型的参数（横轴：alpha)与模型的评价指标MSE(竖轴：score)的误差棒图。
可以看出，对于岭回归模型，随着alpha的增大，评价指标MSE的数值也越来越大，其模型的方差也逐渐增大。</code></pre><p>​</p><h4 id="代码解释-2">代码解释</h4><ol type="1"><li></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">cv_score.name = model<br>score_models = score_models.append(cv_score)<br>````<br><br>```python<br><span class="hljs-built_in">print</span>(cv_score.name)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-------&quot;</span>)<br><span class="hljs-built_in">print</span>(score_models)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 结果</span><br>Ridge<br>-------<br>           mean       std<br>Ridge  <span class="hljs-number">0.106211</span>  <span class="hljs-number">0.007446</span><br></code></pre></td></tr></table></figure><hr><ol start="2" type="1"><li></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.errorbar(alph_range, <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;mean_test_score&#x27;</span>]),<br>             <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*repeats))<br></code></pre></td></tr></table></figure><p>代码根据给定的数据点集合在图表上绘制条形图，并添加以标准误差为高度的误差线。</p><ul><li><code>errorbar()</code> 用于绘制带有误差线的条形图。</li></ul><p>参数解释:</p><ul><li><code>alph_range</code> 是 x 轴上的数据点集合，它表示自变量的取值范围。</li><li><code>abs(grid_results['mean_test_score'])</code> 是 y 轴上的数据点集合，它表示不同自变量取值下的平均测试分数的绝对值。</li><li><code>abs(grid_results['std_test_score'])/np.sqrt(splits*repeats)</code> 是误差条的高度。<code>grid_results['std_test_score']</code> 表示测试分数的标准差，而 <code>splits</code> 和 <code>repeats</code> 是进行交叉验证时划分数据集的折数和重复次数，通过除以sqrt(splits*repeats) 来将标准差转换为标准误差。</li></ul><p>​</p><h2 id="lasso回归">6.2 Lasso回归</h2><p>使用Lasso回归模型对数据进行预测，采用RMSE,MSE等指标对模型性能进行评价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;Lasso&#x27;</span><br><br>opt_models[model] = Lasso()<br>alph_range = np.arange(<span class="hljs-number">1e-4</span>,<span class="hljs-number">1e-3</span>,<span class="hljs-number">4e-5</span>)<br>param_grid = &#123;<span class="hljs-string">&#x27;alpha&#x27;</span>: alph_range&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=repeats)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br><br>plt.figure()<br>plt.errorbar(alph_range, <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;mean_test_score&#x27;</span>]),<span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*repeats))<br>plt.xlabel(<span class="hljs-string">&#x27;alpha&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;score&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 25 folds for each of 23 candidates, totalling 575 fits
----------------------
Lasso(alpha=0.0001)
----------------------
score= 0.8965376022911505
rmse= 0.3187174209135977
mse= 0.10158079439381539
cross_val: mean= 0.1062923603647315 , std= 0.007051871077111589



Text(0, 0.5, &#39;score&#39;)</code></pre><p>​<br><img src="/img/工业蒸汽预测-07模型融合/output_40_2.png" srcset="/img/loading.gif" lazyload> ​</p><p><img src="/img/工业蒸汽预测-07模型融合/output_40_3-169517575505525.png" srcset="/img/loading.gif" lazyload></p><h2 id="elasticnet-回归">6.3 ElasticNet 回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">model =<span class="hljs-string">&#x27;ElasticNet&#x27;</span><br>opt_models[model] = ElasticNet()<br><br>param_grid = &#123;<span class="hljs-string">&#x27;alpha&#x27;</span>: np.arange(<span class="hljs-number">1e-4</span>,<span class="hljs-number">1e-3</span>,<span class="hljs-number">1e-4</span>),<br>              <span class="hljs-string">&#x27;l1_ratio&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">0.1</span>),<br>              <span class="hljs-string">&#x27;max_iter&#x27;</span>:[<span class="hljs-number">100000</span>]&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=<span class="hljs-number">1</span>)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 5 folds for each of 81 candidates, totalling 405 fits
----------------------
ElasticNet(alpha=0.0001, l1_ratio=0.9, max_iter=100000)
----------------------
score= 0.8965268226984906
rmse= 0.3187340238271355
mse= 0.10159137794503677
cross_val: mean= 0.10558612445735098 , std= 0.006931804612280223</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_42_1-169517575505526.png" srcset="/img/loading.gif" lazyload></p><h2 id="svr回归">6.4 SVR回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">model=<span class="hljs-string">&#x27;LinearSVR&#x27;</span><br>opt_models[model] = LinearSVR()<br><br>crange = np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">0.1</span>)<br>param_grid = &#123;<span class="hljs-string">&#x27;C&#x27;</span>:crange,<br>             <span class="hljs-string">&#x27;max_iter&#x27;</span>:[<span class="hljs-number">1000</span>]&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=repeats)<br><br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br><br>plt.figure()<br>plt.errorbar(crange, <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;mean_test_score&#x27;</span>]),<span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*repeats))<br>plt.xlabel(<span class="hljs-string">&#x27;C&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;score&#x27;</span>)<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 25 folds for each of 9 candidates, totalling 225 fits
----------------------
LinearSVR(C=0.4)
----------------------
score= 0.30645151350483657
rmse= 0.8251880824335185
mse= 0.680935371390307
cross_val: mean= 0.9136545268818084 , std= 0.5904526473477509





Text(0, 0.5, &#39;score&#39;)</code></pre><p>​<br><img src="/img/工业蒸汽预测-07模型融合/output_44_2.png" srcset="/img/loading.gif" lazyload> ​</p><p><img src="/img/工业蒸汽预测-07模型融合/output_44_3-169517575505529.png" srcset="/img/loading.gif" lazyload></p><h2 id="k近邻">6.5 K近邻</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;KNeighbors&#x27;</span><br>opt_models[model] = KNeighborsRegressor()<br><br>param_grid = &#123;<span class="hljs-string">&#x27;n_neighbors&#x27;</span>:np.arange(<span class="hljs-number">3</span>,<span class="hljs-number">11</span>,<span class="hljs-number">1</span>)&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=<span class="hljs-number">1</span>)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br><br>plt.figure()<br>plt.errorbar(np.arange(<span class="hljs-number">3</span>,<span class="hljs-number">11</span>,<span class="hljs-number">1</span>), <span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;mean_test_score&#x27;</span>]),<span class="hljs-built_in">abs</span>(grid_results[<span class="hljs-string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*<span class="hljs-number">1</span>))<br>plt.xlabel(<span class="hljs-string">&#x27;n_neighbors&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;score&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 5 folds for each of 8 candidates, totalling 40 fits
----------------------
KNeighborsRegressor(n_neighbors=10)
----------------------
score= 0.7188007679386812
rmse= 0.5254381453364182
mse= 0.27608524457457456
cross_val: mean= 0.35006829225711783 , std= 0.04461643597140863





Text(0, 0.5, &#39;score&#39;)</code></pre><p>​<br><img src="/img/工业蒸汽预测-07模型融合/output_46_2.png" srcset="/img/loading.gif" lazyload> ​</p><p><img src="/img/工业蒸汽预测-07模型融合/output_46_3-169517575505530.png" srcset="/img/loading.gif" lazyload></p><h1 id="模型融合-boosting方法">7 模型融合 Boosting方法</h1><p>把n个比较弱的模型，组合成一个比较强的模型。类似于随机森林。</p><h2 id="gbdt-模型">7.1 GBDT 模型</h2><p>使用 Gradient Boosting模型对数据进行预测，采用RMSE,MSE等指标对模型性能进行评价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;GradientBoosting&#x27;</span><br>opt_models[model] = GradientBoostingRegressor()<br><br>param_grid = &#123;<span class="hljs-string">&#x27;n_estimators&#x27;</span>:[<span class="hljs-number">150</span>,<span class="hljs-number">250</span>,<span class="hljs-number">350</span>],<br>              <span class="hljs-string">&#x27;max_depth&#x27;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],<br>              <span class="hljs-string">&#x27;min_samples_split&#x27;</span>:[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=<span class="hljs-number">1</span>)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 5 folds for each of 27 candidates, totalling 135 fits
----------------------
GradientBoostingRegressor(min_samples_split=6, n_estimators=250)
----------------------
score= 0.9677208586746097
rmse= 0.17802275580033733
mse= 0.03169210158274656
cross_val: mean= 0.09849105444854306 , std= 0.014499755846113458</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_48_1.png" srcset="/img/loading.gif" lazyload></p><h2 id="xgboost模型">7.2 XGBoost模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;XGB&#x27;</span><br>opt_models[model] = XGBRegressor()<br><br>param_grid = &#123;<span class="hljs-string">&#x27;n_estimators&#x27;</span>:[<span class="hljs-number">100</span>,<span class="hljs-number">200</span>,<span class="hljs-number">300</span>,<span class="hljs-number">400</span>,<span class="hljs-number">500</span>],<br>              <span class="hljs-string">&#x27;max_depth&#x27;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],<br>             &#125;<br><br>opt_models[model], cv_score,grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=splits, repeats=<span class="hljs-number">1</span>)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 5 folds for each of 15 candidates, totalling 75 fits
----------------------
XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#39;depthwise&#39;,
             importance_type=None, interaction_constraints=&#39;&#39;,
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints=&#39;()&#39;, n_estimators=100, n_jobs=0,
             num_parallel_tree=1, predictor=&#39;auto&#39;, random_state=0, reg_alpha=0,
             reg_lambda=1, ...)
----------------------
score= 0.9702586237542838
rmse= 0.1708815062712164
mse= 0.029200489185519693
cross_val: mean= 0.10472580078722642 , std= 0.006953064644267524</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_50_1.png" srcset="/img/loading.gif" lazyload></p><h2 id="随机森林模型">7.3 随机森林模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">model = <span class="hljs-string">&#x27;RandomForest&#x27;</span><br>opt_models[model] = RandomForestRegressor()<br><br>param_grid = &#123;<span class="hljs-string">&#x27;n_estimators&#x27;</span>:[<span class="hljs-number">100</span>,<span class="hljs-number">150</span>,<span class="hljs-number">200</span>],<br>              <span class="hljs-string">&#x27;max_features&#x27;</span>:[<span class="hljs-number">8</span>,<span class="hljs-number">12</span>,<span class="hljs-number">16</span>,<span class="hljs-number">20</span>,<span class="hljs-number">24</span>],<br>              <span class="hljs-string">&#x27;min_samples_split&#x27;</span>:[<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>]&#125;<br><br>opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, <br>                                              splits=<span class="hljs-number">5</span>, repeats=<span class="hljs-number">1</span>)<br><br>cv_score.name = model<br>score_models = score_models.append(cv_score)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Fitting 5 folds for each of 45 candidates, totalling 225 fits
----------------------
RandomForestRegressor(max_features=16, n_estimators=150)
----------------------
score= 0.9856162598758819
rmse= 0.11883666269492393
mse= 0.01412215240046713
cross_val: mean= 0.10239417326207083 , std= 0.006602546408163406</code></pre><p><img src="/img/工业蒸汽预测-07模型融合/output_52_1.png" srcset="/img/loading.gif" lazyload></p><h1 id="多模型预测-bagging方法">8 多模型预测 Bagging方法</h1><p>Bagging 通常对分类任务使用简单投票法，对回归任务使用简单平均法.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_predict</span>(<span class="hljs-params">test_data,test_y=[],stack=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-comment">#poly_trans=PolynomialFeatures(degree=2)</span><br>    <span class="hljs-comment">#test_data1=poly_trans.fit_transform(test_data)</span><br>    <span class="hljs-comment">#test_data=MinMaxScaler().fit_transform(test_data)</span><br>    i=<span class="hljs-number">0</span><br>    y_predict_total=np.zeros((test_data.shape[<span class="hljs-number">0</span>],))<br>    <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> opt_models.keys():<br>        <span class="hljs-keyword">if</span> model!=<span class="hljs-string">&quot;LinearSVR&quot;</span> <span class="hljs-keyword">and</span> model!=<span class="hljs-string">&quot;KNeighbors&quot;</span>:<br>            y_predict=opt_models[model].predict(test_data)<br>            y_predict_total+=y_predict<br>            i+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(test_y)&gt;<span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;_mse:&quot;</span>.<span class="hljs-built_in">format</span>(model),mean_squared_error(y_predict,test_y))<br>    y_predict_mean=np.<span class="hljs-built_in">round</span>(y_predict_total/i,<span class="hljs-number">3</span>) <span class="hljs-comment"># 模型融合的mean</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(test_y)&gt;<span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mean_mse:&quot;</span>,mean_squared_error(y_predict_mean,test_y))<br>    <span class="hljs-keyword">else</span>:<br>        y_predict_mean=pd.Series(y_predict_mean)<br>        <span class="hljs-keyword">return</span> y_predict_mean<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model_predict(X_valid,y_valid)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Ridge_mse: 0.137671879096647
Lasso_mse: 0.13786142881850508
ElasticNet_mse: 0.1378268557408619
LinearSVR_mse: 0.1378268557408619
KNeighbors_mse: 0.1378268557408619
GradientBoosting_mse: 0.1345410925334943
XGB_mse: 0.14010339249433112
RandomForest_mse: 0.13880263283624247
mean_mse: 0.12569497923875433</code></pre><h4 id="代码解释-3">代码解释</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_predict</span>(<span class="hljs-params">test_data, test_y=[], stack=<span class="hljs-literal">False</span></span>):<br>    i = <span class="hljs-number">0</span><br>    y_predict_total = np.zeros((test_data.shape[<span class="hljs-number">0</span>],))<br></code></pre></td></tr></table></figure><p>这里定义了一个名为 <code>model_predict</code> 的函数，它接受三个参数：<code>test_data</code>（待预测的测试数据），<code>test_y</code>（可选的真实标签），<code>stack</code>（是否进行堆叠）。函数中初始化了变量 <code>i</code> 和 <code>y_predict_total</code>，其中 <code>i</code> 用于计算参与预测的模型数量，<code>y_predict_total</code> 是一个形状与 <code>test_data</code> 行数相同的全零数组，用于累加每个模型的预测结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> opt_models.keys():<br>    <span class="hljs-keyword">if</span> model != <span class="hljs-string">&quot;LinearSVR&quot;</span> <span class="hljs-keyword">and</span> model != <span class="hljs-string">&quot;KNeighbors&quot;</span>:<br>        y_predict = opt_models[model].predict(test_data)<br>        y_predict_total += y_predict<br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(test_y) &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;_mse:&quot;</span>.<span class="hljs-built_in">format</span>(model), mean_squared_error(y_predict, test_y))<br></code></pre></td></tr></table></figure><p>这部分使用 <code>for</code> 循环遍历 <code>opt_models</code> 字典的键。这个字典存储了优化后的模型。在循环中，根据特定的条件判断，跳过了特定的两个模型（"LinearSVR" 和 "KNeighbors"）。然后，使用对应模型 <code>model</code> 对测试数据 <code>test_data</code> 进行预测，并将预测结果累加到 <code>y_predict_total</code> 中。同时，更新 <code>i</code> 的值。如果提供了真实标签 <code>test_y</code>，则计算并输出该模型的均方误差（MSE）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">y_predict_mean = np.<span class="hljs-built_in">round</span>(y_predict_total / i, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>这里计算了平均预测结果 <code>y_predict_mean</code>，通过将 <code>y_predict_total</code> 除以 <code>i</code> 得到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(test_y) &gt; <span class="hljs-number">0</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mean_mse:&quot;</span>, mean_squared_error(y_predict_mean, test_y))<br><span class="hljs-keyword">else</span>:<br>    y_predict_mean = pd.Series(y_predict_mean)<br>    <span class="hljs-keyword">return</span> y_predict_mean<br></code></pre></td></tr></table></figure><p>这部分首先判断是否提供了真实标签 <code>test_y</code>。如果提供了，计算并输出平均预测结果 <code>y_predict_mean</code> 和真实标签之间的均方误差（MSE）。如果没有提供真实标签，则将 <code>y_predict_mean</code> 转换为 Pandas Series 对象并返回。</p><p>代码的整体思路是：</p><ul><li>遍历存储了优化后模型的字典 <code>opt_models</code> 的键。</li><li>对于每个模型，根据特定条件进行预测，然后将预测结果累加到 <code>y_predict_total</code> 中。</li><li>计算平均预测结果并返回或输出与真实标签的均方误差（如果提供了真实标签）。</li></ul><p>目的是对一组模型进行预测，并计算它们的平均预测结果或与真实标签的均方误差。如果没有提供真实标签，它将返回一个包含平均预测结果的 Pandas Series 对象。</p><p>可以看到，模型融合预测的MSE最小，预测性能最优。</p><h1 id="多模型融合-stacking方法">9 多模型融合 Stacking方法</h1><p>https://blog.csdn.net/m0_47256162/article/details/119979540</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib.gridspec <span class="hljs-keyword">as</span> gridspec <span class="hljs-comment"># 创建多维子图网格的模块</span><br><span class="hljs-keyword">import</span> itertools<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><br><span class="hljs-comment">##主要使用pip install mlxtend安装mlxtend</span><br><span class="hljs-keyword">from</span> mlxtend.classifier <span class="hljs-keyword">import</span> EnsembleVoteClassifier<br><span class="hljs-keyword">from</span> mlxtend.data <span class="hljs-keyword">import</span> iris_data<br><span class="hljs-keyword">from</span> mlxtend.plotting <span class="hljs-keyword">import</span> plot_decision_regions<br>%matplotlib inline<br><br><span class="hljs-comment"># Initializing Classifiers</span><br>clf1 = LogisticRegression(random_state=<span class="hljs-number">0</span>)<br>clf2 = RandomForestClassifier(random_state=<span class="hljs-number">0</span>)<br>clf3 = SVC(random_state=<span class="hljs-number">0</span>, probability=<span class="hljs-literal">True</span>)<br>eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], voting=<span class="hljs-string">&#x27;soft&#x27;</span>)<br><br><span class="hljs-comment"># Loading some example data</span><br>X, y = iris_data()<br>X = X[:,[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]]<br><br><span class="hljs-comment"># Plotting Decision Regions</span><br>gs = gridspec.GridSpec(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>fig = plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br><br><span class="hljs-keyword">for</span> clf, lab, grd <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>([clf1, clf2, clf3, eclf],<br>                         [<span class="hljs-string">&#x27;Logistic Regression&#x27;</span>, <span class="hljs-string">&#x27;Random Forest&#x27;</span>, <span class="hljs-string">&#x27;RBF kernel SVM&#x27;</span>, <span class="hljs-string">&#x27;Ensemble&#x27;</span>],<br>                         itertools.product([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], repeat=<span class="hljs-number">2</span>)):<br>    clf.fit(X, y)<br>    ax = plt.subplot(gs[grd[<span class="hljs-number">0</span>], grd[<span class="hljs-number">1</span>]])<br>    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=<span class="hljs-number">2</span>)<br>    plt.title(lab)<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-07模型融合/output_59_0.png" srcset="/img/loading.gif" lazyload> ​</p><h4 id="代码解释-4">代码解释</h4><p><code>EnsembleVoteClassifier()</code></p><p>用于创建集成投票分类器。它可以将多个基分类器的预测结果进行投票，从而得到集成分类器的最终预测结果。</p><p>参数包括：</p><ul><li><code>clfs</code>：一个列表，包含要集成的基分类器对象。</li><li><code>voting</code>：设置投票方式，可选的取值为<code>'hard'</code>或<code>'soft'</code>，分别表示硬投票和软投票。硬投票是指根据少数服从多数的原则选择最多数量的类别作为预测结果，而软投票则是根据分类器预测的概率进行加权计算，并选择概率加权总和最大的类别作为预测结果。</li><li><code>weights</code>：一个可选的列表，用于指定每个基分类器的权重。如果未指定，则默认所有分类器的权重相等。</li></ul><hr><ol type="1"><li><p><code>for clf, lab, grd in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'], itertools.product([0, 1], repeat=2)):</code>：</p><ul><li><code>zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'], itertools.product([0, 1], repeat=2))</code>将分类器列表、标签列表和网格坐标的笛卡尔积打包在一起，返回一个迭代器。每次迭代返回一个元组<code>(clf, lab, grd)</code>，其中<code>clf</code>表示分类器对象，<code>lab</code>表示标签，<code>grd</code>表示网格坐标。</li><li><code>for clf, lab, grd in ...:</code>遍历迭代器中的每个元组，依次赋值给变量<code>clf</code>、<code>lab</code>和<code>grd</code>。</li></ul></li><li><p><code>clf.fit(X, y)</code>：使用当前分类器<code>clf</code>拟合数据集<code>X</code>和目标变量<code>y</code>，即进行训练。</p></li><li><p><code>ax = plt.subplot(gs[grd[0], grd[1]])</code>：在网格规则对象<code>gs</code>上创建一个子图对象，并将其赋值给变量<code>ax</code>。通过索引<code>grd[0]</code>和<code>grd[1]</code>，选择网格规则中的坐标位置。</p></li><li><p><code>fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)</code>：使用<code>mlxtend.plotting</code>模块的<code>plot_decision_regions</code>函数，在当前子图上绘制决策边界。传入参数包括输入数据集<code>X</code>、目标变量<code>y</code>、当前分类器<code>clf</code>，以及将图例放置的位置<code>legend=2</code>。绘制结果会返回一个图形对象，将其赋值给变量<code>fig</code>。</p></li><li><p><code>plt.title(lab)</code>：设置当前子图的标题为相应的标签<code>lab</code>。</p></li><li><p>最后一行<code>plt.show()</code>：显示整个图形，包含所有子图和决策边界。</p></li></ol><p>通过这段代码，可以实现对每个分类器的训练和决策边界的绘制，并在同一个图形中进行比较和展示。每个分类器都会有一个独立的子图，显示相应的决策边界和标签。最后，通过<code>plt.show()</code>将整个图形显示出来。</p><h1 id="工业蒸汽赛题多模型融合-stacking方法">10工业蒸汽赛题多模型融合 stacking方法</h1><h2 id="基础代码">10.1 基础代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> sparse<br><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> lightgbm<br><br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br><br><span class="hljs-comment"># 针对于一个模型进行K折交叉验证的函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">stacking_reg</span>(<span class="hljs-params">clf,train_x,train_y,test_x,clf_name,kf,label_split=<span class="hljs-literal">None</span></span>):<br>    train=np.zeros((train_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test=np.zeros((test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test_pre=np.empty((folds,test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>)) <span class="hljs-comment"># 对话详解</span><br>    cv_scores=[]<br>    <span class="hljs-keyword">for</span> i,(train_index,test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(train_x,label_split)):       <br>        tr_x=train_x[train_index]<br>        tr_y=train_y[train_index]<br>        te_x=train_x[test_index]<br>        te_y = train_y[test_index]<br>        <span class="hljs-keyword">if</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;rf&quot;</span>,<span class="hljs-string">&quot;ada&quot;</span>,<span class="hljs-string">&quot;gb&quot;</span>,<span class="hljs-string">&quot;et&quot;</span>,<span class="hljs-string">&quot;lr&quot;</span>,<span class="hljs-string">&quot;lsvc&quot;</span>,<span class="hljs-string">&quot;knn&quot;</span>]:<br>            clf.fit(tr_x,tr_y)<br>            pre=clf.predict(te_x).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) <span class="hljs-comment"># 对话详解</span><br>            train[test_index]=pre<br>            test_pre[i,:]=clf.predict(test_x).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>            cv_scores.append(mean_squared_error(te_y, pre))<br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;xgb&quot;</span>]:<br>            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-<span class="hljs-number">1</span>) <span class="hljs-comment"># 对话详解</span><br>            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-<span class="hljs-number">1</span>)<br>            z = clf.DMatrix(test_x, label=te_y, missing=-<span class="hljs-number">1</span>)<br>            params = &#123;<span class="hljs-string">&#x27;booster&#x27;</span>: <span class="hljs-string">&#x27;gbtree&#x27;</span>,<br>                      <span class="hljs-string">&#x27;eval_metric&#x27;</span>: <span class="hljs-string">&#x27;rmse&#x27;</span>,<br>                      <span class="hljs-string">&#x27;gamma&#x27;</span>: <span class="hljs-number">1</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;max_depth&#x27;</span>: <span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;eta&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span><br>                      &#125;<br>            num_round = <span class="hljs-number">10000</span><br>            early_stopping_rounds = <span class="hljs-number">100</span><br>            watchlist = [(train_matrix, <span class="hljs-string">&#x27;train&#x27;</span>),<br>                         (test_matrix, <span class="hljs-string">&#x27;eval&#x27;</span>)<br>                         ]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,<br>                                  early_stopping_rounds=early_stopping_rounds<br>                                  )<br>                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                train[test_index]=pre<br>                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(mean_squared_error(te_y, pre))<br><br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lgb&quot;</span>]:<br>            train_matrix = clf.Dataset(tr_x, label=tr_y)<br>            test_matrix = clf.Dataset(te_x, label=te_y)<br>            <span class="hljs-comment">#z = clf.Dataset(test_x, label=te_y)</span><br>            <span class="hljs-comment">#z=test_x</span><br>            params = &#123;<br>                      <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>                      <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;regression_l2&#x27;</span>,<br>                      <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;mse&#x27;</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">2</span>**<span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda_l2&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span>,<br>                      <span class="hljs-string">&#x27;silent&#x27;</span>: <span class="hljs-literal">True</span>,<br>                      &#125;<br>            num_round = <span class="hljs-number">10000</span><br>            callbacks=[lightgbm.log_evaluation(period=<span class="hljs-number">100</span>), lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,<br>                                  callbacks = callbacks<br>                                  )<br>                pre= model.predict(te_x,num_iteration=model.best_iteration).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                train[test_index]=pre<br>                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(mean_squared_error(te_y, pre))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> IOError(<span class="hljs-string">&quot;Please add new clf.&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s now score is:&quot;</span>%clf_name,cv_scores)<br>    test[:]=test_pre.mean(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_list:&quot;</span>%clf_name,cv_scores)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_mean:&quot;</span>%clf_name,np.mean(cv_scores))<br>    <span class="hljs-keyword">return</span> train.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),test.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><br><br></code></pre></td></tr></table></figure><h4 id="代码详解">代码详解</h4><p>这段代码是一个用于堆叠（stacking）回归模型的函数。下面是对每一行代码的逐行解释：</p><ol type="1"><li><p><code>def stacking_reg(clf,train_x,train_y,test_x,clf_name,kf,label_split=None):</code> 这个函数定义了一个堆叠回归模型的函数，它接受以下参数：</p><ul><li><code>clf</code>: 使用的基础回归模型</li><li><code>train_x</code>: 训练集的特征数据</li><li><code>train_y</code>: 训练集的目标数据</li><li><code>test_x</code>: 测试集的特征数据</li><li><code>clf_name</code>: 基础回归模型的名称</li><li><code>kf</code>: 交叉验证的迭代器</li><li><code>label_split</code>（可选）: 标签的分割方式</li></ul></li><li><p><code>train=np.zeros((train_x.shape[0],1))</code> 创建一个形状为<code>(训练集样本数, 1)</code>的全零数组，并将其赋值给变量<code>train</code>。这个数组用于存储训练集在基础模型上的预测结果。</p></li><li><p><code>test=np.zeros((test_x.shape[0],1))</code> 创建一个形状为<code>(测试集样本数, 1)</code>的全零数组，并将其赋值给变量<code>test</code>。这个数组用于存储测试集在基础模型上的预测结果。</p></li><li><p><code>test_pre=np.empty((folds,test_x.shape[0],1))</code> 创建一个形状为<code>(folds, 测试集样本数, 1)</code>的空数组，并将其赋值给变量<code>test_pre</code>。这个数组用于存储每次交叉验证中测试集在基础模型上的预测结果。</p></li><li><p><code>cv_scores=[]</code> 创建一个空列表，并将其赋值给变量<code>cv_scores</code>。这个列表用于存储每次交叉验证的均方误差（MSE）。</p></li><li><p><code>for i,(train_index,test_index) in enumerate(kf.split(train_x,label_split)):</code><br>遍历交叉验证迭代器<code>kf</code>生成的训练集和验证集的索引。每次迭代中，会得到一个训练集的索引和一个验证集的索引。</p></li><li><p><code>tr_x=train_x[train_index]</code> 根据索引从训练集中获取相应的特征数据，并赋值给变量<code>tr_x</code>。</p></li><li><p><code>tr_y=train_y[train_index]</code> 根据索引从训练集中获取相应的目标数据，并赋值给变量<code>tr_y</code>。</p></li><li><p><code>te_x=train_x[test_index]</code> 根据索引从训练集中获取相应的特征数据，并赋值给变量<code>te_x</code>。</p></li><li><p><code>te_y=train_y[test_index]</code> 根据索引从训练集中获取相应的目标数据，并赋值给变量<code>te_y</code>。</p></li></ol><p>15-62. 基于不同的基础回归模型进行训练和预测，并计算均方误差（MSE）：</p><ul><li>如果<code>clf_name</code>在<code>["rf","ada","gb","et","lr","lsvc","knn"]</code>中，使用<code>clf.fit()</code>方法进行训练，然后使用<code>clf.predict()</code>方法进行预测，并将预测结果存储在相应的变量中。</li><li>如果<code>clf_name</code>是<code>"xgb"</code>，则使用XGBoost库进行训练和预测。具体的参数设置和训练过程与XGBoost相关。</li><li>如果<code>clf_name</code>是<code>"lgb"</code>，则使用LightGBM库进行训练和预测。具体的参数设置和训练过程与LightGBM相关。</li></ul><ol start="64" type="1"><li><p><code>raise IOError("Please add new clf.")</code> 如果<code>clf_name</code>不属于任何已定义的模型名称，则抛出一个错误。</p></li><li><p><code>print("%s now score is:"%clf_name,cv_scores)</code> 打印当前基础回归模型的均方误差。</p></li><li><p><code>test[:]=test_pre.mean(axis=0)</code> 计算所有交叉验证模型的预测结果的平均值，并将结果赋值给<code>test</code>变量。</p></li></ol><p>70-71. 分别打印基础回归模型的均方误差列表和均值。</p><ol start="73" type="1"><li><code>return train.reshape(-1,1),test.reshape(-1,1)</code> 返回训练集和测试集的预测结果，其中预测结果的形状为<code>(样本数, 1)</code>。</li></ol><hr><p>15-62.代码是一个用于训练和评估XGBoost或LightGBM模型的逻辑。我将逐行解释代码的功能：</p><ol type="1"><li><p><code>train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)</code>: 使用XGBoost库的<code>DMatrix</code>方法创建训练数据矩阵，其中<code>tr_x</code>是特征数据，<code>tr_y</code>是目标数据，<code>missing=-1</code>表示缺失值的表示方式。</p></li><li><p><code>test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)</code>: 使用XGBoost库的<code>DMatrix</code>方法创建测试数据矩阵，其中<code>te_x</code>是特征数据，<code>te_y</code>是目标数据，<code>missing=-1</code>表示缺失值的表示方式。</p></li><li><p><code>z = clf.DMatrix(test_x, label=te_y, missing=-1)</code>: 使用XGBoost库的<code>DMatrix</code>方法创建用于预测的数据矩阵，其中<code>test_x</code>是特征数据，<code>te_y</code>是目标数据，<code>missing=-1</code>表示缺失值的表示方式。</p></li><li><p><code>params = &#123;...&#125;</code>: 设置XGBoost模型的参数，包括树的深度、学习率、正则化等。</p></li><li><p><code>num_round = 10000</code>: 设置迭代轮数。</p></li><li><p><code>early_stopping_rounds = 100</code>: 设置在验证集上早停的轮数。</p></li><li><p><code>watchlist = [(train_matrix, 'train'), (test_matrix, 'eval')]</code>: 创建监控列表用于跟踪训练和测试集上的性能。</p></li><li><p><code>model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,early_stopping_rounds=early_stopping_rounds)</code>: 使用XGBoost库的<code>train</code>方法训练模型，其中<code>params</code>是模型参数，<code>train_matrix</code>是训练数据矩阵，<code>num_boost_round</code>是迭代轮数，<code>evals</code>是监控列表，<code>early_stopping_rounds</code>是早停的轮数。</p></li><li><p><code>pre = model.predict(test_matrix,ntree_limit=model.best_ntree_limit).reshape(-1,1)</code>: 对测试数据进行预测，并将结果重塑为一列。</p></li><li><p><code>train[test_index] = pre</code>: 将对测试集的预测结果保存在训练集的相应位置。</p></li><li><p><code>test_pre[i, :] = model.predict(z, ntree_limit=model.best_ntree_limit).reshape(-1,1)</code>: 对预测数据进行预测，并将结果保存在<code>test_pre</code>数组的第i行。</p></li><li><p><code>cv_scores.append(mean_squared_error(te_y, pre))</code>: 将平均均方误差（MSE）添加到交叉验证分数列表中。</p></li><li><p><code>train_matrix = clf.Dataset(tr_x, label=tr_y)</code>: 使用LightGBM库的<code>Dataset</code>方法创建训练数据集。</p></li><li><p><code>test_matrix = clf.Dataset(te_x, label=te_y)</code>: 使用LightGBM库的<code>Dataset</code>方法创建测试数据集。</p></li><li><p><code>params = &#123;...&#125;</code>: 设置LightGBM模型的参数，包括树的深度、学习率、正则化等。</p></li><li><p><code>model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,early_stopping_rounds=early_stopping_rounds)</code>: 使用LightGBM库的<code>train</code>方法训练模型，其中<code>params</code>是模型参数，<code>train_matrix</code>是训练数据集，<code>num_round</code>是迭代轮数，<code>valid_sets</code>是用于验证的数据集，<code>early_stopping_rounds</code>是早停的轮数。</p></li><li><p><code>pre = model.predict(te_x,num_iteration=model.best_iteration).reshape(-1,1)</code>: 对测试数据进行预测，并将结果重塑为一列。</p></li><li><p><code>train[test_index] = pre</code>: 将对测试集的预测结果保存在训练集的相应位置。</p></li><li><p><code>test_pre[i, :] = model.predict(test_x, num_iteration=model.best_iteration).reshape(-1,1)</code>: 对预测数据进行预测，并将结果保存在<code>test_pre</code>数组的第i行。</p></li><li><p><code>cv_scores.append(mean_squared_error(te_y, pre))</code>: 将平均均方误差（MSE）添加到交叉验证分数列表中。</p></li></ol><h4 id="代码整体思路">代码整体思路</h4><ol type="1"><li><p>创建一些空数组和变量，包括<code>train</code>（训练集预测结果）、<code>test</code>（测试集预测结果）、<code>test_pre</code>（测试集在各折交叉验证下的预测结果）和<code>cv_scores</code>（交叉验证得分列表）。</p></li><li><p>对于交叉验证的每一折，进行以下操作：</p><ul><li>根据当前折的索引，获取训练集的索引和测试集的索引。</li><li>根据索引从训练集和标签中抽取对应的样本和标签。</li><li>如果分类器名称在['rf'、'ada'、'gb'、'et'、'lr'、'lsvc'、'knn']中，则使用分类器训练模型，进行预测，并将预测结果存储在相应的数组中。</li><li>如果分类器名称为'xgb'，则使用XGBoost训练模型，进行预测，并将预测结果存储在相应的数组中。</li><li>如果分类器名称为'lgb'，则使用LightGBM训练模型，进行预测，并将预测结果存储在相应的数组中。</li><li>计算当前折的均方误差得分，并将其添加到cv_scores列表中。</li></ul></li><li><p>计算所有折的平均预测结果，并将其存储在test数组中。</p></li><li><p>打印分类器名称、交叉验证得分列表和平均得分。</p></li><li><p>将train和test数组重新整形为列向量，并返回它们作为函数的输出。</p></li></ol><h2 id="模型融合stacking基学习器">10.2 模型融合stacking基学习器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">rf_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    randomforest = RandomForestRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">20</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>,verbose=<span class="hljs-number">1</span>)<br>    rf_train, rf_test = stacking_reg(randomforest, x_train, y_train, x_valid, <span class="hljs-string">&quot;rf&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> rf_train, rf_test,<span class="hljs-string">&quot;rf_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ada_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    adaboost = AdaBoostRegressor(n_estimators=<span class="hljs-number">30</span>, random_state=<span class="hljs-number">2017</span>, learning_rate=<span class="hljs-number">0.01</span>)<br>    ada_train, ada_test = stacking_reg(adaboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;ada&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> ada_train, ada_test,<span class="hljs-string">&quot;ada_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    gbdt = GradientBoostingRegressor(learning_rate=<span class="hljs-number">0.04</span>, n_estimators=<span class="hljs-number">100</span>, subsample=<span class="hljs-number">0.8</span>, random_state=<span class="hljs-number">2017</span>,max_depth=<span class="hljs-number">5</span>,verbose=<span class="hljs-number">1</span>)<br>    gbdt_train, gbdt_test = stacking_reg(gbdt, x_train, y_train, x_valid, <span class="hljs-string">&quot;gb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> gbdt_train, gbdt_test,<span class="hljs-string">&quot;gb_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">et_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    extratree = ExtraTreesRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">35</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>,verbose=<span class="hljs-number">1</span>)<br>    et_train, et_test = stacking_reg(extratree, x_train, y_train, x_valid, <span class="hljs-string">&quot;et&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> et_train, et_test,<span class="hljs-string">&quot;et_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    lr_reg=LinearRegression(n_jobs=-<span class="hljs-number">1</span>)<br>    lr_train, lr_test = stacking_reg(lr_reg, x_train, y_train, x_valid, <span class="hljs-string">&quot;lr&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> lr_train, lr_test, <span class="hljs-string">&quot;lr_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xgb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    xgb_train, xgb_test = stacking_reg(xgboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;xgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> xgb_train, xgb_test,<span class="hljs-string">&quot;xgb_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lgb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    lgb_train, lgb_test = stacking_reg(lightgbm, x_train, y_train, x_valid, <span class="hljs-string">&quot;lgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> lgb_train, lgb_test,<span class="hljs-string">&quot;lgb_reg&quot;</span><br></code></pre></td></tr></table></figure><h4 id="代码解释-5">代码解释</h4><ol type="1"><li><p><code>rf_reg</code> 函数：</p><ul><li>首先，使用随机森林回归器 <code>RandomForestRegressor</code> 创建一个随机森林模型。设置了一些参数，如树的数量(<code>n_estimators</code>)、最大深度(<code>max_depth</code>)、并行运算的CPU核数(<code>n_jobs</code>)等。</li><li>接下来，调用 <code>stacking_reg</code> 函数，将创建的随机森林模型作为基学习器进行堆叠集成学习。该函数的作用是对训练数据 <code>x_train</code> 进行 K 折交叉验证，并返回基学习器在训练集和验证集上的预测结果。</li><li>最后，返回训练集的预测结果 <code>rf_train</code>、验证集的预测结果 <code>rf_test</code> 和标识符字符串 <code>"rf_reg"</code>。</li></ul></li><li><p><code>ada_reg</code> 函数：</p><ul><li>首先，使用 AdaBoost 回归器 <code>AdaBoostRegressor</code> 创建一个 AdaBoost 模型。设置了一些参数，如基学习器的数量(<code>n_estimators</code>)、学习率(<code>learning_rate</code>)等。</li><li>接下来，调用 <code>stacking_reg</code> 函数，将创建的 AdaBoost 模型作为基学习器进行堆叠集成学习。该函数的作用和上述相同，对训练数据 <code>x_train</code> 进行 K 折交叉验证，并返回基学习器在训练集和验证集上的预测结果。</li><li>最后，返回训练集的预测结果 <code>ada_train</code>、验证集的预测结果 <code>ada_test</code> 和标识符字符串 <code>"ada_reg"</code>。</li></ul></li></ol><p>······</p><p>代码的目的是创建不同的基学习器，并将其作为基础模型进行堆叠集成学习。通过堆叠集成学习，可以利用各个基学习器的优势，提高整体模型的预测性能。最后，返回训练集和验证集上的预测结果以及标识符字符串。</p><h2 id="定义模型融合stacking预测函数">10.3 定义模型融合stacking预测函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">stacking_pred</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, clf_list, label_split=<span class="hljs-literal">None</span>, clf_fin=<span class="hljs-string">&quot;lgb&quot;</span>, if_concat_origin=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-comment"># 第一层-结果为train test</span><br>    <span class="hljs-keyword">for</span> k, clf_list <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(clf_list):<br>        clf_list = [clf_list]<br>        column_list = []<br>        train_data_list=[]<br>        test_data_list=[]<br>        <span class="hljs-keyword">for</span> clf <span class="hljs-keyword">in</span> clf_list:<br>            train_data,test_data,clf_name=clf(x_train, y_train, x_valid, kf, label_split=label_split)<br>            train_data_list.append(train_data)<br>            test_data_list.append(test_data)<br>            column_list.append(<span class="hljs-string">&quot;clf_%s&quot;</span> % (clf_name))<br>    train = np.concatenate(train_data_list, axis=<span class="hljs-number">1</span>)<br>    test = np.concatenate(test_data_list, axis=<span class="hljs-number">1</span>)<br>     <br>    <span class="hljs-comment"># 是否选择原始特征拼接</span><br>    <span class="hljs-keyword">if</span> if_concat_origin:<br>        train = np.concatenate([x_train, train], axis=<span class="hljs-number">1</span>)<br>        test = np.concatenate([x_valid, test], axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(x_train.shape)<br>    <span class="hljs-built_in">print</span>(train.shape)<br>    <span class="hljs-built_in">print</span>(clf_name)<br>    <span class="hljs-built_in">print</span>(clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lgb&quot;</span>])<br>    <span class="hljs-comment"># 第二层</span><br>    <span class="hljs-keyword">if</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;rf&quot;</span>,<span class="hljs-string">&quot;ada&quot;</span>,<span class="hljs-string">&quot;gb&quot;</span>,<span class="hljs-string">&quot;et&quot;</span>,<span class="hljs-string">&quot;lr&quot;</span>,<span class="hljs-string">&quot;lsvc&quot;</span>,<span class="hljs-string">&quot;knn&quot;</span>]:<br>        <span class="hljs-keyword">if</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;rf&quot;</span>]:<br>            clf = RandomForestRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">20</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>,verbose=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;ada&quot;</span>]:<br>            clf = AdaBoostRegressor(n_estimators=<span class="hljs-number">30</span>, random_state=<span class="hljs-number">2017</span>, learning_rate=<span class="hljs-number">0.01</span>)<br>        <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;gb&quot;</span>]:<br>            clf = GradientBoostingRegressor(learning_rate=<span class="hljs-number">0.04</span>, n_estimators=<span class="hljs-number">100</span>, subsample=<span class="hljs-number">0.8</span>, random_state=<span class="hljs-number">2017</span>,max_depth=<span class="hljs-number">5</span>,verbose=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;et&quot;</span>]:<br>            clf = ExtraTreesRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">35</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>,verbose=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lr&quot;</span>]:<br>            clf = LinearRegression(n_jobs=-<span class="hljs-number">1</span>)<br>        clf.fit(train, y_train)<br>        pre = clf.predict(test).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> pred<br>    <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;xgb&quot;</span>]:<br>        clf = xgboost<br>        train_matrix = clf.DMatrix(train, label=y_train, missing=-<span class="hljs-number">1</span>)<br>        test_matrix = clf.DMatrix(train, label=y_train, missing=-<span class="hljs-number">1</span>)<br>        params = &#123;<span class="hljs-string">&#x27;booster&#x27;</span>: <span class="hljs-string">&#x27;gbtree&#x27;</span>,<br>                  <span class="hljs-string">&#x27;eval_metric&#x27;</span>: <span class="hljs-string">&#x27;rmse&#x27;</span>,<br>                  <span class="hljs-string">&#x27;gamma&#x27;</span>: <span class="hljs-number">1</span>,<br>                  <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                  <span class="hljs-string">&#x27;max_depth&#x27;</span>: <span class="hljs-number">5</span>,<br>                  <span class="hljs-string">&#x27;lambda&#x27;</span>: <span class="hljs-number">10</span>,<br>                  <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;eta&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                  <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                  <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                  <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span><br>                  &#125;<br>        num_round = <span class="hljs-number">10000</span><br>        <span class="hljs-comment">#early_stopping_rounds = 100</span><br>        callbacks=[lightgbm.log_evaluation(period=<span class="hljs-number">100</span>), lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)]<br>        watchlist = [(train_matrix, <span class="hljs-string">&#x27;train&#x27;</span>),<br>                     (test_matrix, <span class="hljs-string">&#x27;eval&#x27;</span>)<br>                     ]<br>        model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,<br>                          <span class="hljs-comment">#early_stopping_rounds=early_stopping_rounds</span><br>                          callbacks=callbacks<br>                          )<br>        pre = model.predict(test,ntree_limit=model.best_ntree_limit).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> pre<br>    <span class="hljs-keyword">elif</span> clf_fin <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lgb&quot;</span>]:<br>        <span class="hljs-built_in">print</span>(clf_name)<br>        clf = lightgbm<br>        train_matrix = clf.Dataset(train, label=y_train)<br>        test_matrix = clf.Dataset(train, label=y_train)<br>        params = &#123;<br>                  <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>                  <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;regression_l2&#x27;</span>,<br>                  <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;mse&#x27;</span>,<br>                  <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                  <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">2</span>**<span class="hljs-number">5</span>,<br>                  <span class="hljs-string">&#x27;lambda_l2&#x27;</span>: <span class="hljs-number">10</span>,<br>                  <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                  <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                  <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                  <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                  <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span>,<br>                  <span class="hljs-string">&#x27;silent&#x27;</span>: <span class="hljs-literal">True</span>,<br>                  &#125;<br>        num_round = <span class="hljs-number">10000</span><br>        <span class="hljs-comment">#early_stopping_rounds = 100</span><br>        callbacks=[lightgbm.log_evaluation(period=<span class="hljs-number">100</span>), lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)]<br>        model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,<br>                          <span class="hljs-comment">#early_stopping_rounds=early_stopping_rounds</span><br>                          callbacks=callbacks<br>                          )<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pred&#x27;</span>)<br>        pre = model.predict(test,num_iteration=model.best_iteration).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-built_in">print</span>(pre)<br>        <span class="hljs-keyword">return</span> pre<br></code></pre></td></tr></table></figure><h2 id="使用lr_reg和lgb_reg进行融合预测">10.4 使用lr_reg和lgb_reg进行融合预测</h2><p>加载数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load_dataset</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/zhengqi_train.txt&quot;</span>)  <span class="hljs-keyword">as</span> fr:<br>    data_train=pd.read_table(fr,sep=<span class="hljs-string">&quot;\t&quot;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/zhengqi_test.txt&quot;</span>) <span class="hljs-keyword">as</span> fr_test:<br>    data_test=pd.read_table(fr_test,sep=<span class="hljs-string">&quot;\t&quot;</span>)<br>    <br></code></pre></td></tr></table></figure><p>K折交叉验证</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># K折交叉验证</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold, KFold<br><br>folds = <span class="hljs-number">5</span><br>seed = <span class="hljs-number">1</span><br>kf = KFold(n_splits=<span class="hljs-number">5</span>, shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>训练集和测试集数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练集</span><br>x_train = data_train[data_test.columns].values<br>y_train = data_train[<span class="hljs-string">&#x27;target&#x27;</span>].values<br><span class="hljs-comment"># 测试集</span><br>x_valid = data_test[data_test.columns].values<br></code></pre></td></tr></table></figure><p>使用lr_reg和lgb_reg进行融合预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">clf_list = [lr_reg, lgb_reg]<br><br><span class="hljs-comment">##很容易过拟合</span><br>pred = stacking_pred(x_train, y_train, x_valid, kf, clf_list, label_split=<span class="hljs-literal">None</span>, clf_fin=<span class="hljs-string">&quot;lgb&quot;</span>, if_concat_origin=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>预测结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pred<br></code></pre></td></tr></table></figure><pre><code class="hljs">array([[ 0.41700189],
       [ 0.37101204],
       [ 0.1479981 ],
       ...,
       [-2.48570445],
       [-2.4264629 ],
       [-2.48367665]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将pred转换为一维数组</span><br>pred_flat = pred.flatten()<br><br><span class="hljs-comment"># 保存为文本文件</span><br>np.savetxt(<span class="hljs-string">&#x27;pred.txt&#x27;</span>, pred_flat)<br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>工业蒸汽预测-07模型融合</div><div>https://zhou1317fe5.github.io/2023/09/19/工业蒸汽预测-07模型融合/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年9月19日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/09/28/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-%E8%B5%9B%E9%A2%98%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB/" title="工业蒸汽预测-赛题完整代码分享"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">工业蒸汽预测-赛题完整代码分享</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/09/15/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-06%E7%89%B9%E5%BE%81%E4%BC%98%E5%8C%96/" title="工业蒸汽预测-06特征优化"><span class="hidden-mobile">工业蒸汽预测-06特征优化</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>