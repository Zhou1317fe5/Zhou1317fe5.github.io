<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="1 模型过拟合与欠拟合 1.1 基础代码 导入工具包，用于模型验证和数据处理。 123456789101112131415161718192021import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns # 可视化 用于创建各种类型的统计图形from scipy impo"><meta property="og:type" content="article"><meta property="og:title" content="工业蒸汽预测-05-2赛题模型验证"><meta property="og:url" content="https://zhou1317fe5.github.io/2023/09/04/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-2%E8%B5%9B%E9%A2%98%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="1 模型过拟合与欠拟合 1.1 基础代码 导入工具包，用于模型验证和数据处理。 123456789101112131415161718192021import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns # 可视化 用于创建各种类型的统计图形from scipy impo"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-2%E8%B5%9B%E9%A2%98%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/052_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-2%E8%B5%9B%E9%A2%98%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_53_1.png"><meta property="og:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-2%E8%B5%9B%E9%A2%98%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_55_0.png"><meta property="article:published_time" content="2023-09-04T01:50:53.000Z"><meta property="article:modified_time" content="2023-09-13T02:37:50.000Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://zhou1317fe5.github.io/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-2%E8%B5%9B%E9%A2%98%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/052_1.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>工业蒸汽预测-05-2赛题模型验证 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="工业蒸汽预测-05-2赛题模型验证"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-09-04 09:50" pubdate>2023年9月4日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 30k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 247 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">工业蒸汽预测-05-2赛题模型验证</h1><div class="markdown-body"><h1 id="模型过拟合与欠拟合">1 模型过拟合与欠拟合</h1><h2 id="基础代码">1.1 基础代码</h2><p>导入工具包，用于模型验证和数据处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns <span class="hljs-comment"># 可视化 用于创建各种类型的统计图形</span><br><br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats <span class="hljs-comment"># 用于统计分析</span><br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression  <span class="hljs-comment">#线性回归</span><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor  <span class="hljs-comment">#K近邻回归</span><br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor     <span class="hljs-comment">#决策树回归</span><br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor <span class="hljs-comment">#随机森林回归</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVR  <span class="hljs-comment">#支持向量回归</span><br><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb <span class="hljs-comment">#lightGbm模型</span><br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <span class="hljs-comment"># 切分数据</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error <span class="hljs-comment">#评价指标</span><br><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDRegressor <span class="hljs-comment"># 随机梯度下降线性回归</span><br></code></pre></td></tr></table></figure><p>读取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data_file = <span class="hljs-string">&quot;./data/zhengqi_train.txt&quot;</span><br>test_data_file =  <span class="hljs-string">&quot;./data/zhengqi_test.txt&quot;</span><br><br>train_data = pd.read_csv(train_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>test_data = pd.read_csv(test_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>V0</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V29</th><th>V30</th><th>V31</th><th>V32</th><th>V33</th><th>V34</th><th>V35</th><th>V36</th><th>V37</th><th>target</th></tr></thead><tbody><tr><th>0</th><td>0.566</td><td>0.016</td><td>-0.143</td><td>0.407</td><td>0.452</td><td>-0.901</td><td>-1.812</td><td>-2.360</td><td>-0.436</td><td>-2.114</td><td>...</td><td>0.136</td><td>0.109</td><td>-0.615</td><td>0.327</td><td>-4.627</td><td>-4.789</td><td>-5.101</td><td>-2.608</td><td>-3.508</td><td>0.175</td></tr><tr><th>1</th><td>0.968</td><td>0.437</td><td>0.066</td><td>0.566</td><td>0.194</td><td>-0.893</td><td>-1.566</td><td>-2.360</td><td>0.332</td><td>-2.114</td><td>...</td><td>-0.128</td><td>0.124</td><td>0.032</td><td>0.600</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>-0.335</td><td>-0.730</td><td>0.676</td></tr><tr><th>2</th><td>1.013</td><td>0.568</td><td>0.235</td><td>0.370</td><td>0.112</td><td>-0.797</td><td>-1.367</td><td>-2.360</td><td>0.396</td><td>-2.114</td><td>...</td><td>-0.009</td><td>0.361</td><td>0.277</td><td>-0.116</td><td>-0.843</td><td>0.160</td><td>0.364</td><td>0.765</td><td>-0.589</td><td>0.633</td></tr><tr><th>3</th><td>0.733</td><td>0.368</td><td>0.283</td><td>0.165</td><td>0.599</td><td>-0.679</td><td>-1.200</td><td>-2.086</td><td>0.403</td><td>-2.114</td><td>...</td><td>0.015</td><td>0.417</td><td>0.279</td><td>0.603</td><td>-0.843</td><td>-0.065</td><td>0.364</td><td>0.333</td><td>-0.112</td><td>0.206</td></tr><tr><th>4</th><td>0.684</td><td>0.638</td><td>0.260</td><td>0.209</td><td>0.337</td><td>-0.454</td><td>-1.073</td><td>-2.086</td><td>0.314</td><td>-2.114</td><td>...</td><td>0.183</td><td>1.078</td><td>0.328</td><td>0.418</td><td>-0.843</td><td>-0.215</td><td>0.364</td><td>-0.280</td><td>-0.028</td><td>0.384</td></tr></tbody></table><p>5 rows × 39 columns</p></div><p>归一化处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing <br><span class="hljs-comment"># 1读取特征名</span><br>features_columns = [col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> train_data.columns <span class="hljs-keyword">if</span> col <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;target&#x27;</span>]]<br><span class="hljs-comment"># 2实例化</span><br>min_max_scaler = preprocessing.MinMaxScaler()<br><span class="hljs-comment"># 3训练集fit拟合</span><br>min_max_scaler = min_max_scaler.fit(train_data[features_columns])<br><span class="hljs-comment"># 4transform</span><br>train_data_scaler = min_max_scaler.transform(train_data[features_columns])<br>test_data_scaler = min_max_scaler.transform(test_data[features_columns])<br><span class="hljs-comment"># 5转dataframe-设特征列名</span><br>train_data_scaler = pd.DataFrame(train_data_scaler)<br>train_data_scaler.columns = features_columns<br><br>test_data_scaler = pd.DataFrame(test_data_scaler)<br>test_data_scaler.columns = features_columns<br><span class="hljs-comment"># 6添回target列</span><br>train_data_scaler[<span class="hljs-string">&#x27;target&#x27;</span>] = train_data[<span class="hljs-string">&#x27;target&#x27;</span>]<br></code></pre></td></tr></table></figure><p>PCA处理，特征降维</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA   <span class="hljs-comment">#主成分分析法</span><br><br><span class="hljs-comment">#PCA方法降维</span><br><span class="hljs-comment">#保留16个主成分</span><br>pca = PCA(n_components=<span class="hljs-number">16</span>)<br>new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:,<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>])<br>new_test_pca_16 = pca.transform(test_data_scaler)<br>new_train_pca_16 = pd.DataFrame(new_train_pca_16)<br>new_test_pca_16 = pd.DataFrame(new_test_pca_16)<br>new_train_pca_16[<span class="hljs-string">&#x27;target&#x27;</span>] = train_data_scaler[<span class="hljs-string">&#x27;target&#x27;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#采用 pca 保留16维特征的数据</span><br>new_train_pca_16 = new_train_pca_16.fillna(<span class="hljs-number">0</span>)<br>train = new_train_pca_16[new_test_pca_16.columns]<br>target = new_train_pca_16[<span class="hljs-string">&#x27;target&#x27;</span>]<br><br><span class="hljs-comment"># 切分数据 训练数据80% 验证数据20%</span><br>train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="欠拟合">1.2 欠拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">clf = SGDRegressor(max_iter=<span class="hljs-number">500</span>, tol=<span class="hljs-number">1e-2</span>) <br>clf.fit(train_data, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data))<br>score_test = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.15181384379355015
SGDRegressor test MSE:    0.15618692974276552</code></pre><h4 id="代码解释">代码解释</h4><p>SGDRegressor 是一种基于梯度下降的线性回归模型，使用随机梯度下降算法进行参数估计适用于大规模数据集和高维特征。 与传统的批量梯度下降不同，随机梯度下降每次迭代只使用一个样本或一小批样本来更新模型参数，从而减少了内存消耗和计算复杂度。</p><p>主要参数：</p><ul><li>loss: 损失函数的类型。可选参数有 'squared_loss'（平方损失，默认）、'huber'（Huber 损失）、'epsilon_insensitive'（ϵ-insensitive 损失）等。</li><li>penalty: 正则化项的类型。可选参数有 'l2'（L2 正则化，默认）、'l1'（L1 正则化）、'elasticnet'（弹性网正则化）等。</li><li>alpha: 正则化项的惩罚力度。默认为0.0001。</li><li>max_iter: 最大迭代次数。默认为1000。</li><li>learning_rate: 学习率的类型或大小。可选参数有 'constant'（恒定学习率）、'optimal'（最优学习率）、'invscaling'（逆标度学习率）等。</li><li>eta0: 初始学习率。默认为0.01。</li></ul><p>主要方法：</p><ul><li>fit(X, y): 使用训练数据训练模型。</li><li>predict(X): 对新的输入数据进行预测。</li><li>score(X, y): 返回模型在给定测试数据上的 R^2 分数。</li></ul><p>在 SGDRegressor 中，<code>tol</code> 是用来控制迭代的停止条件的参数。tol（tolerance）表示容忍度，即当损失函数的变化小于 tol 时，算法会停止迭代。<code>tol=1e-2</code> 表示容忍度为 0.01。也就是说，当连续两次迭代的损失函数值之差小于 0.01 时，算法会认为模型已经收敛，并且提前结束迭代，不再继续优化。</p><h2 id="过拟合">1.3 过拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> PolynomialFeatures <span class="hljs-comment"># 用于进行多项式特征转换。</span><br>poly = PolynomialFeatures(<span class="hljs-number">5</span>)<br>train_data_poly = poly.fit_transform(train_data)<br>test_data_poly = poly.transform(test_data)<br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>clf.fit(train_data_poly, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data_poly))<br>score_test = mean_squared_error(test_target, clf.predict(test_data_poly))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.13208128238186503
SGDRegressor test MSE:    0.14458655217709998</code></pre><h2 id="正常拟合">1.4正常拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> PolynomialFeatures<br>poly = PolynomialFeatures(<span class="hljs-number">3</span>)<br>train_data_poly = poly.fit_transform(train_data)<br>test_data_poly = poly.transform(test_data)<br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>clf.fit(train_data_poly, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data_poly))<br>score_test = mean_squared_error(test_target, clf.predict(test_data_poly))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.13419513490030407
SGDRegressor test MSE:    0.14274747547356217</code></pre><h4 id="代码解释-1">代码解释</h4><p><code>PolynomialFeatures</code> 是 scikit-learn（sklearn）库中的一个预处理类，用于生成多项式特征。它可以将原始特征转换为高阶多项式特征，从而扩展特征空间，使模型能够更好地拟合非线性关系。</p><p><code>PolynomialFeatures</code> 的主要作用是通过对原始特征进行多项式扩展，引入多项式交互项，从而增加模型的表示能力。对于给定的一组原始特征 x1, x2, ..., xn，<code>PolynomialFeatures</code> 将创建由这些特征的所有可能的多项式组合组成的新特征矩阵。</p><p><code>PolynomialFeatures</code> 可以生成包括以下几种特征的多项式：</p><ul><li>指数项：x^d （d 为指定的度数）</li><li>交叉项：x1^i * x2^j * ... * xn^k （i + j + ... + k 不大于指定的度数）</li></ul><p>使用 <code>PolynomialFeatures</code> 的步骤如下：</p><ol type="1"><li>创建 <code>PolynomialFeatures</code> 实例，并指定所需的度数。</li><li>使用 <code>fit_transform</code> 方法将原始特征数据集转换为多项式特征数据集。</li></ol><h1 id="模型正则化">2 模型正则化</h1><p>正则化(Regularization)是给需要训练的目标函数加上一些规则（限制），目的是为了防止过拟合。</p><h2 id="l2范数正则化">2.1 L2范数正则化</h2><p><span class="math display">\[ \parallel x\parallel_2=\left(\sum_{i=1}^n\mid x_i\mid^2\right)^{\frac{1}{2}} \]</span></p><p>又叫欧几里得(Euclid)范数，即向量元素绝对值平方和再进行开方</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">poly = PolynomialFeatures(<span class="hljs-number">3</span>)<br>train_data_poly = poly.fit_transform(train_data)<br>test_data_poly = poly.transform(test_data)<br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>, penalty= <span class="hljs-string">&#x27;L2&#x27;</span>, alpha=<span class="hljs-number">0.0001</span>) <br>clf.fit(train_data_poly, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data_poly))<br>score_test = mean_squared_error(test_target, clf.predict(test_data_poly))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.13432119501674716
SGDRegressor test MSE:    0.1426776204742311</code></pre><h2 id="l1范数正则化">2.2 L1范数正则化</h2><p><span class="math display">\[ \parallel x\parallel_1=\sum_{i=1}^N\mid x_i\mid \]</span></p><p>即向量元素绝对值之和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">poly = PolynomialFeatures(<span class="hljs-number">3</span>)<br>train_data_poly = poly.fit_transform(train_data)<br>test_data_poly = poly.transform(test_data)<br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>, penalty= <span class="hljs-string">&#x27;L1&#x27;</span>, alpha=<span class="hljs-number">0.00001</span>) <br>clf.fit(train_data_poly, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data_poly))<br>score_test = mean_squared_error(test_target, clf.predict(test_data_poly))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.133943411262935
SGDRegressor test MSE:    0.14229842600351</code></pre><h2 id="elasticnet-联合-l1和l2范数加权正则化">2.3 ElasticNet 联合 L1和L2范数加权正则化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">poly = PolynomialFeatures(<span class="hljs-number">3</span>)<br>train_data_poly = poly.fit_transform(train_data)<br>test_data_poly = poly.transform(test_data)<br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>, penalty= <span class="hljs-string">&#x27;elasticnet&#x27;</span>, l1_ratio=<span class="hljs-number">0.9</span>, alpha=<span class="hljs-number">0.00001</span>) <br>clf.fit(train_data_poly, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data_poly))<br>score_test = mean_squared_error(test_target, clf.predict(test_data_poly))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.13408335184518458
SGDRegressor test MSE:    0.1427094727208378</code></pre><h4 id="代码解释-2">代码解释</h4><ol type="1"><li><p><code>elasticnet</code>：是 <code>SGDRegressor</code> 的正则化方法之一。Elastic Net 是一种结合了 L1 正则化（Lasso）和 L2 正则化（Ridge）的线性回归模型正则化方法。通过引入两种正则化项，Elastic Net 可以在处理高维数据时具有特征选择的能力，并且可以克服 Lasso 存在的某些限制。默认情况下，<code>penalty</code> 参数被设置为 <code>'l2'</code>，即使用 L2 正则化；而设置为 <code>'elasticnet'</code> 则表示同时使用 L1 和 L2 正则化。</p></li><li><p><code>l1_ratio</code>：这是 Elastic Net 的混合参数，取值范围为 0 到 1 之间。它控制着 L1 正则化在 Elastic Net 中的比例。当 <code>l1_ratio</code> 为 0 时，相当于只使用 L2 正则化，而当 <code>l1_ratio</code> 为 1 时，相当于只使用 L1 正则化。在 0 和 1 之间的值表示混合使用两种正则化方法。在给定的示例中，<code>l1_ratio=0.9</code> 表示 Elastic Net 正则化主要使用 L1 正则化，较少使用 L2 正则化。</p></li></ol><h1 id="模型交叉验证">3 模型交叉验证</h1><h2 id="简单交叉验证-hold-out-menthod">3.1 简单交叉验证 Hold-out-menthod</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 简单交叉验证</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <span class="hljs-comment"># 切分数据</span><br><span class="hljs-comment"># 切分数据 训练数据80% 验证数据20%</span><br>train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">0</span>)<br><br>clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>clf.fit(train_data, train_target)<br>score_train = mean_squared_error(train_target, clf.predict(train_data))<br>score_test = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">SGDRegressor train MSE:    0.1415940546797717
SGDRegressor test MSE:    0.14689229408278165</code></pre><h2 id="k折交叉验证-k-fold-cv">3.2 K折交叉验证 K-fold CV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 5折交叉验证</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><br>kf = KFold(n_splits=<span class="hljs-number">5</span>)<br><span class="hljs-keyword">for</span> k, (train_index, test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(train)):<br>    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]<br>    clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>    clf.fit(train_data, train_target)<br>    score_train = mean_squared_error(train_target, clf.predict(train_data))<br>    score_test = mean_squared_error(test_target, clf.predict(test_data))<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 折&quot;</span>, <span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 折&quot;</span>, <span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test, <span class="hljs-string">&#x27;\n&#x27;</span>)  <br></code></pre></td></tr></table></figure><pre><code class="hljs">0  折 SGDRegressor train MSE:    0.1499137658297044
0  折 SGDRegressor test MSE:    0.1065473927176582 

1  折 SGDRegressor train MSE:    0.13357024550007748
1  折 SGDRegressor test MSE:    0.1816447571392363 

2  折 SGDRegressor train MSE:    0.14645981748519107
2  折 SGDRegressor test MSE:    0.13268383953043347 

3  折 SGDRegressor train MSE:    0.1406425883020885
3  折 SGDRegressor test MSE:    0.16206427864796086 

4  折 SGDRegressor train MSE:    0.1387777962461317
4  折 SGDRegressor test MSE:    0.16600911704035512 </code></pre><p>​</p><h4 id="代码详解--kfold函数">代码详解 -<code>KFold</code>函数</h4><p><code>KFold</code> 是 scikit-learn 库中的一个交叉验证方法，用于划分数据集为 k 折，并生成相应的训练集和测试集索引。</p><p>语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">sklearn.model_selection.KFold(n_splits, shuffle=<span class="hljs-literal">False</span>, random_state=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>n_splits</code>：表示将数据集划分为几个折（即 k 值），默认为 5。</li><li><code>shuffle</code>（可选）：表示是否在划分之前对数据进行洗牌，默认为 False。如果设置为 True，则会在划分之前对数据进行洗牌以打乱顺序。</li><li><code>random_state</code>（可选）：表示随机数种子，用于指定洗牌时的随机性。设置相同的随机数种子可以保证每次划分的结果一致。</li></ul><p>常用方法和属性：</p><ul><li><code>split(X[, y, groups])</code>：返回一个生成器对象，用于生成每个折的训练集和测试集索引。</li><li><code>get_n_splits([X, y, groups])</code>：返回划分的折数（即 k 值）。</li></ul><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><br><span class="hljs-comment"># 创建一个 KFold 对象</span><br>kf = KFold(n_splits=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 模拟一个数据集</span><br>data = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>])<br><br><span class="hljs-comment"># 使用 KFold 进行划分</span><br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> kf.split(data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Train:&quot;</span>, train_index, <span class="hljs-string">&quot;Test:&quot;</span>, test_index)<br>    <br><span class="hljs-keyword">for</span> train_i,test_i <span class="hljs-keyword">in</span> kf.split(data):<br>    <span class="hljs-built_in">print</span>(data[train_i],data[test_i])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;---------&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs tap">Train: [2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>8 9] Test: [0 1]<br>Train: [0<span class="hljs-number"> 1 </span>4<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>8 9] Test: [2 3]<br>Train: [0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>6<span class="hljs-number"> 7 </span>8 9] Test: [4 5]<br>Train: [0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>8 9] Test: [6 7]<br>Train: [0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6 7] Test: [8 9]<br><br>[3 <span class="hljs-number"> 4 </span><span class="hljs-number"> 5 </span><span class="hljs-number"> 6 </span><span class="hljs-number"> 7 </span><span class="hljs-number"> 8 </span><span class="hljs-number"> 9 </span>10] [1 2]<br>------<span class="language-yaml"><span class="hljs-meta">---</span></span><br><span class="language-yaml">[<span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">7</span>  <span class="hljs-number">8</span>  <span class="hljs-number">9</span> <span class="hljs-number">10</span>] [<span class="hljs-number">3</span> <span class="hljs-number">4</span>]</span><br><span class="language-yaml"><span class="hljs-string">---------</span></span><br><span class="language-yaml">[<span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">7</span>  <span class="hljs-number">8</span>  <span class="hljs-number">9</span> <span class="hljs-number">10</span>] [<span class="hljs-number">5</span> <span class="hljs-number">6</span>]</span><br><span class="language-yaml"><span class="hljs-string">---------</span></span><br><span class="language-yaml">[<span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">9</span> <span class="hljs-number">10</span>] [<span class="hljs-number">7</span> <span class="hljs-number">8</span>]</span><br><span class="language-yaml"><span class="hljs-string">---------</span></span><br><span class="language-yaml">[<span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>  <span class="hljs-number">6</span>  <span class="hljs-number">7</span>  <span class="hljs-number">8</span>] [<span class="hljs-number">9</span> <span class="hljs-number">10</span>]</span><br><span class="language-yaml"><span class="hljs-string">---------</span></span><br></code></pre></td></tr></table></figure><p>在这个例子中，我们先创建了一个 <code>KFold</code> 对象 <code>kf</code>，将数据集 <code>data</code> 划分为 5 折交叉验证。然后，在循环中，我们使用 <code>kf.split(data)</code> 生成了每个折的训练集索引 <code>train_index</code> 和测试集索引 <code>test_index</code>。通过打印这些索引，我们可以看到每个折的训练集和测试集索引。</p><h4 id="代码详解--enumerate函数">代码详解 -<code>enumerate</code>函数</h4><p>用于将一个可迭代对象转换为一个枚举对象。它返回一个包含索引和元素的元组的迭代器。</p><p>语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">enumerate</span>(iterable, start=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><ul><li><code>iterable</code>：表示要进行枚举的可迭代对象，可以是列表、元组、字符串、集合等。</li><li><code>start</code>（可选）：表示索引的起始值，默认为 0。</li></ul><p>当对一个可迭代对象使用 <code>enumerate</code> 函数时，它会返回一个生成器对象，每次迭代都会产生一个元组 <code>(index, element)</code>，其中 <code>index</code> 是当前元素的索引，从 <code>start</code> 开始递增，<code>element</code> 是对应的元素。</p><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">fruits = [<span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>]<br><br><span class="hljs-keyword">for</span> index, fruit <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(fruits):<br>    <span class="hljs-built_in">print</span>(index, fruit)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">0 </span>apple<br><span class="hljs-symbol">1 </span>banana<br><span class="hljs-symbol">2 </span>orange<br></code></pre></td></tr></table></figure><p>在例子中，我们使用 <code>enumerate</code> 对列表 <code>fruits</code> 进行枚举。在每次迭代中，<code>index</code> 表示元素的索引，<code>fruit</code> 表示对应的水果名称。通过打印 <code>index</code> 和 <code>fruit</code>，我们可以看到每个元素的索引和对应的水果名称。</p><h2 id="留一法-loo-cv">3.3 留一法 LOO CV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> LeaveOneOut<br>loo = LeaveOneOut()<br><span class="hljs-comment"># num = 100</span><br><span class="hljs-keyword">for</span> k, (train_index, test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loo.split(train)):<br>    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]<br>    clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>    clf.fit(train_data, train_target)<br>    score_train = mean_squared_error(train_target, clf.predict(train_data))<br>    score_test = mean_squared_error(test_target, clf.predict(test_data))<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 个&quot;</span>, <span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 个&quot;</span>, <span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test, <span class="hljs-string">&#x27;\n&#x27;</span>) <br>    <span class="hljs-keyword">if</span> k &gt;= <span class="hljs-number">9</span>: <span class="hljs-comment"># k 大于等于 9时停止迭代</span><br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><pre><code class="hljs">0  个 SGDRegressor train MSE:    0.14154678086730024
0  个 SGDRegressor test MSE:    0.012065815413407692 

1  个 SGDRegressor train MSE:    0.14155310807366145
1  个 SGDRegressor test MSE:    0.1284070906104496 

2  个 SGDRegressor train MSE:    0.1416146883293847
2  个 SGDRegressor test MSE:    0.039426047577402645 

3  个 SGDRegressor train MSE:    0.1415863600282994
3  个 SGDRegressor test MSE:    0.003415838580474376 

4  个 SGDRegressor train MSE:    0.14162529930716214
4  个 SGDRegressor test MSE:    0.011115946286888823 

5  个 SGDRegressor train MSE:    0.1415881641515214
5  个 SGDRegressor test MSE:    0.13704136603528533 

6  个 SGDRegressor train MSE:    0.14157596799992908
6  个 SGDRegressor test MSE:    0.02376598173602542 

7  个 SGDRegressor train MSE:    0.14156227272773078
7  个 SGDRegressor test MSE:    0.0007635271707761818 

8  个 SGDRegressor train MSE:    0.14150680604796795
8  个 SGDRegressor test MSE:    0.08992065000952423 

9  个 SGDRegressor train MSE:    0.1416009075487987
9  个 SGDRegressor test MSE:    0.05042063473393335 </code></pre><p>​</p><h2 id="留p法-lpo-cv">3.4 留P法 LPO CV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> LeavePOut<br>lpo = LeavePOut(p=<span class="hljs-number">10</span>)<br><span class="hljs-comment"># num = 100</span><br><span class="hljs-keyword">for</span> k, (train_index, test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(lpo.split(train)):<br>    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]<br>    clf = SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>) <br>    clf.fit(train_data, train_target)<br>    score_train = mean_squared_error(train_target, clf.predict(train_data))<br>    score_test = mean_squared_error(test_target, clf.predict(test_data))<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 10个&quot;</span>, <span class="hljs-string">&quot;SGDRegressor train MSE:   &quot;</span>, score_train)<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-string">&quot; 10个&quot;</span>, <span class="hljs-string">&quot;SGDRegressor test MSE:   &quot;</span>, score_test, <span class="hljs-string">&#x27;\n&#x27;</span>) <br>    <span class="hljs-keyword">if</span> k &gt;= <span class="hljs-number">9</span>: <span class="hljs-comment"># k 大于等于 9时停止迭代。</span><br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><pre><code class="hljs">0  10个 SGDRegressor train MSE:    0.14188997841367093
0  10个 SGDRegressor test MSE:    0.04891057028963159 

1  10个 SGDRegressor train MSE:    0.14192614406434934
1  10个 SGDRegressor test MSE:    0.04448387541119956 

2  10个 SGDRegressor train MSE:    0.14204156040593743
2  10个 SGDRegressor test MSE:    0.046971875220281685 

3  10个 SGDRegressor train MSE:    0.14195528728520312
3  10个 SGDRegressor test MSE:    0.05454716320716613 

4  10个 SGDRegressor train MSE:    0.14180044048646773
4  10个 SGDRegressor test MSE:    0.06895314629502325 

5  10个 SGDRegressor train MSE:    0.14202846470130537
5  10个 SGDRegressor test MSE:    0.04503516030552096 

6  10个 SGDRegressor train MSE:    0.1419720126637407
6  10个 SGDRegressor test MSE:    0.04910967979051496 

7  10个 SGDRegressor train MSE:    0.14201217375831207
7  10个 SGDRegressor test MSE:    0.052842266808938575 

8  10个 SGDRegressor train MSE:    0.14190421814074677
8  10个 SGDRegressor test MSE:    0.04721338466918536 

9  10个 SGDRegressor train MSE:    0.14205468250513334
9  10个 SGDRegressor test MSE:    0.045801703647200806 </code></pre><p>​</p><h4 id="留p交叉验证-和-k折交叉验证">留P交叉验证 和 K折交叉验证</h4><p>区别和特点如下：</p><ul><li>样本划分：留 P 交叉验证按照固定数量 P 的样本划分为测试集，剩余的样本为训练集；K 折交叉验证按照 K 个折的划分将数据集划分为测试集和训练集。</li><li>迭代次数：留 P 交叉验证的迭代次数取决于样本组合的可能性，通常较大；K 折交叉验证的迭代次数为 K，通常较小。</li><li>样本重复：留 P 交叉验证每个样本只出现一次作为测试集，可能会有样本重复出现在训练集中；K 折交叉验证每个样本会被分到不同的训练集和测试集中，避免了样本的重复。</li></ul><h1 id="模型超参空间及调参">4模型超参空间及调参</h1><h2 id="穷举网格搜索">4.1穷举网格搜索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用数据训练随机森林模型，采用网格搜索方法调参</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV <span class="hljs-comment"># 网格搜索</span><br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <span class="hljs-comment"># 切分数据</span><br><span class="hljs-comment"># 切分数据 训练数据80% 验证数据20%</span><br>train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">0</span>)<br><br>randomForestRegressor = RandomForestRegressor()<br>parameters = &#123;<br>              <span class="hljs-string">&#x27;n_estimators&#x27;</span>:[<span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">200</span>],<br>              <span class="hljs-string">&#x27;max_depth&#x27;</span>:[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>        &#125;<br><br>clf = GridSearchCV(randomForestRegressor, parameters, cv=<span class="hljs-number">5</span>) <span class="hljs-comment"># cv对train_data使用 5 折交叉验证</span><br>clf.fit(train_data, train_target)<br><br>score_test = mean_squared_error(test_target, clf.predict(test_data))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RandomForestRegressor GridSearchCV test MSE:   &quot;</span>, score_test)<br><span class="hljs-built_in">sorted</span>(clf.cv_results_.keys())<br></code></pre></td></tr></table></figure><pre><code class="hljs">RandomForestRegressor GridSearchCV test MSE:    0.2580339125452081





[&#39;mean_fit_time&#39;,
 &#39;mean_score_time&#39;,
 &#39;mean_test_score&#39;,
 &#39;param_max_depth&#39;,
 &#39;param_n_estimators&#39;,
 &#39;params&#39;,
 &#39;rank_test_score&#39;,
 &#39;split0_test_score&#39;,
 &#39;split1_test_score&#39;,
 &#39;split2_test_score&#39;,
 &#39;split3_test_score&#39;,
 &#39;split4_test_score&#39;,
 &#39;std_fit_time&#39;,
 &#39;std_score_time&#39;,
 &#39;std_test_score&#39;]</code></pre><h4 id="代码解释-3">代码解释</h4><ol type="1"><li>GridSearchCV()</li></ol><p><code>GridSearchCV</code> 是一个用于进行网格搜索的类，可以用于参数调优和模型选择。</p><p>网格搜索是指将所有可能的参数组合都尝试一遍，并对每组参数进行评估。通过设置参数范围和步长等信息，我们可以控制参数搜索的规模。</p><p>下面是使用 <code>GridSearchCV</code> 的一般流程：</p><ol type="1"><li>导入 <code>GridSearchCV</code> 类和要使用的模型类。</li><li>定义要搜索的参数空间（通常是一个字典）。</li><li>创建模型对象。</li><li>创建 <code>GridSearchCV</code> 对象，传入模型对象、参数空间和其他参数（例如交叉验证的折数）。</li><li>使用 <code>fit</code> 方法拟合数据，并进行网格搜索和交叉验证。</li><li>可以通过 <code>best_params_</code> 属性查看最佳参数组合。</li><li>可以通过 <code>best_score_</code> 属性查看最佳参数组合的得分。</li><li>可以通过 <code>cv_results_</code> 属性查看所有参数组合的详细结果。</li></ol><hr><ol start="2" type="1"><li><code>clf.cv_results_.keys()</code></li></ol><p>是一个列表，该列表返回字典 <code>clf.cv_results_</code> 中所有的键。<code>clf.cv_results_</code> 包含了网格搜索过程中的详细结果，包括每组参数组合的得分、训练时间等信息。</p><p>通过执行 <code>clf.cv_results_.keys()</code>，你将会得到一个列表，其中包含了所有的键。这个列表提供了一个快速查看可用键的方式。</p><p>常见的一些键可能包括：</p><ul><li><code>'mean_fit_time'</code>：每个参数组合的平均训练时间。</li><li><code>'mean_score_time'</code>：每个参数组合的平均预测时间。</li><li><code>'mean_test_score'</code>：每个参数组合在交叉验证的测试集上的平均得分。</li><li><code>'param_XXX'</code>：参数 <code>XXX</code> 的值（例如，如果有参数 <code>'n_estimators'</code>，则会出现 <code>'param_n_estimators'</code>）。</li><li><code>'rank_test_score'</code>：每个参数组合在交叉验证中的得分排名。</li><li><code>'splitX_test_score'</code>：第 X 折交叉验证中每个参数组合的得分。</li></ul><p>这些指标在模型分析中十分重要，可以查找到整个建模过程中可能的异常</p><p><code>sorted(clf.cv_results_.keys())</code> 按字母顺序排序并打印出 clf.cv_results_ 字典中的键.</p><h2 id="随机参数优化">4.2 随机参数优化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用数据训练随机森林模型，采用随机参数优化方法调参</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <span class="hljs-comment"># 切分数据</span><br><span class="hljs-comment"># 切分数据 训练数据80% 验证数据20%</span><br>train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">0</span>)<br><br>randomForestRegressor = RandomForestRegressor()<br>parameters = &#123;<br>              <span class="hljs-string">&#x27;n_estimators&#x27;</span>:[<span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">200</span>, <span class="hljs-number">300</span>],<br>              <span class="hljs-string">&#x27;max_depth&#x27;</span>:[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>        &#125;<br><br>clf = RandomizedSearchCV(randomForestRegressor, parameters, cv=<span class="hljs-number">5</span>)<br>clf.fit(train_data, train_target)<br><br>score_test = mean_squared_error(test_target, clf.predict(test_data))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RandomForestRegressor RandomizedSearchCV test MSE:   &quot;</span>, score_test)<br><span class="hljs-built_in">sorted</span>(clf.cv_results_.keys())<br></code></pre></td></tr></table></figure><pre><code class="hljs">RandomForestRegressor RandomizedSearchCV test MSE:    0.19466233629207197





[&#39;mean_fit_time&#39;,
 &#39;mean_score_time&#39;,
 &#39;mean_test_score&#39;,
 &#39;param_max_depth&#39;,
 &#39;param_n_estimators&#39;,
 &#39;params&#39;,
 &#39;rank_test_score&#39;,
 &#39;split0_test_score&#39;,
 &#39;split1_test_score&#39;,
 &#39;split2_test_score&#39;,
 &#39;split3_test_score&#39;,
 &#39;split4_test_score&#39;,
 &#39;std_fit_time&#39;,
 &#39;std_score_time&#39;,
 &#39;std_test_score&#39;]</code></pre><h4 id="代码解释-4">代码解释</h4><p><code>RandomizedSearchCV</code> 是一个用于进行随机搜索的类，与 <code>GridSearchCV</code> 类似，它也可以用于参数调优和模型选择。</p><p>与网格搜索不同的是，随机搜索并不尝试所有可能的参数组合。相反，它从参数空间中随机抽样一组参数，并对每组参数进行评估。通过设置抽样的次数，我们可以控制随机搜索的规模。</p><p>下面是使用 <code>RandomizedSearchCV</code> 的一般流程：</p><ol type="1"><li>导入 <code>RandomizedSearchCV</code> 类和要使用的模型类。</li><li>定义要搜索的参数空间。可以使用分布函数（如均匀分布、正态分布），也可以使用指定的参数列表。</li><li>创建模型对象。</li><li>创建 <code>RandomizedSearchCV</code> 对象，传入模型对象、参数空间和其他参数（例如交叉验证的折数）。</li><li>使用 <code>fit</code> 方法拟合数据，并进行随机搜索和交叉验证。</li><li>可以通过 <code>best_params_</code> 属性查看最佳参数组合。</li><li>可以通过 <code>best_score_</code> 属性查看最佳参数组合的得分。</li><li>可以通过 <code>cv_results_</code> 属性查看所有参数组合的详细结果。</li></ol><h2 id="lgb-调参">4.3 Lgb 调参</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用数据训练LGB模型，采用网格搜索方法调参</span><br><br>clf = lgb.LGBMRegressor(num_leaves=<span class="hljs-number">31</span>)<br><br>parameters = &#123;<br>  <br>    <span class="hljs-string">&#x27;learning_rate&#x27;</span>: [<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">20</span>, <span class="hljs-number">40</span>]<br>    <br>&#125;<br><br>clf = GridSearchCV(clf, parameters, cv=<span class="hljs-number">5</span>)<br>clf.fit(train_data, train_target)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Best parameters found by grid search are:&#x27;</span>, clf.best_params_)<br>score_test = mean_squared_error(test_target, clf.predict(test_data))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;LGBMRegressor RandomizedSearchCV test MSE:   &quot;</span>, score_test)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Best parameters found by grid search are: &#123;&#39;learning_rate&#39;: 0.1, &#39;n_estimators&#39;: 40&#125;
LGBMRegressor RandomizedSearchCV test MSE:    0.1521115918778782</code></pre><h2 id="lgb-线下验证">4.4 Lgb 线下验证</h2><p>下面进行数据建模、5折交叉验证、划分数据、对LGB模型进行训练、计算MSE评价性能等流程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data2 = pd.read_csv(<span class="hljs-string">&#x27;./data/zhengqi_train.txt&#x27;</span>,sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br>test_data2 = pd.read_csv(<span class="hljs-string">&#x27;./data/zhengqi_test.txt&#x27;</span>,sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br><br>train_data2_feature = train_data2[test_data2.columns].values<br>train_data2_target = train_data2[<span class="hljs-string">&#x27;target&#x27;</span>].values<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lgb 模型</span><br><span class="hljs-keyword">from</span> sklearn.model_selection  <span class="hljs-keyword">import</span> KFold<br><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-comment"># 5折交叉验证</span><br>Folds=<span class="hljs-number">5</span><br>kf = KFold( n_splits=Folds, random_state=<span class="hljs-number">100</span>, shuffle=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 记录训练和预测MSE</span><br>MSE_DICT = &#123;<br>    <span class="hljs-string">&#x27;train_mse&#x27;</span>:[],<br>    <span class="hljs-string">&#x27;test_mse&#x27;</span>:[]<br>&#125;<br><br><span class="hljs-comment"># 线下训练预测</span><br><span class="hljs-keyword">for</span> i, (train_index, test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(train_data2_feature)):<br>    <span class="hljs-comment"># lgb树模型</span><br>    lgb_reg = lgb.LGBMRegressor(<br>        learning_rate=<span class="hljs-number">0.01</span>,<br>        max_depth=-<span class="hljs-number">1</span>,<br>        n_estimators=<span class="hljs-number">100</span>,<br>        boosting_type=<span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>        random_state=<span class="hljs-number">100</span>,<br>        objective=<span class="hljs-string">&#x27;regression&#x27;</span>,<br>    )<br>   <br>    <span class="hljs-comment"># 切分训练集和预测集</span><br>    X_train_KFold, X_test_KFold = train_data2_feature[train_index], train_data2_feature[test_index] <span class="hljs-comment"># 划分出训练集和测试集的特征</span><br>    y_train_KFold, y_test_KFold = train_data2_target[train_index], train_data2_target[test_index] <span class="hljs-comment"># 划分出训练集和测试集的标签</span><br>    <br>    <span class="hljs-comment"># 训练模型</span><br><span class="hljs-comment">#     reg.fit(X_train_KFold, y_train_KFold)</span><br>    lgb_reg.fit(<br>            X=X_train_KFold,y=y_train_KFold,<br>            eval_set=[(X_train_KFold, y_train_KFold),(X_test_KFold, y_test_KFold)],<br>            eval_names=[<span class="hljs-string">&#x27;Train&#x27;</span>,<span class="hljs-string">&#x27;Test&#x27;</span>],<br>            <span class="hljs-comment"># early_stopping_round=100, # 参数已弃用,通过“callbacks”参数传递回调</span><br>            <span class="hljs-comment"># verbose=50, # 参数已弃用,通过“callbacks”参数传递回调</span><br>            eval_metric=<span class="hljs-string">&#x27;MSE&#x27;</span>,<span class="hljs-comment"># 设置评估指标eval_metric，这里使用均方误差（MSE）</span><br>            callbacks=[lgb.log_evaluation(period=<span class="hljs-number">100</span>), lgb.early_stopping(stopping_rounds=<span class="hljs-number">50</span>)]<br>            <br>        )<br><br><br>    <span class="hljs-comment"># 训练集预测 测试集预测</span><br>    y_train_KFold_predict = lgb_reg.predict(X_train_KFold,num_iteration=lgb_reg.best_iteration_)<br>    y_test_KFold_predict = lgb_reg.predict(X_test_KFold,num_iteration=lgb_reg.best_iteration_) <br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;第&#123;&#125;折 训练和预测 训练MSE 预测MSE&#x27;</span>.<span class="hljs-built_in">format</span>(i))<br>    train_mse = mean_squared_error(y_train_KFold_predict, y_train_KFold)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;------\n&#x27;</span>, <span class="hljs-string">&#x27;训练MSE\n&#x27;</span>, train_mse, <span class="hljs-string">&#x27;\n------&#x27;</span>)<br>    test_mse = mean_squared_error(y_test_KFold_predict, y_test_KFold)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;------\n&#x27;</span>, <span class="hljs-string">&#x27;预测MSE\n&#x27;</span>, test_mse, <span class="hljs-string">&#x27;\n------\n&#x27;</span>)<br>    <br>    MSE_DICT[<span class="hljs-string">&#x27;train_mse&#x27;</span>].append(train_mse)<br>    MSE_DICT[<span class="hljs-string">&#x27;test_mse&#x27;</span>].append(test_mse)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;------\n&#x27;</span>, <span class="hljs-string">&#x27;训练MSE\n&#x27;</span>, MSE_DICT[<span class="hljs-string">&#x27;train_mse&#x27;</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, np.mean(MSE_DICT[<span class="hljs-string">&#x27;train_mse&#x27;</span>]), <span class="hljs-string">&#x27;\n------&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;------\n&#x27;</span>, <span class="hljs-string">&#x27;预测MSE\n&#x27;</span>, MSE_DICT[<span class="hljs-string">&#x27;test_mse&#x27;</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, np.mean(MSE_DICT[<span class="hljs-string">&#x27;test_mse&#x27;</span>]), <span class="hljs-string">&#x27;\n------&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000650 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8853
[LightGBM] [Info] Number of data points in the train set: 2310, number of used features: 38
[LightGBM] [Info] Start training from score 0.121817
Training until validation scores don&#39;t improve for 50 rounds
[100]   Train&#39;s l2: 0.223959    Test&#39;s l2: 0.247217
Did not meet early stopping. Best iteration is:
[100]   Train&#39;s l2: 0.223959    Test&#39;s l2: 0.247217
第0折 训练和预测 训练MSE 预测MSE
------
 训练MSE
 0.22395910176815867 
------
------
 预测MSE
 0.24721747302378572 
------

[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8853
[LightGBM] [Info] Number of data points in the train set: 2310, number of used features: 38
[LightGBM] [Info] Start training from score 0.113222
Training until validation scores don&#39;t improve for 50 rounds
[100]   Train&#39;s l2: 0.221409    Test&#39;s l2: 0.25435
Did not meet early stopping. Best iteration is:
[100]   Train&#39;s l2: 0.221409    Test&#39;s l2: 0.25435
第1折 训练和预测 训练MSE 预测MSE
------
 训练MSE
 0.22140920255015417 
------
------
 预测MSE
 0.2543498234383045 
------

[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8838
[LightGBM] [Info] Number of data points in the train set: 2310, number of used features: 38
[LightGBM] [Info] Start training from score 0.132497
Training until validation scores don&#39;t improve for 50 rounds
[100]   Train&#39;s l2: 0.221398    Test&#39;s l2: 0.256187
Did not meet early stopping. Best iteration is:
[100]   Train&#39;s l2: 0.221398    Test&#39;s l2: 0.256187
第2折 训练和预测 训练MSE 预测MSE
------
 训练MSE
 0.22139783747290231 
------
------
 预测MSE
 0.25618731408519657 
------

[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8849
[LightGBM] [Info] Number of data points in the train set: 2311, number of used features: 38
[LightGBM] [Info] Start training from score 0.125889
Training until validation scores don&#39;t improve for 50 rounds
[100]   Train&#39;s l2: 0.225142    Test&#39;s l2: 0.250629
Did not meet early stopping. Best iteration is:
[100]   Train&#39;s l2: 0.225142    Test&#39;s l2: 0.250629
第3折 训练和预测 训练MSE 预测MSE
------
 训练MSE
 0.22514211678664525 
------
------
 预测MSE
 0.2506288004181115 
------

[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8837
[LightGBM] [Info] Number of data points in the train set: 2311, number of used features: 38
[LightGBM] [Info] Start training from score 0.138334
Training until validation scores don&#39;t improve for 50 rounds
[100]   Train&#39;s l2: 0.2212  Test&#39;s l2: 0.256939
Did not meet early stopping. Best iteration is:
[100]   Train&#39;s l2: 0.2212  Test&#39;s l2: 0.256939
第4折 训练和预测 训练MSE 预测MSE
------
 训练MSE
 0.22120001873881776 
------
------
 预测MSE
 0.2569386630797994 
------

------
 训练MSE
 [0.22395910176815867, 0.22140920255015417, 0.22139783747290231, 0.22514211678664525, 0.22120001873881776] 
 0.22262165546333562 
------
------
 预测MSE
 [0.24721747302378572, 0.2543498234383045, 0.25618731408519657, 0.2506288004181115, 0.2569386630797994] 
 0.2530644148090395 
------</code></pre><p><img src="/img/工业蒸汽预测-05-2赛题模型验证/052_1.png" srcset="/img/loading.gif" lazyload width="300" height="200" alt="" align="center"></p><h4 id="代码解释-5">代码解释</h4><ol type="1"><li><code>eval_set</code> 参数 在训练过程中用于指定评估模型性能的数据集。可以提供一个或多个数据集用于监控模型的性能，并在训练过程中进行早停法（early stopping）等操作。</li></ol><p><code>eval_set</code>参数接受一个二维列表，每个元素都是一个包含特征和目标变量的元组。每个元组代表一个数据集，通常由特征数据和对应的目标变量组成。</p><p>例如，如果我们有一个训练数据集<code>(X_train, y_train)</code>和一个测试数据集<code>(X_test, y_test)</code>，可以将它们作为元组传递给<code>eval_set</code>参数，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">eval_set = [(X_train, y_train), (X_test, y_test)]<br></code></pre></td></tr></table></figure><p>在训练过程中，模型将使用这些数据集来计算训练误差和验证误差，并根据验证误差的变化来决定是否进行早停法。通常情况下，可以通过设置<code>early_stopping_rounds</code>参数来定义早停法的逻辑。</p><hr><ol start="2" type="1"><li><code>eval_names</code>参数 <code>eval_names</code>参数用于为<code>eval_set</code>中的数据集指定名称，以便在输出结果中标识每个数据集的名称。</li></ol><hr><ol start="3" type="1"><li><code>callbacks</code> 参数</li></ol><p>参数输入要求 <code>callbacks : list of callable, or None, optional (default=None)</code> 入参是一个list，list中的对象都是callback方法。callbacks在官方文档中主要是四种方法</p><ul><li><p>early_stopping</p><ul><li>停止迭代</li></ul><p><code>lightgbm.early_stopping(stopping_rounds, first_metric_only=False, verbose=True, min_delta=0.0)</code></p></li><li><p>log_evaluation</p></li><li><p>记录迭代过程的指标, 可以在日志中输出 <code>lightgbm.log_evaluation(period=1, show_stdv=True)</code></p></li><li><p>record_evaluation(eval_result)</p></li><li><p>把迭代过程指标记录到输入的空字典中 <code>lightgbm.record_evaluation(eval_result)</code> ;eval_result 可以为一个空字典<code>eval_result = &#123;&#125;</code></p></li><li><p><code>reset_parameter(**kwargs)</code></p></li><li><p>每次迭代更新数据</p><p>List of parameters for each boosting round or a callable that calculates the parameter in terms of current number of round</p></li></ul><p><strong>示例：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">eval_result = &#123;&#125;<br>lgb_model = lgb.train(lgb_param, train_set=tr_lgb_dt , valid_sets=[tr_lgb_dt, te_lgb_dt], <br>          verbose_eval=<span class="hljs-number">20</span>,<br>          callbacks=[lgb.log_evaluation, lgb.early_stopping(<span class="hljs-number">50</span>, first_metric_only=<span class="hljs-literal">True</span>), lgb.record_evaluation(eval_result)]<br>          )<br><br></code></pre></td></tr></table></figure><hr><ol start="4" type="1"><li><code>lgb_reg.predict</code>中<code>num_iteration</code>参数</li></ol><p><code>num_iteration</code> 参数用于指定预测时使用的树的迭代次数。在 LightGBM 中，模型训练过程中树的数量是逐步增加的，每一轮都会产生一个新的树。在预测时，可以选择使用模型训练过程中的某个迭代轮数的树来进行预测。</p><p>在训练模型时使用了早停功能，即设置了 <code>early_stopping_round</code> 参数，那么最佳迭代次数会自动选择并保存在 <code>lgb_reg.best_iteration_</code> 属性中。所以可以将其作为 <code>num_iteration</code> 参数传递给 <code>predict()</code> 方法，以便在预测时使用最佳迭代次数的树。</p><h1 id="学习曲线和验证曲线">5 学习曲线和验证曲线</h1><h2 id="学习曲线">5.1 学习曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> model_selection <br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDRegressor<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> learning_curve<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_learning_curve</span>(<span class="hljs-params">estimator, title, X, y, ylim=<span class="hljs-literal">None</span>, cv=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                        n_jobs=<span class="hljs-number">1</span>, train_sizes=np.linspace(<span class="hljs-params"><span class="hljs-number">.1</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">5</span></span>)</span>):<br>    <br>    plt.figure()<br>    plt.title(title)<br>    <span class="hljs-keyword">if</span> ylim <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        plt.ylim(*ylim)<br>    plt.xlabel(<span class="hljs-string">&quot;Training examples&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Score&quot;</span>)<br>    train_sizes, train_scores, test_scores = learning_curve(<br>        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)<br>    train_scores_mean = np.mean(train_scores, axis=<span class="hljs-number">1</span>)<br>    train_scores_std = np.std(train_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_mean = np.mean(test_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_std = np.std(test_scores, axis=<span class="hljs-number">1</span>)<br>    plt.grid()<br><br>    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,<br>                     train_scores_mean + train_scores_std, alpha=<span class="hljs-number">0.1</span>,<br>                     color=<span class="hljs-string">&quot;r&quot;</span>)<br>    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,<br>                     test_scores_mean + test_scores_std, alpha=<span class="hljs-number">0.1</span>, color=<span class="hljs-string">&quot;g&quot;</span>)<br>    plt.plot(train_sizes, train_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;r&quot;</span>,<br>             label=<span class="hljs-string">&quot;Training score&quot;</span>)<br>    plt.plot(train_sizes, test_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;g&quot;</span>,<br>             label=<span class="hljs-string">&quot;Cross-validation score&quot;</span>)<br><br>    plt.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br>    <span class="hljs-keyword">return</span> plt<br><br><br>X = train_data2[test_data2.columns].values<br>y = train_data2[<span class="hljs-string">&#x27;target&#x27;</span>].values<br><br><br>title = <span class="hljs-string">&quot;LinearRegression&quot;</span><br><span class="hljs-comment"># Cross validation with 100 iterations to get smoother mean test and train</span><br><span class="hljs-comment"># score curves, each time with 20% data randomly selected as a validation set.</span><br>cv = model_selection.ShuffleSplit(n_splits=<span class="hljs-number">100</span>,<br>                                   test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)<br><br>estimator = SGDRegressor()<br>plot_learning_curve(estimator, title, X, y, ylim=(<span class="hljs-number">0.7</span>, <span class="hljs-number">1.01</span>), cv=cv, n_jobs=<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;module &#39;matplotlib.pyplot&#39; from &#39;D:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\pyplot.py&#39;&gt;</code></pre><p>​<br><img src="/img/工业蒸汽预测-05-2赛题模型验证/output_53_1.png" srcset="/img/loading.gif" lazyload> ​</p><h2 id="验证曲线">5.2 验证曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDRegressor<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> validation_curve<br><br>X = train_data2[test_data2.columns].values<br>y = train_data2[<span class="hljs-string">&#x27;target&#x27;</span>].values<br><span class="hljs-comment"># max_iter=1000, tol=1e-3, penalty= &#x27;L1&#x27;, alpha=0.00001</span><br><br>param_range = [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.001</span>, <span class="hljs-number">0.0001</span>, <span class="hljs-number">0.00001</span>, <span class="hljs-number">0.000001</span>]<br>train_scores, test_scores = validation_curve(<br>    SGDRegressor(max_iter=<span class="hljs-number">1000</span>, tol=<span class="hljs-number">1e-3</span>, penalty= <span class="hljs-string">&#x27;L1&#x27;</span>), X, y, param_name=<span class="hljs-string">&quot;alpha&quot;</span>, param_range=param_range,<br>    cv=<span class="hljs-number">10</span>, scoring=<span class="hljs-string">&#x27;r2&#x27;</span>, n_jobs=<span class="hljs-number">1</span>)<br>train_scores_mean = np.mean(train_scores, axis=<span class="hljs-number">1</span>)<br>train_scores_std = np.std(train_scores, axis=<span class="hljs-number">1</span>)<br>test_scores_mean = np.mean(test_scores, axis=<span class="hljs-number">1</span>)<br>test_scores_std = np.std(test_scores, axis=<span class="hljs-number">1</span>)<br><br>plt.title(<span class="hljs-string">&quot;Validation Curve with SGDRegressor&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;alpha&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Score&quot;</span>)<br>plt.ylim(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.1</span>)<br>plt.semilogx(param_range, train_scores_mean, label=<span class="hljs-string">&quot;Training score&quot;</span>, color=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.fill_between(param_range, train_scores_mean - train_scores_std,<br>                 train_scores_mean + train_scores_std, alpha=<span class="hljs-number">0.2</span>, color=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.semilogx(param_range, test_scores_mean, label=<span class="hljs-string">&quot;Cross-validation score&quot;</span>,<br>             color=<span class="hljs-string">&quot;g&quot;</span>)<br>plt.fill_between(param_range, test_scores_mean - test_scores_std,<br>                 test_scores_mean + test_scores_std, alpha=<span class="hljs-number">0.2</span>, color=<span class="hljs-string">&quot;g&quot;</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽预测-05-2赛题模型验证/output_55_0.png" srcset="/img/loading.gif" lazyload></p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>工业蒸汽预测-05-2赛题模型验证</div><div>https://zhou1317fe5.github.io/2023/09/04/工业蒸汽预测-05-2赛题模型验证/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年9月4日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/09/09/C%E8%AF%AD%E8%A8%8004-%E6%95%B0%E7%BB%8412/" title="C语言04-数组12"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">C语言04-数组12</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/09/03/C%E8%AF%AD%E8%A8%8003-%E5%87%BD%E6%95%B0%E5%92%8C%E9%80%92%E5%BD%92123/" title="C语言03-函数和递归123"><span class="hidden-mobile">C语言03-函数和递归123</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>