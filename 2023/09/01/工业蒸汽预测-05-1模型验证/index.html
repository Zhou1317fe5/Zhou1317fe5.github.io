<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="1 模型评估的概念和方法 1.1 过拟合与欠拟合 获取并绘制数据集 1234567891011import numpy as npimport matplotlib.pyplot as plt%matplotlib inlinenp.random.seed(666)x &#x3D; np.random.uniform(-3.0, 3.0, size&#x3D;100)X &#x3D; x.reshape(-1, 1)y"><meta property="og:type" content="article"><meta property="og:title" content="工业蒸汽预测-05-1模型验证"><meta property="og:url" content="http://zhou1317fe5.link/2023/09/01/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05-1%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="1 模型评估的概念和方法 1.1 过拟合与欠拟合 获取并绘制数据集 1234567891011import numpy as npimport matplotlib.pyplot as plt%matplotlib inlinenp.random.seed(666)x &#x3D; np.random.uniform(-3.0, 3.0, size&#x3D;100)X &#x3D; x.reshape(-1, 1)y"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_3_0.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_10_0.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_19_0.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_22_1.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_25_1.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/05_1.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/05_2.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/05_3.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_39_1.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_41_1.png"><meta property="og:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_43_0.png"><meta property="article:published_time" content="2023-09-01T00:46:56.000Z"><meta property="article:modified_time" content="2023-09-11T01:51:36.575Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://zhou1317fe5.link/img/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E9%A2%84%E6%B5%8B-05%201%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/output_3_0.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>工业蒸汽预测-05-1模型验证 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.link",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="工业蒸汽预测-05-1模型验证"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-09-01 08:46" pubdate>2023年9月1日 早上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 22k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 181 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">工业蒸汽预测-05-1模型验证</h1><div class="markdown-body"><h1 id="模型评估的概念和方法">1 模型评估的概念和方法</h1><h2 id="过拟合与欠拟合">1.1 过拟合与欠拟合</h2><h3 id="获取并绘制数据集">获取并绘制数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>%matplotlib inline<br><br>np.random.seed(<span class="hljs-number">666</span>)<br>x = np.random.uniform(-<span class="hljs-number">3.0</span>, <span class="hljs-number">3.0</span>, size=<span class="hljs-number">100</span>)<br>X = x.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>y = <span class="hljs-number">0.5</span> * x**<span class="hljs-number">2</span> + x + <span class="hljs-number">2</span> + np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, size=<span class="hljs-number">100</span>)<br><br>plt.scatter(x, y)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/img/工业蒸汽预测-05%201模型验证/output_3_0.png" srcset="/img/loading.gif" lazyload></p><h4 id="代码解释">代码解释</h4><ul><li><p><code>np.random.seed(666)</code>：设置随机数种子，这样可以确保每次运行代码时生成的随机数是一致的,仅是为了使随机结果可重现，它不直接与散点图有关。。</p></li><li><p><code>x = np.random.uniform(-3.0, 3.0, size=100)</code>：生成一个包含100个在-3.0到3.0之间均匀分布的随机数的一维数组。</p></li><li><p><code>X = x.reshape(-1, 1)</code>：将一维数组 <code>x</code> 转换（重塑reshape）为二维数组 <code>X</code>，其中一列是 <code>x</code> 的值，行数自动计算以匹配原始数据的维度。<code>reshape(-1, 1)</code> 的作用是将一维数组 x 转换为一个二维数组 X，其中 -1 表示自动计算该维度的大小，而 1 表示要创建的数组的列数为1。</p></li><li><p><code>y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)</code>：根据给定的二次函数关系生成 <code>y</code> 值，并添加均值为0，标准差为1的正态分布随机噪声。<code>np.random.normal(0, 1, size=100)</code> 是用于生成服从正态分布（高斯分布）的随机数的 NumPy 函数。</p><ul><li><code>0</code>：表示正态分布的均值（mean）为0，即随机数的平均值为0。</li><li><code>1</code>：表示正态分布的标准差（standard deviation）为1，即随机数的离散程度。</li><li><code>size=100</code>：表示要生成的随机数的数量为100。</li></ul><p>这个函数将生成一个包含100个元素的一维数组，其中的每个元素都是从均值为0、标准差为1的正态分布中抽取的随机数。在本例中，这些随机数表示了噪声，会被添加到二次曲线的计算结果中，用于在原始数据上引入一些随机性和波动。</p><p>最终，通过 <code>y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)</code> 这行代码，我们将按照二次函数关系生成的理想曲线上加入了服从正态分布的随机噪声，得到了最终的观测数据 <code>y</code>。噪声的作用是模拟现实世界中数据的波动性和随机性，使得数据更接近真实情况。</p></li><li><p><code>plt.scatter(x, y)</code>：创建散点图，将 <code>x</code> 和 <code>y</code> 的值传递给 <code>scatter()</code> 函数以绘制数据点。</p></li></ul><p>使用线性回归拟合数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br><br>lin_reg = LinearRegression()<br>lin_reg.fit(X, y)<br>lin_reg.score(X, y)<br></code></pre></td></tr></table></figure><pre><code class="hljs">0.4953707811865009</code></pre><p>准确率为 0.495，比较低，直线拟合数据的程度较低。</p><h3 id="使用均方误差判断拟合程度">使用均方误差判断拟合程度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br>y_predict = lin_reg.predict(X)<br>mean_squared_error(y, y_predict)<br></code></pre></td></tr></table></figure><pre><code class="hljs">3.0750025765636577</code></pre><h3 id="绘制拟合结果">绘制拟合结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">y_predict = lin_reg.predict(X)<br>plt.scatter(x, y)<br>plt.plot(np.sort(x), y_predict[np.argsort(x)], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-05%201模型验证/output_10_0.png" srcset="/img/loading.gif" lazyload> ​</p><h4 id="代码解释-1">代码解释</h4><p><code>plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')</code> 用于在图形中绘制拟合直线。</p><ul><li><p><code>np.sort(x)</code>：将输入特征 <code>x</code> 进行升序排序，得到排序后的数组。这是因为 <code>x</code> 的顺序可能是乱序的，绘制拟合直线时需要按照从小到大的顺序连接数据点。</p></li><li><p><code>y_predict[np.argsort(x)]</code>：根据 <code>x</code> 的排序结果，对预测值 <code>y_predict</code> 进行重新排列。<code>np.argsort(x)</code> 返回的是 <code>x</code> 的索引按照升序排列的结果。通过使用这个索引数组对 <code>y_predict</code> 进行切片操作，可以按照相同的顺序重新排列预测值，使其与排序后的 <code>x</code> 相对应。</p></li><li><p><code>color='r'</code>：指定拟合直线的颜色为红色 ('r')。</p></li></ul><p>将排序后的输入特征 <code>x</code> 与重新排列的预测值 <code>y_predict</code> 作为参数传递给 <code>plot()</code> 函数，绘制拟合直线。通过按照从小到大的顺序连接数据点，可以在图形中展示出线性回归模型对原始数据的拟合程度。</p><h3 id="使用多项式回归拟合">使用多项式回归拟合</h3><ul><li>首先封装Pipeline管道，这样便于下一步灵活调整多项式回归模型参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline <br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> PolynomialFeatures<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">PolynomialRegression</span>(<span class="hljs-params">degree</span>):<br>    <span class="hljs-keyword">return</span> Pipeline([<br>        (<span class="hljs-string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),<br>        (<span class="hljs-string">&#x27;std_scaler&#x27;</span>, StandardScaler()),<br>        (<span class="hljs-string">&#x27;lin_reg&#x27;</span>, LinearRegression())<br>    ])<br></code></pre></td></tr></table></figure><h4 id="代码解释-2">代码解释</h4><p>用于创建多项式回归模型的函数。使用sklearn库中的Pipeline类来构建一个机器学习工作流程，包括多项式特征转换、标准化和线性回归模型。</p><ul><li><p><code>from sklearn.pipeline import Pipeline</code>: Pipeline类，用于将多个数据处理步骤和机器学习模型封装在一起，形成一个流水线。</p></li><li><p><code>from sklearn.preprocessing import PolynomialFeatures</code>: PolynomialFeatures类，用于进行多项式特征转换。</p></li><li><p><code>from sklearn.preprocessing import StandardScaler</code>: StandardScaler类，用于进行特征标准化（特征缩放）。</p></li><li><p><code>def PolynomialRegression(degree)</code>: 定义PolynomialRegression函数，接受参数degree，表示多项式的次数。</p></li><li><p><code>return Pipeline([...])</code>: 使用Pipeline类创建一个机器学习工作流程并返回。Pipeline类接受一个由元组构成的列表作为参数，每个元组代表工作流程中的一个步骤。</p><ul><li><p><code>('poly', PolynomialFeatures(degree=degree))</code>: 多项式特征转换步骤，将输入特征转换为指定次数的多项式特征。使用PolynomialFeatures类，并将其实例命名为'poly'。</p></li><li><p><code>('std_scaler', StandardScaler())</code>: 标准化步骤，对多项式特征进行特征缩放，使特征的均值为0，标准差为1。使用StandardScaler类，并将其实例命名为'std_scaler'。</p></li><li><p><code>('lin_reg', LinearRegression())</code>: 线性回归模型步骤，用于拟合多项式特征和目标变量之间的关系。使用LinearRegression类，并将其实例命名为'lin_reg'。</p></li></ul></li></ul><p>创建一个多项式回归模型，通过使用多项式特征转换和标准化来提高模型的性能。可以根据需要选择不同的多项式次数，从而得到不同复杂度的模型。</p><ul><li>使用 Pipeline 拟合数据：degree = 2</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">poly2_reg = PolynomialRegression(degree=<span class="hljs-number">2</span>)<br>poly2_reg.fit(X, y)<br><br>y2_predict = poly2_reg.predict(X)<br><br><span class="hljs-comment"># 比较真值和预测值的均方误差</span><br>mean_squared_error(y, y2_predict)<br></code></pre></td></tr></table></figure><pre><code class="hljs">1.0987392142417858</code></pre><ul><li>绘制拟合结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.scatter(x, y)<br>plt.plot(np.sort(x), y2_predict[np.argsort(x)], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-05%201模型验证/output_19_0.png" srcset="/img/loading.gif" lazyload> ​</p><ul><li>调整 degree = 10</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">poly10_reg = PolynomialRegression(degree=<span class="hljs-number">10</span>)<br>poly10_reg.fit(X, y)<br><br>y10_predict = poly10_reg.predict(X)<br><span class="hljs-built_in">print</span>(mean_squared_error(y, y10_predict))<br><br><br>plt.scatter(x, y)<br>plt.plot(np.sort(x), y10_predict[np.argsort(x)], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><pre><code class="hljs">1.0508466763764126</code></pre><p><img src="/img/工业蒸汽预测-05%201模型验证/output_22_1.png" srcset="/img/loading.gif" lazyload></p><ul><li>调整 degree = 100</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">poly100_reg = PolynomialRegression(degree=<span class="hljs-number">100</span>)<br>poly100_reg.fit(X, y)<br><br>y100_predict = poly100_reg.predict(X)<br><span class="hljs-built_in">print</span>(mean_squared_error(y, y100_predict))<br><br><br>plt.scatter(x, y)<br>plt.plot(np.sort(x), y100_predict[np.argsort(x)], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><pre><code class="hljs">0.6807802342342404</code></pre><p><img src="/img/工业蒸汽预测-05%201模型验证/output_25_1.png" srcset="/img/loading.gif" lazyload></p><ul><li>分析<ol type="1"><li>degree=2：均方误差为 1.0987392142417858；</li><li>degree=10：均方误差为 1.0508466763764126；</li><li>degree=100：均方误差为 0.6807802342342404；</li><li>degree 越大拟合的效果越好，因为样本点是一定的，我们总能找到一条曲线将所有的样本点拟合，也就是说将所有的样本点都完全落在这根曲线上，使得整体的均方误差为 0；</li><li>红色曲线并不是所计算出的拟合曲线，而此红色曲线只是原有的数据点对应的 y 的预测值连接出来的结果，而且有的地方没有数据点，因此连接的结果和原来的曲线不一样；</li></ol></li></ul><h2 id="交叉验证">1.2 交叉验证</h2><h3 id="交叉验证迭代器">1.2.1交叉验证迭代器</h3><p><strong>K折交叉验证</strong>：K-Fold Cross Validation,是将原始数据分成K组（一般是均分）,称为折叠 (fold)，然后将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样就会得到K个模型，将K个模型最终的验证集的分类准确率取平均值，作为K折交叉验证分类器的性能指标。通常设置K大于或等于3。</p><p><img src="/img/工业蒸汽预测-05%201模型验证/05_1.png" srcset="/img/loading.gif" lazyload></p><p><strong>K折重复多次</strong>： RepeatedKFold 重复 K-Fold n 次。当需要运行时可以使用它 KFold n 次，在每次重复中产生不同的分割。</p><p><strong>留一交叉验证</strong>： LeaveOneOut (或 LOO) 是一个简单的交叉验证。每个训练集都由除了一个样本以外的其余所有样本组成的，留下的一个样本组成检验集。 这样，对于 n 个样本，我们有 n 个不同的训练集和 n 个不同的测试集。因此LOO-CV会得到N个模型，用N个模型最终的验证集的分类准确率的平均数作为分类器的性能指标。这种交叉验证程序不会浪费太多数据，因为只有一个样本是从训练集中删除掉的。</p><p><img src="/img/工业蒸汽预测-05%201模型验证/05_2.png" srcset="/img/loading.gif" lazyload></p><p><strong>留P交叉验证</strong>： LeavePOut 与 LeaveOneOut 非常相似，因为它通过从整个集合中删除 p 个样本来创建所有可能的训练/测试集。对于 n 个样本，这产生了 (n,p) 个 训练-测试对。与 LeaveOneOut 和 KFold 不同，当 p &gt; 1 时，测试集会重叠。</p><p><strong>用户自定义数据集划分： ShuffleSplit</strong> 迭代器将会生成一个用户给定数量的独立的训练/测试数据划分。样例首先被打散然后划分为一对训练测试集合。</p><p><strong>设置每次生成的随机数相同</strong>： 可以通过设定明确的 random_state ，使得伪随机生成器的结果可以重复。</p><h3 id="基于类标签具有分层的交叉验证迭代器">1.2.2基于类标签、具有分层的交叉验证迭代器</h3><p>如何解决样本不平衡问题？ 使用StratifiedKFold和StratifiedShuffleSplit 分层抽样。 一些分类问题在目标类别的分布上可能表现出很大的不平衡性：例如，可能会出现比正样本多数倍的负样本。在这种情况下，建议采用如 StratifiedKFold 和 StratifiedShuffleSplit 中实现的分层抽样方法，确保相应的类别频率在每个训练和验证的折叠中大致得以保留。</p><p><strong>StratifiedKFold</strong>是 k-fold 的变种，会返回 stratified（分层） 的折叠：每个小集合中，各个类别的样例比例大致和完整数据集中相同。</p><p><strong>StratifiedShuffleSplit</strong>是 ShuffleSplit 的一个变种，会返回直接的划分，比如：创建一个划分，但是划分中每个类的比例和完整数据集中的相同。</p><h3 id="用于分组数据的交叉验证迭代器">1.2.3用于分组数据的交叉验证迭代器</h3><p>如何进一步测试模型的泛化能力？ 留出一组特定的不属于测试集和训练集的数据。有时我们想知道在一组特定的 groups 上训练的模型是否能很好地适用于看不见的新数据。为了衡量这一点，我们需要确保验证对象中的所有样本均未在配对训练折叠中出现过，采用的办法就是留出一组特定的不属于测试集和训练集的数据，常用的方法包括GroupKFold,LeaveOneGroupOut,LeavePGroupsOut,GroupShuffleSplit.</p><p><strong>GroupKFold</strong>是 k-fold 的变体，它确保同一个 group 在测试和训练集中都不被表示。 例如，如果数据是从不同的组获得的，每个组又有多个样本，并且如果模型足够灵活，能高度从指定的特征中学习，则可能存在很好地拟合训练的组，但不能很好地预测不存在于训练组中的样本，GroupKFold 可以检测到这种过拟合的情况。</p><p><strong>LeaveOneGroupOut</strong>是一个交叉验证方案，它根据用户提供的 array of integer groups （整数组的数组）来区别不同的组，以此来提供样本。这个组信息可以用来编码任意域特定的预定义交叉验证折叠。每个训练集都是由除特定组别以外的所有样本构成的。</p><p><strong>LeavePGroupsOut</strong>类似于 LeaveOneGroupOut ，但为每个训练/测试集删除与 P 组有关的样本。</p><p><strong>GroupShuffleSplit</strong>迭代器是 ShuffleSplit 和 LeavePGroupsOut 的组合，它生成一个随机划分分区的序列，其中为每个分组提供了一个组子集。</p><h3 id="时间序列分割">1.2.4 时间序列分割</h3><p><strong>TimeSeriesSplit</strong> 也是K-Fold的一个变种，首先返回K折作为训练数据集，把K+1折作为测试数据集。请注意，与标准的交叉验证方法不同，有关时间序列的样本切分必须保证时间上的顺序性，不能用未来的数据去验证现在数据的正确性，只能使用时间上之前一段的数据建模，而用后一段时间的数据来验证模型预测的效果，这也是时间序列数据在做模型验证划分数据时与其他常规数据切分的区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split,cross_val_score,cross_validate <span class="hljs-comment"># 交叉验证所需的函数</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold,LeaveOneOut,LeavePOut,ShuffleSplit <span class="hljs-comment"># 交叉验证所需的子集划分方法</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold,StratifiedShuffleSplit <span class="hljs-comment"># 分层分割</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GroupKFold,LeaveOneGroupOut,LeavePGroupsOut,GroupShuffleSplit <span class="hljs-comment"># 分组分割</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> TimeSeriesSplit <span class="hljs-comment"># 时间序列分割</span><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets  <span class="hljs-comment"># 自带数据集</span><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm  <span class="hljs-comment"># SVM算法</span><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing  <span class="hljs-comment"># 预处理模块</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score  <span class="hljs-comment"># 模型度量</span><br><br>iris = datasets.load_iris()  <span class="hljs-comment"># 加载数据集</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;样本集大小：&#x27;</span>,iris.data.shape,iris.target.shape)<br><br><span class="hljs-comment"># ===================================数据集划分,训练模型==========================</span><br>X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="hljs-number">0.4</span>, random_state=<span class="hljs-number">0</span>)  <span class="hljs-comment"># 交叉验证划分训练集和测试集.test_size为测试集所占的比例</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练集大小：&#x27;</span>,X_train.shape,y_train.shape)  <span class="hljs-comment"># 训练集样本大小</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试集大小：&#x27;</span>,X_test.shape,y_test.shape)  <span class="hljs-comment"># 测试集样本大小</span><br>clf = svm.SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>, C=<span class="hljs-number">1</span>).fit(X_train, y_train) <span class="hljs-comment"># 使用训练集训练模型</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确率：&#x27;</span>,clf.score(X_test, y_test))  <span class="hljs-comment"># 计算测试集的度量值（准确率）</span><br><br><br><span class="hljs-comment">#  如果涉及到归一化，则在测试集上也要使用训练集模型提取的归一化函数。</span><br>scaler = preprocessing.StandardScaler().fit(X_train)  <span class="hljs-comment"># 通过训练集获得归一化函数模型。（也就是先减几，再除以几的函数）。在训练集和测试集上都使用这个归一化函数</span><br>X_train_transformed = scaler.transform(X_train)<br>clf = svm.SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>, C=<span class="hljs-number">1</span>).fit(X_train_transformed, y_train) <span class="hljs-comment"># 使用训练集训练模型</span><br>X_test_transformed = scaler.transform(X_test)<br><span class="hljs-built_in">print</span>(clf.score(X_test_transformed, y_test))  <span class="hljs-comment"># 计算测试集的度量值（准确度）</span><br><br><span class="hljs-comment"># ===================================直接调用交叉验证评估模型==========================</span><br>clf = svm.SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>, C=<span class="hljs-number">1</span>)<br>scores = cross_val_score(clf, iris.data, iris.target, cv=<span class="hljs-number">5</span>)  <span class="hljs-comment">#cv为迭代次数。</span><br><span class="hljs-built_in">print</span>(scores)  <span class="hljs-comment"># 打印输出每次迭代的度量值（准确度）</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy: %0.2f (+/- %0.2f)&quot;</span> % (scores.mean(), scores.std() * <span class="hljs-number">2</span>))  <span class="hljs-comment"># 获取置信区间。（也就是均值和方差）</span><br><br><span class="hljs-comment"># ===================================多种度量结果======================================</span><br>scoring = [<span class="hljs-string">&#x27;precision_macro&#x27;</span>, <span class="hljs-string">&#x27;recall_macro&#x27;</span>] <span class="hljs-comment"># precision_macro为精度（准确率），recall_macro为召回率</span><br>scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,cv=<span class="hljs-number">5</span>, return_train_score=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">sorted</span>(scores.keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试结果：&#x27;</span>,scores)  <span class="hljs-comment"># scores类型为字典。包含训练得分，拟合次数， score-times （得分次数）</span><br><br><br><span class="hljs-comment"># ==================================K折交叉验证、留一交叉验证、留p交叉验证、随机排列交叉验证==========================================</span><br><span class="hljs-comment"># k折划分子集</span><br>kf = KFold(n_splits=<span class="hljs-number">2</span>)<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> kf.split(iris.data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;k折划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># 留一划分子集</span><br>loo = LeaveOneOut()<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> loo.split(iris.data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;留一划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># 留p划分子集</span><br>lpo = LeavePOut(p=<span class="hljs-number">2</span>)<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> loo.split(iris.data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;留p划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># 随机排列划分子集</span><br>ss = ShuffleSplit(n_splits=<span class="hljs-number">3</span>, test_size=<span class="hljs-number">0.25</span>,random_state=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> ss.split(iris.data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机排列划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># ==================================分层K折交叉验证、分层随机交叉验证==========================================</span><br>skf = StratifiedKFold(n_splits=<span class="hljs-number">3</span>)  <span class="hljs-comment">#各个类别的比例大致和完整数据集中相同</span><br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> skf.split(iris.data, iris.target):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;分层K折划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br>skf = StratifiedShuffleSplit(n_splits=<span class="hljs-number">3</span>)  <span class="hljs-comment"># 划分中每个类的比例和完整数据集中的相同</span><br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> skf.split(iris.data, iris.target):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;分层随机划分：%s %s&quot;</span> % (train.shape, test.shape))<br>    <span class="hljs-keyword">break</span><br><br><br><span class="hljs-comment"># ==================================组 k-fold交叉验证、留一组交叉验证、留 P 组交叉验证、Group Shuffle Split==========================================</span><br>X = [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">2.2</span>, <span class="hljs-number">2.4</span>, <span class="hljs-number">2.3</span>, <span class="hljs-number">4.55</span>, <span class="hljs-number">5.8</span>, <span class="hljs-number">8.8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]<br>y = [<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>]<br>groups = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>]<br><br><span class="hljs-comment"># k折分组</span><br>gkf = GroupKFold(n_splits=<span class="hljs-number">3</span>)  <span class="hljs-comment"># 训练集和测试集属于不同的组</span><br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> gkf.split(X, y, groups=groups):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;组 k-fold分割：%s %s&quot;</span> % (train, test))<br><br><span class="hljs-comment"># 留一分组</span><br>logo = LeaveOneGroupOut()<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> logo.split(X, y, groups=groups):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;留一组分割：%s %s&quot;</span> % (train, test))<br><br><span class="hljs-comment"># 留p分组</span><br>lpgo = LeavePGroupsOut(n_groups=<span class="hljs-number">2</span>)<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> lpgo.split(X, y, groups=groups):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;留 P 组分割：%s %s&quot;</span> % (train, test))<br><br><span class="hljs-comment"># 随机分组</span><br>gss = GroupShuffleSplit(n_splits=<span class="hljs-number">4</span>, test_size=<span class="hljs-number">0.5</span>, random_state=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> gss.split(X, y, groups=groups):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机分割：%s %s&quot;</span> % (train, test))<br><br><br><span class="hljs-comment"># ==================================时间序列分割==========================================</span><br>tscv = TimeSeriesSplit(n_splits=<span class="hljs-number">3</span>)<br>TimeSeriesSplit(max_train_size=<span class="hljs-literal">None</span>, n_splits=<span class="hljs-number">3</span>)<br><span class="hljs-keyword">for</span> train, test <span class="hljs-keyword">in</span> tscv.split(iris.data):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;时间序列分割：%s %s&quot;</span> % (train, test))<br></code></pre></td></tr></table></figure><pre><code class="hljs">样本集大小： (150, 4) (150,)
训练集大小： (90, 4) (90,)
测试集大小： (60, 4) (60,)
准确率： 0.9666666666666667
0.9333333333333333
[0.96666667 1.         0.96666667 0.96666667 1.        ]
Accuracy: 0.98 (+/- 0.03)
测试结果： &#123;&#39;fit_time&#39;: array([0.00000000e+00, 1.00016594e-03, 1.00016594e-03, 4.05311584e-05,
       0.00000000e+00]), &#39;score_time&#39;: array([0.00100017, 0.        , 0.00100017, 0.        , 0.        ]), &#39;test_precision_macro&#39;: array([0.96969697, 1.        , 0.96969697, 0.96969697, 1.        ]), &#39;train_precision_macro&#39;: array([0.97674419, 0.97674419, 0.99186992, 0.98412698, 0.98333333]), &#39;test_recall_macro&#39;: array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ]), &#39;train_recall_macro&#39;: array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])&#125;
k折划分：(75,) (75,)
留一划分：(149,) (1,)
留p划分：(149,) (1,)
随机排列划分：(149,) (1,)
分层K折划分：(100,) (50,)
分层随机划分：(135,) (15,)
组 k-fold分割：[0 1 2 3 4 5] [6 7 8 9]
组 k-fold分割：[0 1 2 6 7 8 9] [3 4 5]
组 k-fold分割：[3 4 5 6 7 8 9] [0 1 2]
留一组分割：[3 4 5 6 7 8 9] [0 1 2]
留一组分割：[0 1 2 6 7 8 9] [3 4 5]
留一组分割：[0 1 2 3 4 5] [6 7 8 9]
留 P 组分割：[6 7 8 9] [0 1 2 3 4 5]
留 P 组分割：[3 4 5] [0 1 2 6 7 8 9]
留 P 组分割：[0 1 2] [3 4 5 6 7 8 9]
随机分割：[0 1 2] [3 4 5 6 7 8 9]
随机分割：[3 4 5] [0 1 2 6 7 8 9]
随机分割：[3 4 5] [0 1 2 6 7 8 9]
随机分割：[3 4 5] [0 1 2 6 7 8 9]
时间序列分割：[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38] [39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
 63 64 65 66 67 68 69 70 71 72 73 74 75]
时间序列分割：[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75] [ 76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93
  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111
 112]
时间序列分割：[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112] [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
 149]</code></pre><h1 id="模型调参">2 模型调参</h1><p>参数可分为两类：过程影响类参数和子模型影响类参数。</p><h2 id="网格搜索">2.1 网格搜索</h2><p>Grid Search：一种穷举搜索的调参手段；穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。</p><h3 id="简单的网格搜索">简单的网格搜索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br>iris = load_iris()<br><br>X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Size of training set:&#123;&#125; size of testing set:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(X_train.shape[<span class="hljs-number">0</span>],X_test.shape[<span class="hljs-number">0</span>]))<br><br><span class="hljs-comment">####   grid search start</span><br>best_score = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> gamma <span class="hljs-keyword">in</span> [<span class="hljs-number">0.001</span>,<span class="hljs-number">0.01</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,<span class="hljs-number">100</span>]:<br>    <span class="hljs-keyword">for</span> C <span class="hljs-keyword">in</span> [<span class="hljs-number">0.001</span>,<span class="hljs-number">0.01</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,<span class="hljs-number">100</span>]:<br>        svm = SVC(gamma=gamma,C=C)<span class="hljs-comment">#对于每种参数可能的组合，进行一次训练；</span><br>        svm.fit(X_train,y_train)<br>        score = svm.score(X_test,y_test)<br>        <span class="hljs-keyword">if</span> score &gt; best_score:<span class="hljs-comment">#找到表现最好的参数</span><br>            best_score = score<br>            best_parameters = &#123;<span class="hljs-string">&#x27;gamma&#x27;</span>:gamma,<span class="hljs-string">&#x27;C&#x27;</span>:C&#125;<br><span class="hljs-comment">####   grid search end</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best score:&#123;:.2f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(best_score))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best parameters:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(best_parameters))<br></code></pre></td></tr></table></figure><pre><code class="hljs">Size of training set:112 size of testing set:38
Best score:0.97
Best parameters:&#123;&#39;gamma&#39;: 0.001, &#39;C&#39;: 100&#125;</code></pre><h2 id="学习曲线和验证曲线">2.2 学习曲线和验证曲线</h2><h3 id="学习曲线">2.2.1 学习曲线</h3><p>通过学习曲线来绘制模型在训练集和交叉验证集上的准确率，观察模型在新数据上的表现进而判断模型的方差或偏差是否过高，以及增大训练集是否可以减小过拟合。 <img src="/img/工业蒸汽预测-05%201模型验证/05_3.png" srcset="/img/loading.gif" lazyload></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB <span class="hljs-comment"># 高斯朴素贝叶斯分类器</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC <span class="hljs-comment"># 支持向量机（SVM）分类器</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_digits <span class="hljs-comment"># 手写数字数据集</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> learning_curve <span class="hljs-comment"># 绘制学习曲线</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> ShuffleSplit <span class="hljs-comment"># 创建随机交叉验证策略</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 绘制学习曲线</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_learning_curve</span>(<span class="hljs-params">estimator, title, X, y, ylim=<span class="hljs-literal">None</span>, cv=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                        n_jobs=<span class="hljs-number">1</span>, train_sizes=np.linspace(<span class="hljs-params"><span class="hljs-number">.1</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">5</span></span>)</span>):<br>    plt.figure()<br>    plt.title(title)<br>    <span class="hljs-keyword">if</span> ylim <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        plt.ylim(*ylim)<br>    plt.xlabel(<span class="hljs-string">&quot;Training examples&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Score&quot;</span>)<br>    train_sizes, train_scores, test_scores = learning_curve(<br>        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)<br>    train_scores_mean = np.mean(train_scores, axis=<span class="hljs-number">1</span>)<br>    train_scores_std = np.std(train_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_mean = np.mean(test_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_std = np.std(test_scores, axis=<span class="hljs-number">1</span>)<br>    plt.grid() <span class="hljs-comment"># 在绘图中添加网格线</span><br><br>    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,<br>                     train_scores_mean + train_scores_std, alpha=<span class="hljs-number">0.1</span>,<br>                     color=<span class="hljs-string">&quot;r&quot;</span>)<br>    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,<br>                     test_scores_mean + test_scores_std, alpha=<span class="hljs-number">0.1</span>, color=<span class="hljs-string">&quot;g&quot;</span>)<br>    plt.plot(train_sizes, train_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;r&quot;</span>,<br>             label=<span class="hljs-string">&quot;Training score&quot;</span>)<br>    plt.plot(train_sizes, test_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;g&quot;</span>,<br>             label=<span class="hljs-string">&quot;Cross-validation score&quot;</span>)<br><br>    plt.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br>    <span class="hljs-keyword">return</span> plt <br></code></pre></td></tr></table></figure><h4 id="代码解释-3">代码解释</h4><p>定义 <code>plot_learning_curve</code> 的函数。该函数用于绘制学习曲线，评估模型在不同训练集大小下的性能表现。</p><p><strong>参数说明：</strong></p><ul><li><code>estimator</code>：要评估的分类器或回归器对象</li><li><code>title</code>：图形的标题</li><li><code>X</code>：特征矩阵</li><li><code>y</code>：目标变量</li><li><code>ylim</code>：y轴上的取值范围</li><li><code>cv</code>：交叉验证策略对象，默认为<code>None</code></li><li><code>n_jobs</code>：并行处理的工作进程数，默认为1</li><li><code>train_sizes</code>：可选的训练集大小，用于绘制学习曲线，默认为 <code>[0.1, 0.3, 0.5, 0.7, 0.9, 1.0]</code></li></ul><p><strong>函数内部的操作如下：</strong></p><ol type="1"><li>创建一个新的图形对象</li><li>设置图形的标题和轴标签</li><li>如果指定了 <code>ylim</code> 参数，则设置 y 轴上的取值范围</li><li>调用 <code>learning_curve</code> 方法计算训练集和测试集的得分 (<code>train_scores</code> 和 <code>test_scores</code>)，以及相应的均值 (<code>train_scores_mean</code> 和 <code>test_scores_mean</code>) 和标准差 (<code>train_scores_std</code> 和 <code>test_scores_std</code>)</li><li>绘制学习曲线图形：使用 <code>fill_between</code> 方法绘制训练集和测试集得分的区间范围，使用 <code>plot</code> 方法绘制训练集和测试集得分的均值</li><li>添加图例并显示网格线</li><li>返回图形对象</li></ol><p><strong>部分代码详解：</strong></p><ol type="1"><li><code>plt.ylim(*ylim)</code><ul><li><code>plt.ylim</code> 是 Matplotlib 库中的一个函数，用于设置 y 轴上的取值范围。该函数接受两个参数，表示 y 轴的下限和上限。在上述代码中，<code>plt.ylim(*ylim)</code> 表示将传入的 <code>ylim</code> 参数解包，并将解包后得到的两个值分别作为下限和上限传递给 <code>plt.ylim</code> 函数。</li><li><code>*ylim</code> 使用了 <code>*</code> 运算符，表示将 <code>ylim</code> 参数解包。当函数调用时，如果一个参数前面有 <code>*</code>，则表示将该参数解包为多个独立的值。在这里，<code>*ylim</code> 的作用是将 <code>ylim</code> 参数解包为两个值，以便传递给 <code>plt.ylim</code> 函数。解包后的第一个值将成为下限，第二个值将成为上限。</li></ul></li></ol><hr><ol start="2" type="1"><li><code>learning_curve</code> 函数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> learning_curve<br><br>train_sizes, train_scores, test_scores = learning_curve(<br>    estimator, X, y, train_sizes=<span class="hljs-literal">None</span>, cv=<span class="hljs-literal">None</span>, scoring=<span class="hljs-literal">None</span>, n_jobs=<span class="hljs-literal">None</span>, <br>    shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-literal">None</span>, verbose=<span class="hljs-number">0</span>, error_score=<span class="hljs-string">&#x27;raise&#x27;</span>, **kwargs)<br></code></pre></td></tr></table></figure><pre><code class="hljs">参数说明： </code></pre><ul><li><code>estimator</code>: 所使用的分类或回归算法。</li><li><code>X</code>: 特征矩阵。</li><li><code>y</code>: 目标变量。</li><li><code>train_sizes</code>: 是否自定义训练集大小，如果指定为 <code>None</code>，则默认生成 5 个等间隔的训练集大小，最小大小为 0.1，最大大小为 1，即 <code>train_sizes=np.linspace(0.1, 1.0, 5)</code>。</li><li><code>cv</code>: 交叉验证策略对象，默认为 None。可以使用整数、用于指定折叠数量的交叉验证生成器，或者用于划分数据集的可迭代对象。</li><li><code>scoring</code>: 模型性能评估指标，可以选择预定义的性能评估指标字符串，或者自定义的评估函数。</li><li><code>n_jobs</code>: 并行处理的工作进程数，默认为 None，表示使用单个进程（如果设为 -1，则使用所有可用的CPU）。</li><li><code>shuffle</code>: 每次交叉验证时，是否对训练数据顺序进行随机洗牌。</li><li><code>random_state</code>: 用于生成随机数的种子，设定后可以保证每次运行都能得到相同的结果。</li><li><code>verbose</code>: 控制输出信息的详细程度。</li><li><code>error_score</code>: 如果某个参数设置导致模型无法有效的训练，则会产生一个错误分数。</li></ul><pre><code class="hljs">函数返回三个数组：</code></pre><ul><li><code>train_sizes</code>: 训练集大小的数组。</li><li><code>train_scores</code>: 每组训练集大小下模型在训练集上的得分的数组。</li><li><code>test_scores</code>: 每组训练集大小下模型在测试集上的得分的数组。</li></ul><hr><ol start="3" type="1"><li><code>plt.fill_between()</code> 函数</li></ol><p>用于在两条曲线之间填充颜色或填充区域。它可以用于可视化误差范围、置信区间或数据集分布等情况。文中即在学习曲线图中填充了训练集得分均值的上下方差区域。具体来说，它将训练集得分均值减去标准差的结果和加上标准差的结果之间的区域进行填充，并指定了填充的颜色。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.fill_between(x, y1, y2=<span class="hljs-number">0</span>, where=<span class="hljs-literal">None</span>, interpolate=<span class="hljs-literal">False</span>, step=<span class="hljs-literal">None</span>, **kwargs)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>x</code>：表示 x 轴上的数据点。</li><li><code>y1</code>：表示第一条曲线的 y 值。</li><li><code>y2</code>：表示第二条曲线的 y 值，默认为 0。如果设置为数组，则必须和 <code>y1</code> 的长度相同，用于填充两条曲线之间的区域。</li><li><code>where</code>：一个条件数组或布尔表达式，指定应该填充区域的位置。默认为 None，表示在整个 x 范围内填充区域。</li><li><code>interpolate</code>：一个布尔值，指定是否对填充区域进行插值。默认为 False，表示不进行插值。</li><li><code>step</code>：一个字符串，指定填充区域的类型，可以是 "pre"、"post" 或者 "mid"。默认为 None，表示不进行任何变化。</li><li><code>**kwargs</code>：可选参数，用于指定填充区域的属性，例如填充颜色、透明度等。</li></ul><p>常用属性参数：</p><ul><li><code>color</code>：指定填充的颜色。</li><li><code>alpha</code>：指定填充颜色的透明度。</li><li><code>edgecolor</code>：指定边缘线的颜色。</li><li><code>linewidth</code>：指定边缘线的宽度。</li></ul><hr><ol start="4" type="1"><li><code>plt.plot()</code> 函数 用于绘制线图。可以用来可视化数据集、绘制函数曲线等。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.plot(x, y, fmt, **kwargs)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>x</code>：表示 x 轴上的数据点。</li><li><code>y</code>：表示 y 轴上的数据点。</li><li><code>fmt</code>：一个可选参数，用于指定线条的样式，包括颜色、线型和标记。例如，'b-' 表示蓝色实线；'g--' 表示绿色虚线；'ro' 表示红色圆点。参考下面的属性参数部分。</li><li><code>**kwargs</code>：可选参数，用于设置线条的其他属性，例如线宽、标签、透明度等。</li></ul><p>常用的属性参数：</p><ul><li><code>color</code>：指定线条的颜色，例如 'red'、'green'。</li><li><code>linestyle</code>：指定线条的样式，例如 '-'（实线）、'--'（虚线）。</li><li><code>marker</code>：指定标记类型，例如 'o'（圆点）、's'（方块）。</li><li><code>linewidth</code>：指定线条的宽度。</li><li><code>label</code>：指定线条的标签。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">digits = load_digits()<br>X, y = digits.data, digits.target<br><br><br>title = <span class="hljs-string">&quot;Learning Curves (Naive Bayes)&quot;</span><br><span class="hljs-comment"># Cross validation with 100 iterations to get smoother mean test and train</span><br><span class="hljs-comment"># score curves, each time with 20% data randomly selected as a validation set.</span><br>cv = ShuffleSplit(n_splits=<span class="hljs-number">100</span>, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)<br><br>estimator = GaussianNB()<br>plot_learning_curve(estimator, title, X, y, ylim=(<span class="hljs-number">0.7</span>, <span class="hljs-number">1.01</span>), cv=cv, n_jobs=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;module &#39;matplotlib.pyplot&#39; from &#39;D:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\pyplot.py&#39;&gt;</code></pre><p>​<br><img src="/img/工业蒸汽预测-05%201模型验证/output_39_1.png" srcset="/img/loading.gif" lazyload> ​</p><h4 id="代码解释-4">代码解释</h4><p><code>ShuffleSplit()</code> 用于生成随机划分的训练集和测试集。它在每次划分时都会对数据集进行洗牌（随机打乱），以确保训练集和测试集的划分是随机的。</p><p>两个主要作用：</p><ol type="1"><li>评估模型性能：通过多次随机划分数据集并在每个划分上训练和评估模型，可以得到模型在不同训练集和测试集上的性能指标，如准确率、回归的 R2 分数等。</li><li>参数调优：通过交叉验证评估模型的性能，可以帮助选择最优的模型参数。例如，在网格搜索调优中使用 <code>ShuffleSplit()</code> 可以评估不同参数组合下的模型性能。</li></ol><p>常用参数：</p><ul><li><code>n_splits</code>：指定将数据集划分为多少个不同的训练集和测试集的组合。</li><li><code>test_size</code>：指定测试集的大小。可以是一个整数（表示样本数量），也可以是一个浮点数（表示比例）。</li><li><code>train_size</code>：指定训练集的大小。可以是一个整数（表示样本数量），也可以是一个浮点数（表示比例）。与 <code>test_size</code> 二选一。</li><li><code>random_state</code>：指定随机种子。保持相同的 <code>random_state</code> 值会得到相同的随机结果。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">title = <span class="hljs-string">&quot;Learning Curves (SVM, RBF kernel, $\gamma=0.001$)&quot;</span><br><span class="hljs-comment"># SVC is more expensive so we do a lower number of CV iterations:</span><br>cv = ShuffleSplit(n_splits=<span class="hljs-number">10</span>, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)<br>estimator = SVC(gamma=<span class="hljs-number">0.001</span>)<br>plot_learning_curve(estimator, title, X, y, (<span class="hljs-number">0.7</span>, <span class="hljs-number">1.01</span>), cv=cv, n_jobs=<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;module &#39;matplotlib.pyplot&#39; from &#39;D:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\pyplot.py&#39;&gt;</code></pre><p>​<br><img src="/img/工业蒸汽预测-05%201模型验证/output_41_1.png" srcset="/img/loading.gif" lazyload> ​</p><h3 id="验证曲线">2.2.2 验证曲线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_digits<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn. model_selection <span class="hljs-keyword">import</span> validation_curve<br><br>digits = load_digits()<br>X, y = digits.data, digits.target<br><br>param_range = np.logspace(-<span class="hljs-number">6</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">5</span>)<br>train_scores, test_scores = validation_curve(<br>    SVC(), X, y, param_name=<span class="hljs-string">&quot;gamma&quot;</span>, param_range=param_range,<br>    cv=<span class="hljs-number">10</span>, scoring=<span class="hljs-string">&quot;accuracy&quot;</span>, n_jobs=<span class="hljs-number">1</span>)<br>train_scores_mean = np.mean(train_scores, axis=<span class="hljs-number">1</span>)<br>train_scores_std = np.std(train_scores, axis=<span class="hljs-number">1</span>)<br>test_scores_mean = np.mean(test_scores, axis=<span class="hljs-number">1</span>)<br>test_scores_std = np.std(test_scores, axis=<span class="hljs-number">1</span>)<br><br>plt.title(<span class="hljs-string">&quot;Validation Curve with SVM&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$\gamma$&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Score&quot;</span>)<br>plt.ylim(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.1</span>)<br>plt.semilogx(param_range, train_scores_mean, label=<span class="hljs-string">&quot;Training score&quot;</span>, color=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.fill_between(param_range, train_scores_mean - train_scores_std,<br>                 train_scores_mean + train_scores_std, alpha=<span class="hljs-number">0.2</span>, color=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.semilogx(param_range, test_scores_mean, label=<span class="hljs-string">&quot;Cross-validation score&quot;</span>,<br>             color=<span class="hljs-string">&quot;g&quot;</span>)<br>plt.fill_between(param_range, test_scores_mean - test_scores_std,<br>                 test_scores_mean + test_scores_std, alpha=<span class="hljs-number">0.2</span>, color=<span class="hljs-string">&quot;g&quot;</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>​<br><img src="/img/工业蒸汽预测-05%201模型验证/output_43_0.png" srcset="/img/loading.gif" lazyload> ​</p><h4 id="代码解释-5">代码解释</h4><ol type="1"><li><code>np.logspace()</code> 用于生成在对数刻度上均匀分布的数值序列。</li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">np.logspace(start, stop, <span class="hljs-attribute">num</span>=50, <span class="hljs-attribute">endpoint</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">base</span>=10.0, <span class="hljs-attribute">dtype</span>=None)<br></code></pre></td></tr></table></figure><p>参数解释：</p><ul><li><code>start</code>：起始值，表示数列的起点。</li><li><code>stop</code>：结束值，表示数列的终点。</li><li><code>num</code>：要生成的数的个数，默认为 50。</li><li><code>endpoint</code>：是否包含终点值，默认为 True。如果为 False，则生成的数列不包含结束值。</li><li><code>base</code>：对数的底数，默认为 10.0。</li><li><code>dtype</code>：返回值的数据类型。</li></ul><p><code>np.logspace()</code> 函数将起始值和结束值在对数刻度上等分为指定个数的数列，并返回该数列。</p><p><code>param_range = np.logspace(-6, -1, 5)</code> 生成一个从 10 的 -6 次方到 10 的 -1 次方之间的等比数列，共包含 5 个值。</p><hr><ol start="2" type="1"><li><code>validation_curve()</code>函数 用于绘制验证曲线（validation curve）。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">sklearn.model_selection.validation_curve(estimator, X, y, param_name, param_range, cv=<span class="hljs-literal">None</span>, scoring=<span class="hljs-literal">None</span>, n_jobs=<span class="hljs-literal">None</span>, pre_dispatch=<span class="hljs-string">&quot;all&quot;</span>, verbose=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>参数解释：</p><ul><li><code>estimator</code>：用于训练和预测的模型对象。</li><li><code>X</code>：特征数据。</li><li><code>y</code>：目标数据。</li><li><code>param_name</code>：要调整的控制模型行为的参数名称。</li><li><code>param_range</code>：参数的取值范围。</li><li><code>cv</code>：交叉验证的折数，默认为 None。如果为整数，则表示 K 折交叉验证；如果为交叉验证生成器对象，则可以更灵活地定义交叉验证策略。</li><li><code>scoring</code>：评估指标，默认为 None。如果为 None，则使用模型的默认评估指标；如果为字符串或可调用对象，则使用指定的评估指标。</li><li><code>n_jobs</code>：并行运行的作业数，默认为 None，表示使用单个进程运行。</li><li><code>pre_dispatch</code>：控制并行运行的内部作业数量，默认为 "all"，表示并行运行所有作业。</li><li><code>verbose</code>：详细程度，默认为 0，表示不输出执行信息；大于 0 的值表示输出一些执行信息。</li></ul><p><code>validation_curve()</code> 函数通过在给定参数的不同取值上计算训练得分和验证得分，绘制了模型复杂度（参数）与性能之间的关系曲线。它有助于判断模型在不同参数取值下的过/欠拟合情况，并选择最佳参数取值。</p><p>返回值：</p><ul><li>返回一个包含训练得分和验证得分的元组 <code>(train_scores, test_scores)</code>。每个得分都是一个二维数组，行数表示不同参数取值，列数表示交叉验证的次数。</li></ul><p>本示例中，我们使用 SVM 模型对 iris 数据集进行训练。<code>param_name="gamma"</code> 表示将调整 gamma 参数的值。<code>param_range</code> 定义了 gamma 参数的取值范围。</p><p><code>cv=5</code> 表示进行 5 折交叉验证。<code>scoring="accuracy"</code> 表示评估指标为准确率。</p><hr><ol start="3" type="1"><li><code>plt.semilogx()</code> 函数 在 x 轴为对数刻度的情况下，绘制曲线。</li></ol><p><code>plt.semilogx(param_range, train_scores_mean, label="Training score", color="r")</code> 中：</p><ul><li><code>param_range</code>：表示 x 轴上的数据点位置。</li><li><code>train_scores_mean</code>：表示 y 轴上的数据点位置。</li><li><code>label="Training score"</code>：指定图例中要显示的曲线名称为 "Training score"。</li><li><code>color="r"</code>：指定曲线的颜色为红色。</li></ul><hr><ol start="4" type="1"><li><code>plt.legend()</code> 函数 用于添加图例。</li></ol><p><code>plt.legend(loc="best")</code> 的作用是根据已经标识的线条对应的标签名称，自动在最佳位置添加图例。其中 <code>loc</code> 参数指定了图例的位置，"best" 表示自动选择最佳位置，也可以通过具体的坐标系位置或字符串表示来指定固定的位置。</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>工业蒸汽预测-05-1模型验证</div><div>http://zhou1317fe5.link/2023/09/01/工业蒸汽预测-05-1模型验证/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年9月1日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/09/02/C%E8%AF%AD%E8%A8%8002-%E5%88%86%E6%94%AF%E5%92%8C%E5%BE%AA%E7%8E%AF12/" title="C语言02-分支和循环12"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">C语言02-分支和循环12</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/08/30/C%E8%AF%AD%E8%A8%8001-C%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86123/" title="C语言01-C语言的基础知识123"><span class="hidden-mobile">C语言01-C语言的基础知识123</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>