<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhou1317fe5"><meta name="keywords" content=""><meta name="description" content="天猫重复购买预测特征工程代码详解"><meta property="og:type" content="article"><meta property="og:title" content="天猫重复购买预测-03特征工程"><meta property="og:url" content="http://zhou1317fe5.link/2024/02/15/%E5%A4%A9%E7%8C%AB%E9%87%8D%E5%A4%8D%E8%B4%AD%E4%B9%B0%E9%A2%84%E6%B5%8B-03%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/index.html"><meta property="og:site_name" content="Zhou1317fe5"><meta property="og:description" content="天猫重复购买预测特征工程代码详解"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2024-02-15T04:49:05.000Z"><meta property="article:modified_time" content="2024-02-15T04:54:05.788Z"><meta property="article:author" content="Zhou1317fe5"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>天猫重复购买预测-03特征工程 - Zhou1317fe5</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/iconfont_csdn/iconfont.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"zhou1317fe5.link",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Zhou1317fe5</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/Post_banner_img.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="天猫重复购买预测-03特征工程"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-02-15 12:49" pubdate>2024年2月15日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 44k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 365 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">天猫重复购买预测-03特征工程</h1><div class="markdown-body"><h2 id="工具导入">1 工具导入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><br><span class="hljs-keyword">import</span> gc<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">import</span> copy<br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br> <br>%matplotlib inline<br></code></pre></td></tr></table></figure><h2 id="数据读取">2 数据读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#读取数据集</span><br>test_data = pd.read_csv(<span class="hljs-string">&#x27;./data/data_format1/test_format1.csv&#x27;</span>)<br>train_data = pd.read_csv(<span class="hljs-string">&#x27;./data/data_format1/train_format1.csv&#x27;</span>)<br>user_info = pd.read_csv(<span class="hljs-string">&#x27;./data/data_format1/user_info_format1.csv&#x27;</span>)<br>user_log = pd.read_csv(<span class="hljs-string">&#x27;./data/data_format1/user_log_format1.csv&#x27;</span>)<br></code></pre></td></tr></table></figure><p><strong>数据资源查看</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 260864 entries, 0 to 260863
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype
---  ------       --------------   -----
 0   user_id      260864 non-null  int64
 1   merchant_id  260864 non-null  int64
 2   label        260864 non-null  int64
dtypes: int64(3)
memory usage: 6.0 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 261477 entries, 0 to 261476
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype  
---  ------       --------------   -----  
 0   user_id      261477 non-null  int64  
 1   merchant_id  261477 non-null  int64  
 2   prob         0 non-null       float64
dtypes: float64(1), int64(2)
memory usage: 6.0 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">user_info.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 424170 entries, 0 to 424169
Data columns (total 3 columns):
 #   Column     Non-Null Count   Dtype  
---  ------     --------------   -----  
 0   user_id    424170 non-null  int64  
 1   age_range  421953 non-null  float64
 2   gender     417734 non-null  float64
dtypes: float64(2), int64(1)
memory usage: 9.7 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">user_log.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 54925330 entries, 0 to 54925329
Data columns (total 7 columns):
 #   Column       Dtype  
---  ------       -----  
 0   user_id      int64  
 1   item_id      int64  
 2   cat_id       int64  
 3   seller_id    int64  
 4   brand_id     float64
 5   time_stamp   int64  
 6   action_type  int64  
dtypes: float64(1), int64(6)
memory usage: 2.9 GB</code></pre><p>数据资源非常大，甚至达到2.9GB，需要进行数据压缩</p><h2 id="对数据进行内存压缩">3 对数据进行内存压缩</h2><h3 id="定义内存压缩方法">（1）定义内存压缩方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># reduce memory</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reduce_mem_usage</span>(<span class="hljs-params">df, verbose=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-comment"># 开始时的内存使用</span><br>    start_mem = df.memory_usage().<span class="hljs-built_in">sum</span>() / <span class="hljs-number">1024</span>**<span class="hljs-number">2</span><br>    numerics = [<span class="hljs-string">&#x27;int16&#x27;</span>, <span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-string">&#x27;int64&#x27;</span>, <span class="hljs-string">&#x27;float16&#x27;</span>, <span class="hljs-string">&#x27;float32&#x27;</span>, <span class="hljs-string">&#x27;float64&#x27;</span>]<br>    <br>    <span class="hljs-comment"># 遍历每一列</span><br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df.columns:<br>        <span class="hljs-comment"># 获取列的数据类型</span><br>        col_type = df[col].dtypes<br>        <span class="hljs-comment"># 如果列的数据类型在数值类型中</span><br>        <span class="hljs-keyword">if</span> col_type <span class="hljs-keyword">in</span> numerics:<br>            <span class="hljs-comment"># 获取列的最小值和最大值</span><br>            c_min = df[col].<span class="hljs-built_in">min</span>()<br>            c_max = df[col].<span class="hljs-built_in">max</span>()<br>            <span class="hljs-comment"># 如果数据类型为int</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(col_type)[:<span class="hljs-number">3</span>] == <span class="hljs-string">&#x27;int&#x27;</span>:<br>                <span class="hljs-comment"># 如果最小值大于int8的最小值，最大值小于int8的最大值</span><br>                <span class="hljs-keyword">if</span> c_min &gt; np.iinfo(np.int8).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.iinfo(np.int8).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为int8</span><br>                    df[col] = df[col].astype(np.int8)<br>                <span class="hljs-comment"># 如果最小值大于int16的最小值，最大值小于int16的最大值</span><br>                <span class="hljs-keyword">elif</span> c_min &gt; np.iinfo(np.int16).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.iinfo(np.int16).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为int16</span><br>                    df[col] = df[col].astype(np.int16)<br>                <span class="hljs-comment"># 如果最小值大于int32的最小值，最大值小于int32的最大值</span><br>                <span class="hljs-keyword">elif</span> c_min &gt; np.iinfo(np.int32).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.iinfo(np.int32).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为int32</span><br>                    df[col] = df[col].astype(np.int32)<br>                <span class="hljs-comment"># 如果最小值大于int64的最小值，最大值小于int64的最大值</span><br>                <span class="hljs-keyword">elif</span> c_min &gt; np.iinfo(np.int64).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.iinfo(np.int64).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为int64</span><br>                    df[col] = df[col].astype(np.int64)<br>            <span class="hljs-comment"># 如果数据类型为float</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># 如果最小值大于float16的最小值，最大值小于float16的最大值</span><br>                <span class="hljs-keyword">if</span> c_min &gt; np.finfo(np.float16).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.finfo(np.float16).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为float16</span><br>                    df[col] = df[col].astype(np.float16)<br>                <span class="hljs-comment"># 如果最小值大于float32的最小值，最大值小于float32的最大值</span><br>                <span class="hljs-keyword">elif</span> c_min &gt; np.finfo(np.float32).<span class="hljs-built_in">min</span> <span class="hljs-keyword">and</span> c_max &lt; np.finfo(np.float32).<span class="hljs-built_in">max</span>:<br>                    <span class="hljs-comment"># 将列的数据类型转换为float32</span><br>                    df[col] = df[col].astype(np.float32)<br>                <span class="hljs-comment"># 如果最小值大于float64的最小值，最大值小于float64的最大值</span><br>                <span class="hljs-keyword">else</span>:<br>                    df[col] = df[col].astype(np.float64)<br>                    <br>    <span class="hljs-comment"># 结束时的内存使用</span><br>    end_mem = df.memory_usage().<span class="hljs-built_in">sum</span>() / <span class="hljs-number">1024</span>**<span class="hljs-number">2</span><br>    <span class="hljs-comment"># 打印优化后的内存使用</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Memory usage after optimization is: &#123;:.2f&#125; MB&#x27;</span>.<span class="hljs-built_in">format</span>(end_mem))<br>    <span class="hljs-comment"># 打印优化率</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Decreased by &#123;:.1f&#125;%&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-number">100</span> * (start_mem - end_mem) / start_mem))<br>    <span class="hljs-comment"># 返回优化后的DataFrame</span><br>    <span class="hljs-keyword">return</span> df<br></code></pre></td></tr></table></figure><h4 id="代码解释">代码解释</h4><p>用于优化数据帧（dataframe）的内存使用，主要目的是将数据帧中的整数和浮点数类型转换为更小的数据类型，从而减少内存占用。</p><p>以下是代码的详细解释：</p><ol type="1"><li><p>定义一个名为<code>reduce_mem_usage</code>的函数，接受一个数据帧<code>df</code>和一个布尔值<code>verbose</code>作为参数。</p></li><li><p>计算原始数据帧的内存使用情况，并将结果除以1024^2以转换为MB。</p></li><li><p>定义一个包含整数和浮点数类型的列表<code>numerics</code>。</p></li><li><p>遍历数据帧的列（<code>for col in df.columns:</code>）。</p></li><li><p>获取当前列的数据类型（<code>col_type = df[col].dtypes</code>）。</p></li><li><p>如果当前列的数据类型在<code>numerics</code>列表中（<code>if col_type in numerics:</code>），则进行以下操作：</p><ol type="a"><li><p>计算当前列的最小值和最大值（<code>c_min = df[col].min()</code>和<code>c_max = df[col].max()</code>）。</p></li><li><p>如果当前列的数据类型是整数类型（<code>if str(col_type)[:3] == 'int'</code>），则检查当前列的最小值和最大值是否在整数类型的范围中。如果是，则将当前列转换为更小的整数类型（<code>int8</code>、<code>int16</code>、<code>int32</code>或<code>int64</code>）。</p></li><li><p>如果当前列的数据类型是浮点数类型，则检查当前列的最小值和最大值是否在浮点数类型的范围中。如果是，则将当前列转换为更小的浮点数类型（<code>float16</code>、<code>float32</code>或<code>64</code>）。</p></li></ol></li><li><p>计算优化后的数据帧的内存使用情况，并将结果除以1024^2以转换为MB。</p></li><li><p>打印优化后的数据帧的内存使用情况，以及与原始数据帧的内存使用情况的百分比差异。</p></li><li><p>返回优化后的数据帧。</p></li></ol><h3 id="对数据进行内存压缩-1">（2）对数据进行内存压缩</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据读取函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_csv</span>(<span class="hljs-params">file_name, num_rows</span>):<br>    <span class="hljs-keyword">return</span> pd.read_csv(file_name, nrows=num_rows)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">num_rows = <span class="hljs-literal">None</span><br>num_rows = <span class="hljs-number">200</span> * <span class="hljs-number">10000</span> <br><br>train_file = <span class="hljs-string">&#x27;./data/data_format1/train_format1.csv&#x27;</span><br>test_file = <span class="hljs-string">&#x27;./data/data_format1/test_format1.csv&#x27;</span><br><br>user_info_file = <span class="hljs-string">&#x27;./data/data_format1/user_info_format1.csv&#x27;</span><br>user_log_file = <span class="hljs-string">&#x27;./data/data_format1/user_log_format1.csv&#x27;</span><br><br>train_data = reduce_mem_usage(read_csv(train_file, num_rows))<br>test_data = reduce_mem_usage(read_csv(test_file, num_rows))<br><br>user_info = reduce_mem_usage(read_csv(user_info_file, num_rows))<br>user_log = reduce_mem_usage(read_csv(user_log_file, num_rows))<br></code></pre></td></tr></table></figure><pre><code class="hljs">Memory usage after optimization is: 1.74 MB
Decreased by 70.8%
Memory usage after optimization is: 3.49 MB
Decreased by 41.7%
Memory usage after optimization is: 3.24 MB
Decreased by 66.7%
Memory usage after optimization is: 32.43 MB
Decreased by 69.6%</code></pre><h3 id="查看压缩后的数据信息">（3）查看压缩后的数据信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 260864 entries, 0 to 260863
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype
---  ------       --------------   -----
 0   user_id      260864 non-null  int32
 1   merchant_id  260864 non-null  int16
 2   label        260864 non-null  int8 
dtypes: int16(1), int32(1), int8(1)
memory usage: 1.7 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_data.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 261477 entries, 0 to 261476
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype  
---  ------       --------------   -----  
 0   user_id      261477 non-null  int32  
 1   merchant_id  261477 non-null  int16  
 2   prob         0 non-null       float64
dtypes: float64(1), int16(1), int32(1)
memory usage: 3.5 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">user_info.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 424170 entries, 0 to 424169
Data columns (total 3 columns):
 #   Column     Non-Null Count   Dtype  
---  ------     --------------   -----  
 0   user_id    424170 non-null  int32  
 1   age_range  421953 non-null  float16
 2   gender     417734 non-null  float16
dtypes: float16(2), int32(1)
memory usage: 3.2 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">user_log.info()<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 2000000 entries, 0 to 1999999
Data columns (total 7 columns):
 #   Column       Dtype  
---  ------       -----  
 0   user_id      int32  
 1   item_id      int32  
 2   cat_id       int16  
 3   seller_id    int16  
 4   brand_id     float16
 5   time_stamp   int16  
 6   action_type  int8   
dtypes: float16(1), int16(3), int32(2), int8(1)
memory usage: 32.4 MB</code></pre><h2 id="数据处理">4 数据处理</h2><h3 id="合并用户信息">4.1 合并用户信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 合并训练集、测试集、用户信息表</span><br><span class="hljs-keyword">del</span> test_data[<span class="hljs-string">&#x27;prob&#x27;</span>]<br>all_data = train_data.append(test_data)<br>all_data = all_data.merge(user_info,on=[<span class="hljs-string">&#x27;user_id&#x27;</span>],how=<span class="hljs-string">&#x27;left&#x27;</span>)<br><span class="hljs-keyword">del</span> train_data, test_data, user_info<br>gc.collect()<br></code></pre></td></tr></table></figure><pre><code class="hljs">159</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>merchant_id</th><th>label</th><th>age_range</th><th>gender</th></tr></thead><tbody><tr><th>0</th><td>34176</td><td>3906</td><td>0.0</td><td>6.0</td><td>0.0</td></tr><tr><th>1</th><td>34176</td><td>121</td><td>0.0</td><td>6.0</td><td>0.0</td></tr><tr><th>2</th><td>34176</td><td>4356</td><td>1.0</td><td>6.0</td><td>0.0</td></tr><tr><th>3</th><td>34176</td><td>2217</td><td>0.0</td><td>6.0</td><td>0.0</td></tr><tr><th>4</th><td>230784</td><td>4818</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div><h4 id="代码解释-1">代码解释</h4><p>这段代码的主要目的是合并训练集、测试集和用户信息表，并将它们合并为一个新的数据集all_data。</p><ol type="1"><li>首先，代码删除了测试集中名为'prob'的列，因为它在训练集中不存在。</li><li>然后，将训练集和测试集合并为一个新的数据集all_data。这里使用了<code>append()</code>方法将测试集添加到训练集的末尾。。</li><li>接着，使用<code>merge()</code>方法将用户信息表和合并后的数据集all_data合并，使用'on'参数指定连接的列，使用'how'参数指定连接方式为左连接（即保留左表中的所有行，即使右表中没有匹配的行）。</li><li>最后，删除了训练集、测试集和用户信息表，使用<code>del</code>关键字。同时，调用<code>gc.collect()</code>函数释放内存。</li></ol><ul><li><p><code>del</code>关键字用于删除变量或对象。当在Python中使用<code>del</code>关键字时，它会从内存中删除变量或对象的引用，从而释放该对象所占用的内存空间。</p></li><li><p><code>gc.collect()</code>函数是Python的垃圾回收器（Garbage Collector）的接口，用于手动触发垃圾回收操作。在某些情况下，Python可能会无法及时回收垃圾，这时可以使用<code>gc.collect()</code>函数手动触发垃圾回收，以释放被占用的内存空间。</p></li></ul><h3 id="用户行为日志信息按时间进行排序">4.2 用户行为日志信息按时间进行排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">按时间排序</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>user_log = user_log.sort_values([<span class="hljs-string">&#x27;user_id&#x27;</span>,<span class="hljs-string">&#x27;time_stamp&#x27;</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">user_log.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>item_id</th><th>cat_id</th><th>seller_id</th><th>brand_id</th><th>time_stamp</th><th>action_type</th></tr></thead><tbody><tr><th>61975</th><td>16</td><td>980982</td><td>437</td><td>650</td><td>4276.0</td><td>914</td><td>0</td></tr><tr><th>61976</th><td>16</td><td>980982</td><td>437</td><td>650</td><td>4276.0</td><td>914</td><td>0</td></tr><tr><th>61977</th><td>16</td><td>980982</td><td>437</td><td>650</td><td>4276.0</td><td>914</td><td>0</td></tr><tr><th>61978</th><td>16</td><td>962763</td><td>19</td><td>650</td><td>4276.0</td><td>914</td><td>0</td></tr><tr><th>61979</th><td>16</td><td>391126</td><td>437</td><td>650</td><td>4276.0</td><td>914</td><td>0</td></tr></tbody></table></div><h4 id="代码解释-2">代码解释</h4><p>对user_id列和time_stamp列进行排序的具体步骤如下：</p><ol type="1"><li>首先，使用<code>sort_values()</code>方法对user_id列进行升序排序。升序排序意味着从小到大排列，即按user_id的顺序排列。</li><li>然后，使用<code>sort_values()</code>方法对time_stamp列进行升序排序。升序排序意味着从小到大排列，即按时间戳的顺序排列。</li></ol><p>因此，经过这两步排序后，user_log数据框中的数据将按照用户ID和时间戳的顺序进行排列。</p><h3 id="对每个用户逐个合并所有的字段">4.3 对每个用户逐个合并所有的字段</h3><p>合并字段为item_id, cat_id,seller_id,brand_id,time_stamp, action_type</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">合并数据</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>list_join_func = <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot; &quot;</span>.join([<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x])<br><br><br>agg_dict = &#123;<br>            <span class="hljs-string">&#x27;item_id&#x27;</span> : list_join_func,	<br>            <span class="hljs-string">&#x27;cat_id&#x27;</span> : list_join_func,<br>            <span class="hljs-string">&#x27;seller_id&#x27;</span> : list_join_func,<br>            <span class="hljs-string">&#x27;brand_id&#x27;</span> : list_join_func,<br>            <span class="hljs-string">&#x27;time_stamp&#x27;</span> : list_join_func,<br>            <span class="hljs-string">&#x27;action_type&#x27;</span> : list_join_func<br>        &#125;<br><br>rename_dict = &#123;<br>            <span class="hljs-string">&#x27;item_id&#x27;</span> : <span class="hljs-string">&#x27;item_path&#x27;</span>,<br>            <span class="hljs-string">&#x27;cat_id&#x27;</span> : <span class="hljs-string">&#x27;cat_path&#x27;</span>,<br>            <span class="hljs-string">&#x27;seller_id&#x27;</span> : <span class="hljs-string">&#x27;seller_path&#x27;</span>,<br>            <span class="hljs-string">&#x27;brand_id&#x27;</span> : <span class="hljs-string">&#x27;brand_path&#x27;</span>,<br>            <span class="hljs-string">&#x27;time_stamp&#x27;</span> : <span class="hljs-string">&#x27;time_stamp_path&#x27;</span>,<br>            <span class="hljs-string">&#x27;action_type&#x27;</span> : <span class="hljs-string">&#x27;action_type_path&#x27;</span><br>        &#125;<br><br><span class="hljs-comment"># def merge_list(df_ID, join_columns, df_data, agg_dict, rename_dict):</span><br><span class="hljs-comment">#     # 对df_data按照join_columns进行分组，并使用agg_dict进行聚合操作，然后重命名列</span><br><span class="hljs-comment">#     df_data = df_data.\</span><br><span class="hljs-comment">#                 groupby(join_columns).\</span><br><span class="hljs-comment">#                 agg(agg_dict).\</span><br><span class="hljs-comment">#                 reset_index().\</span><br><span class="hljs-comment">#                 rename(columns=rename_dict)</span><br>    <br><span class="hljs-comment">#     # 将df_ID和df_data按照join_columns进行左连接</span><br><span class="hljs-comment">#     df_ID = df_ID.merge(df_data, on=join_columns, how=&quot;left&quot;) </span><br><span class="hljs-comment">#     return df_data,df_ID</span><br><span class="hljs-comment"># all_data = merge_list(all_data, &#x27;user_id&#x27;, user_log, agg_dict, rename_dict)</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#all_data</span><br></code></pre></td></tr></table></figure><h4 id="代码解释-3">代码解释</h4><p>这段代码的主要目的是合并数据，将多个列组合成一个字符串，并将结果合并到现有的数据框中。实现原理如下：</p><ol type="1"><li><p>使用lambda函数定义一个名为<code>list_join_func</code>的函数，该函数接受一个列表参数，并将列表中的元素以空格分隔拼接成一个字符串。</p></li><li><p>定义一个名为<code>agg_dict</code>的字典，该字典包含要进行聚合操作的列及其对应的聚合函数。例如，<code>'item_id' : list_join_func</code>表示要将<code>item_id</code>列的值拼接成一个字符串。</p></li><li><p>定义一个名为<code>rename_dict</code>的字典，该字典包含要重命名的列。例如，<code>'item_id' : 'item_path'</code>表示要将<code>item_id</code>列重命名为<code>item_path</code>。</p></li><li><p>定义一个名为<code>merge_list</code>的函数，该函数接受四个参数：<code>df_ID</code>、<code>join_columns</code>、<code>df_data</code>和<code>agg_dict</code>。函数首先对<code>df_data</code>按照<code>join_columns</code>进行分组，并使用<code>agg_dict</code>进行聚合操作。然后，将结果重命名列，并返回重命名后的数据框。</p></li><li><p>在主程序中，首先对<code>all_data</code>和<code>user_log</code>按照<code>user_id</code>进行左连接。然后，将合并后的数据帧传递给<code>merge_list</code>函数，并将结果更新到<code>all_data</code>。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">user_log_path = user_log.groupby(<span class="hljs-string">&#x27;user_id&#x27;</span>).agg(agg_dict).reset_index().rename(columns=rename_dict)<br>user_log_path.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>item_path</th><th>cat_path</th><th>seller_path</th><th>brand_path</th><th>time_stamp_path</th><th>action_type_path</th></tr></thead><tbody><tr><th>0</th><td>16</td><td>980982 980982 980982 962763 391126 827174 6731...</td><td>437 437 437 19 437 437 437 437 895 19 437 437 ...</td><td>650 650 650 650 650 650 650 650 3948 650 650 6...</td><td>4276.0 4276.0 4276.0 4276.0 4276.0 4276.0 4276...</td><td>914 914 914 914 914 914 914 914 914 914 914 91...</td><td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 ...</td></tr><tr><th>1</th><td>19</td><td>388018 388018 88673 88673 88673 88673 846066 5...</td><td>949 949 614 614 614 614 420 1401 948 948 513 1...</td><td>2772 2772 4066 4066 4066 4066 4951 4951 2872 2...</td><td>2112.0 2112.0 1552.0 1552.0 1552.0 1552.0 5200...</td><td>710 710 711 711 711 711 908 908 1105 1105 1105...</td><td>0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td></tr><tr><th>2</th><td>41</td><td>60215 1004605 60215 60215 60215 60215 628525 5...</td><td>1308 1308 1308 1308 1308 1308 1271 656 656 656...</td><td>2128 3207 2128 2128 2128 2128 3142 4618 4618 4...</td><td>3848.0 3848.0 3848.0 3848.0 3848.0 3848.0 1014...</td><td>521 521 521 521 521 522 529 828 828 828 828 82...</td><td>0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 ...</td></tr><tr><th>3</th><td>56</td><td>889499 528459 765746 553259 889499 22435 40047...</td><td>662 1075 662 1577 662 11 184 1604 11 11 177 11...</td><td>4048 601 3104 3828 4048 4766 2419 2768 2565 26...</td><td>5360.0 1040.0 8240.0 1446.0 5360.0 4360.0 3428...</td><td>517 520 525 528 602 602 610 610 610 610 610 61...</td><td>3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 ...</td></tr><tr><th>4</th><td>155</td><td>979639 890128 981780 211366 211366 797946 4567...</td><td>267 1271 1505 267 267 1075 1075 407 407 1075 4...</td><td>2429 4785 3784 800 800 1595 1418 2662 2662 315...</td><td>2276.0 1422.0 5692.0 6328.0 6328.0 5800.0 7140...</td><td>529 529 602 604 604 607 607 607 607 607 607 60...</td><td>0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 2 ...</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data_path = all_data.merge(user_log_path,on=<span class="hljs-string">&#x27;user_id&#x27;</span>)<br>all_data_path.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>merchant_id</th><th>label</th><th>age_range</th><th>gender</th><th>item_path</th><th>cat_path</th><th>seller_path</th><th>brand_path</th><th>time_stamp_path</th><th>action_type_path</th></tr></thead><tbody><tr><th>0</th><td>105600</td><td>1487</td><td>0.0</td><td>6.0</td><td>1.0</td><td>986160 681407 681407 910680 681407 592698 3693...</td><td>35 1554 1554 119 1554 662 1095 662 35 833 833 ...</td><td>4811 4811 4811 1897 4811 3315 2925 1340 1875 4...</td><td>127.0 127.0 127.0 4704.0 127.0 1605.0 6000.0 1...</td><td>518 518 518 520 520 524 524 524 525 525 525 52...</td><td>2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td></tr><tr><th>1</th><td>110976</td><td>159</td><td>0.0</td><td>5.0</td><td>0.0</td><td>396970 961553 627712 926681 1012423 825576 149...</td><td>1023 420 407 1505 962 602 184 1606 351 1505 11...</td><td>1435 1648 223 3178 2418 1614 3004 2511 2285 78...</td><td>5504.0 7780.0 1751.0 7540.0 6652.0 8116.0 5328...</td><td>517 520 522 522 527 530 530 530 601 601 602 60...</td><td>2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 ...</td></tr><tr><th>2</th><td>374400</td><td>302</td><td>0.0</td><td>5.0</td><td>1.0</td><td>256546 202393 927572 2587 10956 549283 270303 ...</td><td>1188 646 1175 1188 1414 681 1175 681 681 115 1...</td><td>805 390 4252 3979 1228 2029 2029 2029 4252 923...</td><td>1842.0 5920.0 133.0 6304.0 7584.0 133.0 133.0 ...</td><td>517 604 604 604 607 609 609 609 609 615 621 62...</td><td>2 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td></tr><tr><th>3</th><td>189312</td><td>1760</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td></tr><tr><th>4</th><td>189312</td><td>2511</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td></tr></tbody></table></div><h3 id="删除数据并回收内存">4.4 删除数据并回收内存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">删除不需要的数据</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">del</span> user_log<br>gc.collect()<br></code></pre></td></tr></table></figure><pre><code class="hljs">42</code></pre><h2 id="定义数据统计函数">5 定义数据统计函数</h2><h3 id="定义统计函数">5.1 定义统计函数</h3><p><strong>(1)定义统计数据总数的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cnt_</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(x.split(<span class="hljs-string">&#x27; &#x27;</span>))<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>(2)定义统计数据唯一值总数的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nunique_</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(x.split(<span class="hljs-string">&#x27; &#x27;</span>)))<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>(3)定义统计数据最大值的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">max</span>([<span class="hljs-built_in">int</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>)])<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p><strong>(4)定义统计数据最小值的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">min_</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">min</span>([<span class="hljs-built_in">int</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>)])<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>  <br></code></pre></td></tr></table></figure><p><strong>(5)定义统计数据标准差的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">std_</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> np.std([<span class="hljs-built_in">float</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>)])<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> <br></code></pre></td></tr></table></figure><p><strong>(6)定义统计数据中topN数据的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">most_n</span>(<span class="hljs-params">x, n</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> Counter(x.split(<span class="hljs-string">&#x27; &#x27;</span>)).most_common(n)[n-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>(7)定义统计数据中topN数据总数的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">most_n_cnt</span>(<span class="hljs-params">x, n</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> Counter(x.split(<span class="hljs-string">&#x27; &#x27;</span>)).most_common(n)[n-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>   <br></code></pre></td></tr></table></figure><h3 id="调用定义的统计函数">5.2 调用定义的统计函数</h3><p>调用数据集的特征统计函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_cnt</span>(<span class="hljs-params">df_data, single_col, name</span>):<br>    df_data[name] = df_data[single_col].apply(cnt_)<br>    <span class="hljs-keyword">return</span> df_data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_nunique</span>(<span class="hljs-params">df_data, single_col, name</span>):<br>    df_data[name] = df_data[single_col].apply(nunique_)<br>    <span class="hljs-keyword">return</span> df_data<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_max</span>(<span class="hljs-params">df_data, single_col, name</span>):<br>    df_data[name] = df_data[single_col].apply(max_)<br>    <span class="hljs-keyword">return</span> df_data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_min</span>(<span class="hljs-params">df_data, single_col, name</span>):<br>    df_data[name] = df_data[single_col].apply(min_)<br>    <span class="hljs-keyword">return</span> df_data<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_std</span>(<span class="hljs-params">df_data, single_col, name</span>):<br>    df_data[name] = df_data[single_col].apply(std_)<br>    <span class="hljs-keyword">return</span> df_data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_most_n</span>(<span class="hljs-params">df_data, single_col, name, n=<span class="hljs-number">1</span></span>):<br>    func = <span class="hljs-keyword">lambda</span> x: most_n(x, n)<br>    df_data[name] = df_data[single_col].apply(func)<br>    <span class="hljs-keyword">return</span> df_data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_most_n_cnt</span>(<span class="hljs-params">df_data, single_col, name, n=<span class="hljs-number">1</span></span>):<br>    func = <span class="hljs-keyword">lambda</span> x: most_n_cnt(x, n)<br>    df_data[name] = df_data[single_col].apply(func)<br>    <span class="hljs-keyword">return</span> df_data<br><br></code></pre></td></tr></table></figure><h2 id="提取统计特征">6 提取统计特征</h2><h3 id="特征统计">6.1 特征统计</h3><h4 id="店铺特征统计">(1)店铺特征统计</h4><p>统计与店铺特点有关的特征，如店铺、商品、品牌等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    提取基本统计特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-comment">#all_data_test = all_data</span><br>all_data_test = all_data_path<br><span class="hljs-comment"># 统计用户 点击、浏览、加购、购买行为</span><br><span class="hljs-comment"># 总次数</span><br>all_data_test = user_cnt(all_data_test,  <span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;user_cnt&#x27;</span>)<br><span class="hljs-comment"># 不同店铺个数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;seller_nunique&#x27;</span>)<br><span class="hljs-comment"># 不同品类个数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;cat_path&#x27;</span>, <span class="hljs-string">&#x27;cat_nunique&#x27;</span>)<br><span class="hljs-comment"># 不同品牌个数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;brand_path&#x27;</span>, <span class="hljs-string">&#x27;brand_nunique&#x27;</span>)<br><span class="hljs-comment"># 不同商品个数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;item_path&#x27;</span>, <span class="hljs-string">&#x27;item_nunique&#x27;</span>)<br><span class="hljs-comment"># 活跃天数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;time_stamp_path&#x27;</span>, <span class="hljs-string">&#x27;time_stamp_nunique&#x27;</span>)<br><span class="hljs-comment"># 不用行为种数</span><br>all_data_test = user_nunique(all_data_test,  <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;action_type_nunique&#x27;</span>)<br><span class="hljs-comment"># ....</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data_test.head()<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>merchant_id</th><th>label</th><th>age_range</th><th>gender</th><th>item_path</th><th>cat_path</th><th>seller_path</th><th>brand_path</th><th>time_stamp_path</th><th>action_type_path</th><th>user_cnt</th><th>seller_nunique</th><th>cat_nunique</th><th>brand_nunique</th><th>item_nunique</th><th>time_stamp_nunique</th><th>action_type_nunique</th></tr></thead><tbody><tr><th>0</th><td>105600</td><td>1487</td><td>0.0</td><td>6.0</td><td>1.0</td><td>986160 681407 681407 910680 681407 592698 3693...</td><td>35 1554 1554 119 1554 662 1095 662 35 833 833 ...</td><td>4811 4811 4811 1897 4811 3315 2925 1340 1875 4...</td><td>127.0 127.0 127.0 4704.0 127.0 1605.0 6000.0 1...</td><td>518 518 518 520 520 524 524 524 525 525 525 52...</td><td>2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td><td>310</td><td>96</td><td>37</td><td>88</td><td>217</td><td>29</td><td>2</td></tr><tr><th>1</th><td>110976</td><td>159</td><td>0.0</td><td>5.0</td><td>0.0</td><td>396970 961553 627712 926681 1012423 825576 149...</td><td>1023 420 407 1505 962 602 184 1606 351 1505 11...</td><td>1435 1648 223 3178 2418 1614 3004 2511 2285 78...</td><td>5504.0 7780.0 1751.0 7540.0 6652.0 8116.0 5328...</td><td>517 520 522 522 527 530 530 530 601 601 602 60...</td><td>2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 ...</td><td>274</td><td>181</td><td>70</td><td>159</td><td>233</td><td>52</td><td>3</td></tr><tr><th>2</th><td>374400</td><td>302</td><td>0.0</td><td>5.0</td><td>1.0</td><td>256546 202393 927572 2587 10956 549283 270303 ...</td><td>1188 646 1175 1188 1414 681 1175 681 681 115 1...</td><td>805 390 4252 3979 1228 2029 2029 2029 4252 923...</td><td>1842.0 5920.0 133.0 6304.0 7584.0 133.0 133.0 ...</td><td>517 604 604 604 607 609 609 609 609 615 621 62...</td><td>2 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td><td>278</td><td>57</td><td>59</td><td>62</td><td>148</td><td>35</td><td>3</td></tr><tr><th>3</th><td>189312</td><td>1760</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td><td>237</td><td>49</td><td>35</td><td>45</td><td>170</td><td>9</td><td>2</td></tr><tr><th>4</th><td>189312</td><td>2511</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td><td>237</td><td>49</td><td>35</td><td>45</td><td>170</td><td>9</td><td>2</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 最晚时间</span><br>all_data_test = user_max(all_data_test,  <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;time_stamp_max&#x27;</span>)<br><span class="hljs-comment"># 最早时间</span><br>all_data_test = user_min(all_data_test,  <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;time_stamp_min&#x27;</span>)<br><span class="hljs-comment"># 活跃天数方差</span><br>all_data_test = user_std(all_data_test,  <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;time_stamp_std&#x27;</span>)<br><span class="hljs-comment"># 最早和最晚相差天数</span><br>all_data_test[<span class="hljs-string">&#x27;time_stamp_range&#x27;</span>] = all_data_test[<span class="hljs-string">&#x27;time_stamp_max&#x27;</span>] - all_data_test[<span class="hljs-string">&#x27;time_stamp_min&#x27;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用户最喜欢的店铺</span><br>all_data_test = user_most_n(all_data_test, <span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;seller_most_1&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最喜欢的类目</span><br>all_data_test = user_most_n(all_data_test, <span class="hljs-string">&#x27;cat_path&#x27;</span>, <span class="hljs-string">&#x27;cat_most_1&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最喜欢的品牌</span><br>all_data_test = user_most_n(all_data_test, <span class="hljs-string">&#x27;brand_path&#x27;</span>, <span class="hljs-string">&#x27;brand_most_1&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最常见的行为动作</span><br>all_data_test = user_most_n(all_data_test, <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;action_type_1&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># .....</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用户最喜欢的店铺 行为次数</span><br>all_data_test = user_most_n_cnt(all_data_test, <span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;seller_most_1_cnt&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最喜欢的类目 行为次数</span><br>all_data_test = user_most_n_cnt(all_data_test, <span class="hljs-string">&#x27;cat_path&#x27;</span>, <span class="hljs-string">&#x27;cat_most_1_cnt&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最喜欢的品牌 行为次数</span><br>all_data_test = user_most_n_cnt(all_data_test, <span class="hljs-string">&#x27;brand_path&#x27;</span>, <span class="hljs-string">&#x27;brand_most_1_cnt&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 最常见的行为动作 行为次数</span><br>all_data_test = user_most_n_cnt(all_data_test, <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;action_type_1_cnt&#x27;</span>, n=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># .....</span><br></code></pre></td></tr></table></figure><h4 id="用户特征统计">(2)用户特征统计</h4><p>对用户的点击、加购、购买、收藏等特征进行统计。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对点击、加购、购买、收藏 分开统计</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">统计基本特征函数  </span><br><span class="hljs-string">-- 知识点二</span><br><span class="hljs-string">-- 根据不同行为的业务函数</span><br><span class="hljs-string">-- 提取不同特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">col_cnt_</span>(<span class="hljs-params">df_data, columns_list, action_type</span>):<br>    <span class="hljs-comment"># 定义一个名为col_cnt_的函数，参数分别为df_data（数据框），columns_list（列名列表），action_type（行为类型）</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-comment"># 定义一个名为data_dict的字典</span><br>        data_dict = &#123;&#125;<br><br>        <span class="hljs-comment"># 将columns_list复制一份，命名为col_list</span><br>        col_list = copy.deepcopy(columns_list)<br>        <span class="hljs-comment"># 如果action_type不为空，将action_type_path添加到col_list中</span><br>        <span class="hljs-keyword">if</span> action_type != <span class="hljs-literal">None</span>:<br>            col_list += [<span class="hljs-string">&#x27;action_type_path&#x27;</span>]<br><br>        <span class="hljs-comment"># 将df_data中的每一列按照空格分割，存入data_dict中</span><br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> col_list:<br>            data_dict[col] = df_data[col].split(<span class="hljs-string">&#x27; &#x27;</span>)<br><br>        <span class="hljs-comment"># 获取data_dict中每一列的长度</span><br>        path_len = <span class="hljs-built_in">len</span>(data_dict[col])<br><br>        <span class="hljs-comment"># 定义一个名为data_out的空列表</span><br>        data_out = []<br>        <span class="hljs-comment"># 遍历data_dict中每一列的长度</span><br>        <span class="hljs-keyword">for</span> i_ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(path_len):<br>            <span class="hljs-comment"># 定义一个名为data_txt的空字符串</span><br>            data_txt = <span class="hljs-string">&#x27;&#x27;</span><br>            <span class="hljs-comment"># 遍历columns_list中的每一列</span><br>            <span class="hljs-keyword">for</span> col_ <span class="hljs-keyword">in</span> columns_list:<br>                <span class="hljs-comment"># 如果action_type_path中当前行的值为action_type，将data_dict中当前列的值添加到data_txt中</span><br>                <span class="hljs-keyword">if</span> data_dict[<span class="hljs-string">&#x27;action_type_path&#x27;</span>][i_] == action_type:<br>                    data_txt += <span class="hljs-string">&#x27;_&#x27;</span> + data_dict[col_][i_]<br>            <span class="hljs-comment"># 将data_txt添加到data_out中</span><br>            data_out.append(data_txt)<br><br>        <span class="hljs-comment"># 返回data_out的长度</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(data_out)  <br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-comment"># 如果发生异常，返回-1</span><br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">col_nuique_</span>(<span class="hljs-params">df_data, columns_list, action_type</span>):<br>    <span class="hljs-keyword">try</span>:<br>        data_dict = &#123;&#125;<br><br>        col_list = copy.deepcopy(columns_list)<br>        <span class="hljs-keyword">if</span> action_type != <span class="hljs-literal">None</span>:<br>            col_list += [<span class="hljs-string">&#x27;action_type_path&#x27;</span>]<br><br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> col_list:<br>            data_dict[col] = df_data[col].split(<span class="hljs-string">&#x27; &#x27;</span>)<br><br>        path_len = <span class="hljs-built_in">len</span>(data_dict[col])<br><br>        data_out = []<br>        <span class="hljs-keyword">for</span> i_ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(path_len):<br>            data_txt = <span class="hljs-string">&#x27;&#x27;</span><br>            <span class="hljs-keyword">for</span> col_ <span class="hljs-keyword">in</span> columns_list:<br>                <span class="hljs-keyword">if</span> data_dict[<span class="hljs-string">&#x27;action_type_path&#x27;</span>][i_] == action_type:<br>                    data_txt += <span class="hljs-string">&#x27;_&#x27;</span> + data_dict[col_][i_]<br>            data_out.append(data_txt)<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(data_out))<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>    <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_col_cnt</span>(<span class="hljs-params">df_data, columns_list, action_type, name</span>):<br>    df_data[name] = df_data.apply(<span class="hljs-keyword">lambda</span> x: col_cnt_(x, columns_list, action_type), axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> df_data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">user_col_nunique</span>(<span class="hljs-params">df_data, columns_list, action_type, name</span>):<br>    df_data[name] = df_data.apply(<span class="hljs-keyword">lambda</span> x: col_nuique_(x, columns_list, action_type), axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> df_data<br></code></pre></td></tr></table></figure><h5 id="代码解释-4">代码解释</h5><p>这段代码用于对用户在购物网站上的点击、加购、购买和收藏行为进行统计。实现原理是使用DataFrame的apply方法对数据进行处理，根据不同的行为类型和业务逻辑对数据进行提取和统计。</p><p>功能：</p><ol type="1"><li><code>col_cnt_</code>函数：统计指定列（columns_list）中每个路径的重复次数。</li><li><code>col_nuique_</code>函数：统计指定列（columns_list）中每个路径去重后的次数。</li><li><code>user_col_cnt</code>函数：将统计结果存储在DataFrame的指定列（name）中。</li><li><code>user_col_nunique</code>函数：将统计结果存储在DataFrame的指定列（name）中。</li></ol><h4 id="统计用户和店铺的关系">(3)统计用户和店铺的关系</h4><p>统计店铺被用户点击次数，加购次数，购买次数，收藏次数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 点击次数</span><br>all_data_test = user_col_cnt(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>], <span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;user_cnt_0&#x27;</span>)<br><span class="hljs-comment"># 加购次数</span><br>all_data_test = user_col_cnt(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>], <span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;user_cnt_1&#x27;</span>)<br><span class="hljs-comment"># 购买次数</span><br>all_data_test = user_col_cnt(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>], <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;user_cnt_2&#x27;</span>)<br><span class="hljs-comment"># 收藏次数</span><br>all_data_test = user_col_cnt(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>], <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;user_cnt_3&#x27;</span>)<br><br><br><span class="hljs-comment"># 不同店铺个数</span><br>all_data_test = user_col_nunique(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>], <span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;seller_nunique_0&#x27;</span>)<br><span class="hljs-comment"># ....</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data_test<br></code></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>user_id</th><th>merchant_id</th><th>label</th><th>age_range</th><th>gender</th><th>item_path</th><th>cat_path</th><th>seller_path</th><th>brand_path</th><th>time_stamp_path</th><th>...</th><th>action_type_1</th><th>seller_most_1_cnt</th><th>cat_most_1_cnt</th><th>brand_most_1_cnt</th><th>action_type_1_cnt</th><th>user_cnt_0</th><th>user_cnt_1</th><th>user_cnt_2</th><th>user_cnt_3</th><th>seller_nunique_0</th></tr></thead><tbody><tr><th>0</th><td>105600</td><td>1487</td><td>0.0</td><td>6.0</td><td>1.0</td><td>986160 681407 681407 910680 681407 592698 3693...</td><td>35 1554 1554 119 1554 662 1095 662 35 833 833 ...</td><td>4811 4811 4811 1897 4811 3315 2925 1340 1875 4...</td><td>127.0 127.0 127.0 4704.0 127.0 1605.0 6000.0 1...</td><td>518 518 518 520 520 524 524 524 525 525 525 52...</td><td>...</td><td>0</td><td>35</td><td>43</td><td>35</td><td>299</td><td>310</td><td>310</td><td>310</td><td>310</td><td>97</td></tr><tr><th>1</th><td>110976</td><td>159</td><td>0.0</td><td>5.0</td><td>0.0</td><td>396970 961553 627712 926681 1012423 825576 149...</td><td>1023 420 407 1505 962 602 184 1606 351 1505 11...</td><td>1435 1648 223 3178 2418 1614 3004 2511 2285 78...</td><td>5504.0 7780.0 1751.0 7540.0 6652.0 8116.0 5328...</td><td>517 520 522 522 527 530 530 530 601 601 602 60...</td><td>...</td><td>0</td><td>9</td><td>56</td><td>11</td><td>259</td><td>274</td><td>274</td><td>274</td><td>274</td><td>181</td></tr><tr><th>2</th><td>374400</td><td>302</td><td>0.0</td><td>5.0</td><td>1.0</td><td>256546 202393 927572 2587 10956 549283 270303 ...</td><td>1188 646 1175 1188 1414 681 1175 681 681 115 1...</td><td>805 390 4252 3979 1228 2029 2029 2029 4252 923...</td><td>1842.0 5920.0 133.0 6304.0 7584.0 133.0 133.0 ...</td><td>517 604 604 604 607 609 609 609 609 615 621 62...</td><td>...</td><td>0</td><td>93</td><td>29</td><td>48</td><td>241</td><td>278</td><td>278</td><td>278</td><td>278</td><td>56</td></tr><tr><th>3</th><td>189312</td><td>1760</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>...</td><td>0</td><td>45</td><td>68</td><td>45</td><td>228</td><td>237</td><td>237</td><td>237</td><td>237</td><td>50</td></tr><tr><th>4</th><td>189312</td><td>2511</td><td>0.0</td><td>4.0</td><td>0.0</td><td>290583 166235 556025 217894 166235 556025 5589...</td><td>601 601 601 601 601 601 601 601 601 601 601 60...</td><td>3139 3139 3524 3139 3139 3524 3139 3139 3139 3...</td><td>549.0 549.0 549.0 549.0 549.0 549.0 549.0 549....</td><td>924 924 924 924 924 924 924 924 924 924 924 92...</td><td>...</td><td>0</td><td>45</td><td>68</td><td>45</td><td>228</td><td>237</td><td>237</td><td>237</td><td>237</td><td>50</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>16859</th><td>120191</td><td>1899</td><td>NaN</td><td>4.0</td><td>0.0</td><td>793882 288225 288225 288225 195714 195714 1957...</td><td>387 35 35 35 1213 1213 1213 1213 1075 447 1213...</td><td>1146 696 696 696 1200 1200 1200 1200 2702 4279...</td><td>8064.0 3600.0 3600.0 3600.0 2276.0 2276.0 2276...</td><td>512 516 516 516 606 606 606 606 606 606 606 60...</td><td>...</td><td>0</td><td>11</td><td>14</td><td>11</td><td>69</td><td>96</td><td>96</td><td>96</td><td>96</td><td>29</td></tr><tr><th>16860</th><td>121727</td><td>4044</td><td>NaN</td><td>4.0</td><td>0.0</td><td>544029 562170 544029 562170 544029 544029 5621...</td><td>1505 662 1505 662 1505 1505 662 1505 1505 1505...</td><td>795 1910 795 1910 795 795 1910 795 795 795 411...</td><td>3608.0 950.0 3608.0 950.0 3608.0 3608.0 950.0 ...</td><td>628 628 628 628 628 628 628 628 628 628 710 71...</td><td>...</td><td>0</td><td>12</td><td>12</td><td>12</td><td>43</td><td>49</td><td>49</td><td>49</td><td>49</td><td>15</td></tr><tr><th>16861</th><td>385919</td><td>3912</td><td>NaN</td><td>0.0</td><td>0.0</td><td>187936 187936 657875 969054 462255 985073 1602...</td><td>602 602 1389 1505 1228 1604 1228 662 1228 662 ...</td><td>661 661 643 643 4738 643 3740 643 4738 643 643...</td><td>1484.0 1484.0 968.0 968.0 6220.0 968.0 4072.0 ...</td><td>512 512 513 513 524 524 524 524 524 524 526 60...</td><td>...</td><td>0</td><td>33</td><td>19</td><td>33</td><td>44</td><td>54</td><td>54</td><td>54</td><td>54</td><td>12</td></tr><tr><th>16862</th><td>215423</td><td>4356</td><td>NaN</td><td>5.0</td><td>0.0</td><td>885364 938282 966141 174392 885364 821661 3473...</td><td>1389 662 1095 1095 1389 662 1577 821 662 1389 ...</td><td>2602 2602 2602 2602 2602 2602 3128 2602 2602 2...</td><td>1900.0 1900.0 1900.0 1900.0 1900.0 1900.0 8392...</td><td>521 521 521 521 521 521 521 521 521 521 521 52...</td><td>...</td><td>0</td><td>63</td><td>58</td><td>63</td><td>118</td><td>152</td><td>152</td><td>152</td><td>152</td><td>25</td></tr><tr><th>16863</th><td>215423</td><td>1840</td><td>NaN</td><td>5.0</td><td>0.0</td><td>885364 938282 966141 174392 885364 821661 3473...</td><td>1389 662 1095 1095 1389 662 1577 821 662 1389 ...</td><td>2602 2602 2602 2602 2602 2602 3128 2602 2602 2...</td><td>1900.0 1900.0 1900.0 1900.0 1900.0 1900.0 8392...</td><td>521 521 521 521 521 521 521 521 521 521 521 52...</td><td>...</td><td>0</td><td>63</td><td>58</td><td>63</td><td>118</td><td>152</td><td>152</td><td>152</td><td>152</td><td>25</td></tr></tbody></table><p>16864 rows × 35 columns</p></div><h3 id="特征组合">6.2 特征组合</h3><h4 id="特征组合进行业务特征提取">（1）特征组合进行业务特征提取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 点击次数</span><br>all_data_test = user_col_cnt(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;item_path&#x27;</span>], <span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;user_cnt_0&#x27;</span>)<br><br><span class="hljs-comment"># 不同店铺个数</span><br>all_data_test = user_col_nunique(all_data_test,  [<span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;item_path&#x27;</span>], <span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;seller_nunique_0&#x27;</span>)<br><span class="hljs-comment"># ....</span><br></code></pre></td></tr></table></figure><h4 id="查看提取的特征">（2）查看提取的特征</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data_test.columns<br></code></pre></td></tr></table></figure><pre><code class="hljs">Index([&#39;user_id&#39;, &#39;merchant_id&#39;, &#39;label&#39;, &#39;age_range&#39;, &#39;gender&#39;, &#39;item_path&#39;,
       &#39;cat_path&#39;, &#39;seller_path&#39;, &#39;brand_path&#39;, &#39;time_stamp_path&#39;,
       &#39;action_type_path&#39;, &#39;user_cnt&#39;, &#39;seller_nunique&#39;, &#39;cat_nunique&#39;,
       &#39;brand_nunique&#39;, &#39;item_nunique&#39;, &#39;time_stamp_nunique&#39;,
       &#39;action_type_nunique&#39;, &#39;time_stamp_max&#39;, &#39;time_stamp_min&#39;,
       &#39;time_stamp_std&#39;, &#39;time_stamp_range&#39;, &#39;seller_most_1&#39;, &#39;cat_most_1&#39;,
       &#39;brand_most_1&#39;, &#39;action_type_1&#39;, &#39;seller_most_1_cnt&#39;, &#39;cat_most_1_cnt&#39;,
       &#39;brand_most_1_cnt&#39;, &#39;action_type_1_cnt&#39;, &#39;user_cnt_0&#39;, &#39;user_cnt_1&#39;,
       &#39;user_cnt_2&#39;, &#39;user_cnt_3&#39;, &#39;seller_nunique_0&#39;],
      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">list</span>(all_data_test.columns)<br></code></pre></td></tr></table></figure><pre><code class="hljs">[&#39;user_id&#39;,
 &#39;merchant_id&#39;,
 &#39;label&#39;,
 &#39;age_range&#39;,
 &#39;gender&#39;,
 &#39;item_path&#39;,
 &#39;cat_path&#39;,
 &#39;seller_path&#39;,
 &#39;brand_path&#39;,
 &#39;time_stamp_path&#39;,
 &#39;action_type_path&#39;,
 &#39;user_cnt&#39;,
 &#39;seller_nunique&#39;,
 &#39;cat_nunique&#39;,
 &#39;brand_nunique&#39;,
 &#39;item_nunique&#39;,
 &#39;time_stamp_nunique&#39;,
 &#39;action_type_nunique&#39;,
 &#39;time_stamp_max&#39;,
 &#39;time_stamp_min&#39;,
 &#39;time_stamp_std&#39;,
 &#39;time_stamp_range&#39;,
 &#39;seller_most_1&#39;,
 &#39;cat_most_1&#39;,
 &#39;brand_most_1&#39;,
 &#39;action_type_1&#39;,
 &#39;seller_most_1_cnt&#39;,
 &#39;cat_most_1_cnt&#39;,
 &#39;brand_most_1_cnt&#39;,
 &#39;action_type_1_cnt&#39;,
 &#39;user_cnt_0&#39;,
 &#39;user_cnt_1&#39;,
 &#39;user_cnt_2&#39;,
 &#39;user_cnt_3&#39;,
 &#39;seller_nunique_0&#39;]</code></pre><h2 id="利用countvectortf-idf提取特征">7 利用Countvector，TF-IDF提取特征</h2><p>(1)利用Countvector和TF-IDF提取特征，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-- 知识点四</span><br><span class="hljs-string">-- 利用countvector，tfidf提取特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> sparse<br><span class="hljs-comment"># cntVec = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)</span><br>tfidfVec = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), max_features=<span class="hljs-number">100</span>)<br><br><br><span class="hljs-comment"># columns_list = [&#x27;seller_path&#x27;, &#x27;cat_path&#x27;, &#x27;brand_path&#x27;, &#x27;action_type_path&#x27;, &#x27;item_path&#x27;, &#x27;time_stamp_path&#x27;]</span><br>columns_list = [<span class="hljs-string">&#x27;seller_path&#x27;</span>]<br><span class="hljs-keyword">for</span> i, col <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(columns_list):<br>    all_data_test[col] = all_data_test[col].astype(<span class="hljs-built_in">str</span>)<br>    tfidfVec.fit(all_data_test[col])<br>    data_ = tfidfVec.transform(all_data_test[col])<br>    <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>        data_cat = data_<br>    <span class="hljs-keyword">else</span>:<br>        data_cat = sparse.hstack((data_cat, data_))<br></code></pre></td></tr></table></figure><h4 id="代码解释-5">代码解释</h4><p>这段代码是针对文本数据的向量化处理。代码主要使用了<code>TfidfVectorizer</code>进行文本特征的提取。以下是对代码逐行的解释：</p><ol type="1"><li><p>首先，导入必要的库和方法。<code>CountVectorizer</code>和<code>TfidfVectorizer</code>用于将文本数据转换为向量形式。<code>ENGLISH_STOP_WORDS</code>提供英文停用词列表，这些词通常在文本处理中被过滤掉，因为它们通常不含有相关信息。<code>sparse</code>来自<code>scipy</code>库，用于处理稀疏矩阵。</p></li><li><p>注释掉了一个创建<code>CountVectorizer</code>的实例的行，这意味着作者可能原本计划使用它，但最后选择了<code>TfidfVectorizer</code>。停用词被设为英语停用词，<code>ngram_range</code>为(1, 1)，表示只考虑单个词语（一元模型），<code>max_features=100</code>表示仅保留词频最高的100个词。</p></li><li><p><code>TfidfVectorizer</code>同样创建了一个实例，配置和<code>CountVectorizer</code>几乎相同，但是<code>TfidfVectorizer</code>计算的是词的TF-IDF值，这是词频（TF）和逆文档频率（IDF）的乘积，能够更好地表示词的重要性。</p></li><li><p><code>columns_list</code>定义了需要进行特征提取的列名称列表，在这段代码中，作者只选择了<code>'seller_path'</code>一列进行特征提取。</p></li><li><p>通过遍历<code>columns_list</code>，对每个列采取如下操作：</p><ul><li>首先将列的数据类型转换为字符串类型。</li><li>使用<code>tfidfVec</code>对象的<code>fit</code>方法来“学习”这一列的词汇和IDF值。</li><li>使用<code>transform</code>方法将这列的文本转换为TF-IDF的稀疏矩阵形式。</li></ul></li><li><p>如果这是第一个列（由<code>i == 0</code>检查），则将转换后得到的稀疏矩阵赋值给<code>data_cat</code>。如果不是第一个列，则使用<code>scipy</code>库中的<code>sparse.hstack</code>方法将新的稀疏矩阵与前面的矩阵横向拼接。</p></li><li><p>结果是<code>data_cat</code>变量现在包含了<code>'seller_path'</code>列经过TF-IDF转换后的特征矩阵。若<code>columns_list</code>中有更多列，则<code>data_cat</code>会依据上述逻辑横向拼接它们的TF-IDF矩阵。</p></li></ol><p>这段代码的目的是生成用于后续机器学习模型训练的特征，这种特征提取方法在文本分类、情感分析等NLP任务中非常常见。</p><p>(2)特征重命名 特征合并</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">df_tfidf = pd.DataFrame(data_cat.toarray())<br>df_tfidf.columns = [<span class="hljs-string">&#x27;tfidf_&#x27;</span> + <span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> df_tfidf.columns]<br>all_data_test = pd.concat([all_data_test, df_tfidf],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h2 id="嵌入embeeding特征">8 嵌入(embeeding)特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gensim<br><br><span class="hljs-comment"># Train Word2Vec model</span><br><br>model = gensim.models.Word2Vec(all_data_test[<span class="hljs-string">&#x27;seller_path&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: x.split(<span class="hljs-string">&#x27; &#x27;</span>)), vector_size=<span class="hljs-number">100</span>, window=<span class="hljs-number">5</span>, min_count=<span class="hljs-number">5</span>, workers=<span class="hljs-number">4</span>)<br><span class="hljs-comment"># model.save(&quot;product2vec.model&quot;)</span><br><span class="hljs-comment"># model = gensim.models.Word2Vec.load(&quot;product2vec.model&quot;)</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mean_w2v_</span>(<span class="hljs-params">x, model, vector_size=<span class="hljs-number">100</span></span>):<br>    <span class="hljs-keyword">try</span>:<br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>):<br>            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> model.wv.vocab:<br>                i += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>                    vec = np.zeros(vector_size)<br>                vec += model.wv[word]<br>        <span class="hljs-keyword">return</span> vec / i <br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span>  np.zeros(vector_size)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_mean_w2v</span>(<span class="hljs-params">df_data, columns, model, vector_size</span>):<br>    data_array = []<br>    <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> df_data.iterrows():<br>        w2v = mean_w2v_(row[columns], model, vector_size)<br>        data_array.append(w2v)<br>    <span class="hljs-keyword">return</span> pd.DataFrame(data_array)<br><br>df_embeeding = get_mean_w2v(all_data_test, <span class="hljs-string">&#x27;seller_path&#x27;</span>, model, <span class="hljs-number">100</span>)<br>df_embeeding.columns = [<span class="hljs-string">&#x27;embeeding_&#x27;</span> + <span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> df_embeeding.columns]<br></code></pre></td></tr></table></figure><p><strong>embeeding特征和原始特征合并</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">all_data_test = pd.concat([all_data_test, df_embeeding],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h2 id="stacking特征">9 stacking特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-- 知识点六</span><br><span class="hljs-string">-- stacking特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-comment"># from sklearn.cross_validation import KFold</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> sparse<br><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> lightgbm<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression,LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> LinearSVC,SVC<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> log_loss,mean_absolute_error,mean_squared_error<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> MultinomialNB,GaussianNB<br></code></pre></td></tr></table></figure><h3 id="stacking-回归特征">(1) stacking 回归特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-- 回归</span><br><span class="hljs-string">-- stacking 回归特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">stacking_reg</span>(<span class="hljs-params">clf,train_x,train_y,test_x,clf_name,kf,label_split=<span class="hljs-literal">None</span></span>):<br>    train=np.zeros((train_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test=np.zeros((test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test_pre=np.empty((folds,test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    cv_scores=[]<br>    <span class="hljs-keyword">for</span> i,(train_index,test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(train_x,label_split)):       <br>        tr_x=train_x[train_index]<br>        tr_y=train_y[train_index]<br>        te_x=train_x[test_index]<br>        te_y = train_y[test_index]<br>        <span class="hljs-keyword">if</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;rf&quot;</span>,<span class="hljs-string">&quot;ada&quot;</span>,<span class="hljs-string">&quot;gb&quot;</span>,<span class="hljs-string">&quot;et&quot;</span>,<span class="hljs-string">&quot;lr&quot;</span>]:<br>            clf.fit(tr_x,tr_y)<br>            pre=clf.predict(te_x).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>            train[test_index]=pre<br>            test_pre[i,:]=clf.predict(test_x).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>            cv_scores.append(mean_squared_error(te_y, pre))<br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;xgb&quot;</span>]:<br>            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-<span class="hljs-number">1</span>)<br>            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-<span class="hljs-number">1</span>)<br>            z = clf.DMatrix(test_x, label=te_y, missing=-<span class="hljs-number">1</span>)<br>            params = &#123;<span class="hljs-string">&#x27;booster&#x27;</span>: <span class="hljs-string">&#x27;gbtree&#x27;</span>,<br>                      <span class="hljs-string">&#x27;eval_metric&#x27;</span>: <span class="hljs-string">&#x27;rmse&#x27;</span>,<br>                      <span class="hljs-string">&#x27;gamma&#x27;</span>: <span class="hljs-number">1</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;max_depth&#x27;</span>: <span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;eta&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span><br>                      &#125;<br>            num_round = <span class="hljs-number">10000</span><br>            early_stopping_rounds = <span class="hljs-number">100</span><br>            watchlist = [(train_matrix, <span class="hljs-string">&#x27;train&#x27;</span>),<br>                         (test_matrix, <span class="hljs-string">&#x27;eval&#x27;</span>)<br>                         ]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,<br>                                  early_stopping_rounds=early_stopping_rounds<br>                                  )<br>                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                train[test_index]=pre<br>                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(mean_squared_error(te_y, pre))<br><br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lgb&quot;</span>]:<br>            train_matrix = clf.Dataset(tr_x, label=tr_y)<br>            test_matrix = clf.Dataset(te_x, label=te_y)<br>            params = &#123;<br>                      <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>                      <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;regression_l2&#x27;</span>,<br>                      <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;mse&#x27;</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">2</span>**<span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda_l2&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&#x27;nthread&#x27;</span>: <span class="hljs-number">12</span>,<br>                      <span class="hljs-string">&#x27;silent&#x27;</span>: <span class="hljs-literal">True</span>,<br>                      &#125;<br>            num_round = <span class="hljs-number">10000</span><br>            <span class="hljs-comment">#early_stopping_rounds = 100</span><br>            <span class="hljs-comment">#callbacks=[lightgbm.log_evaluation(period=100), lightgbm.early_stopping(stopping_rounds=100)]</span><br>            callbacks=[lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,<br>                                  <span class="hljs-comment">#early_stopping_rounds=early_stopping_rounds</span><br>                                  callbacks=callbacks<br>                                  )<br>                pre= model.predict(te_x,num_iteration=model.best_iteration).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                train[test_index]=pre<br>                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(mean_squared_error(te_y, pre))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> IOError(<span class="hljs-string">&quot;Please add new clf.&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s now score is:&quot;</span>%clf_name,cv_scores)<br>    test[:]=test_pre.mean(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_list:&quot;</span>%clf_name,cv_scores)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_mean:&quot;</span>%clf_name,np.mean(cv_scores))<br>    <span class="hljs-keyword">return</span> train.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),test.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rf_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    randomforest = RandomForestRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">20</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>,verbose=<span class="hljs-number">1</span>)<br>    rf_train, rf_test = stacking_reg(randomforest, x_train, y_train, x_valid, <span class="hljs-string">&quot;rf&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> rf_train, rf_test,<span class="hljs-string">&quot;rf_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ada_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    adaboost = AdaBoostRegressor(n_estimators=<span class="hljs-number">30</span>, random_state=<span class="hljs-number">2017</span>, learning_rate=<span class="hljs-number">0.01</span>)<br>    ada_train, ada_test = stacking_reg(adaboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;ada&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> ada_train, ada_test,<span class="hljs-string">&quot;ada_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    gbdt = GradientBoostingRegressor(learning_rate=<span class="hljs-number">0.04</span>, n_estimators=<span class="hljs-number">100</span>, subsample=<span class="hljs-number">0.8</span>, random_state=<span class="hljs-number">2017</span>,max_depth=<span class="hljs-number">5</span>,verbose=<span class="hljs-number">1</span>)<br>    gbdt_train, gbdt_test = stacking_reg(gbdt, x_train, y_train, x_valid, <span class="hljs-string">&quot;gb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> gbdt_train, gbdt_test,<span class="hljs-string">&quot;gb_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">et_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    extratree = ExtraTreesRegressor(n_estimators=<span class="hljs-number">600</span>, max_depth=<span class="hljs-number">35</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>,verbose=<span class="hljs-number">1</span>)<br>    et_train, et_test = stacking_reg(extratree, x_train, y_train, x_valid, <span class="hljs-string">&quot;et&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> et_train, et_test,<span class="hljs-string">&quot;et_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    lr_reg=LinearRegression(n_jobs=-<span class="hljs-number">1</span>)<br>    lr_train, lr_test = stacking_reg(lr_reg, x_train, y_train, x_valid, <span class="hljs-string">&quot;lr&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> lr_train, lr_test, <span class="hljs-string">&quot;lr_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xgb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    xgb_train, xgb_test = stacking_reg(xgboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;xgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> xgb_train, xgb_test,<span class="hljs-string">&quot;xgb_reg&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lgb_reg</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    lgb_train, lgb_test = stacking_reg(lightgbm, x_train, y_train, x_valid, <span class="hljs-string">&quot;lgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> lgb_train, lgb_test,<span class="hljs-string">&quot;lgb_reg&quot;</span><br></code></pre></td></tr></table></figure><h3 id="stacking-分类特征">(2) stacking 分类特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-- 分类</span><br><span class="hljs-string">-- stacking 分类特征</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">stacking_clf</span>(<span class="hljs-params">clf,train_x,train_y,test_x,clf_name,kf,label_split=<span class="hljs-literal">None</span></span>):<br>    train=np.zeros((train_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test=np.zeros((test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    test_pre=np.empty((folds,test_x.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>))<br>    cv_scores=[]<br>    <span class="hljs-keyword">for</span> i,(train_index,test_index) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(train_x,label_split)):       <br>        tr_x=train_x[train_index]<br>        tr_y=train_y[train_index]<br>        te_x=train_x[test_index]<br>        te_y = train_y[test_index]<br><br>        <span class="hljs-keyword">if</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;rf&quot;</span>,<span class="hljs-string">&quot;ada&quot;</span>,<span class="hljs-string">&quot;gb&quot;</span>,<span class="hljs-string">&quot;et&quot;</span>,<span class="hljs-string">&quot;lr&quot;</span>,<span class="hljs-string">&quot;knn&quot;</span>,<span class="hljs-string">&quot;gnb&quot;</span>]:<br>            clf.fit(tr_x,tr_y)<br>            pre=clf.predict_proba(te_x)<br>            <br>            train[test_index]=pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>            test_pre[i,:]=clf.predict_proba(test_x)[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>            <br>            cv_scores.append(log_loss(te_y, pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;xgb&quot;</span>]:<br>            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-<span class="hljs-number">1</span>)<br>            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-<span class="hljs-number">1</span>)<br>            z = clf.DMatrix(test_x)<br>            params = &#123;<span class="hljs-string">&#x27;booster&#x27;</span>: <span class="hljs-string">&#x27;gbtree&#x27;</span>,<br>                      <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;multi:softprob&#x27;</span>,<br>                      <span class="hljs-string">&#x27;eval_metric&#x27;</span>: <span class="hljs-string">&#x27;mlogloss&#x27;</span>,<br>                      <span class="hljs-string">&#x27;gamma&#x27;</span>: <span class="hljs-number">1</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;max_depth&#x27;</span>: <span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;eta&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&quot;num_class&quot;</span>: <span class="hljs-number">2</span><br>                      &#125;<br><br>            num_round = <span class="hljs-number">10000</span><br>            early_stopping_rounds = <span class="hljs-number">100</span><br>            watchlist = [(train_matrix, <span class="hljs-string">&#x27;train&#x27;</span>),<br>                         (test_matrix, <span class="hljs-string">&#x27;eval&#x27;</span>)<br>                         ]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,<br>                                  early_stopping_rounds=early_stopping_rounds<br>                                  )<br>                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit)<br>                train[test_index]=pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit)[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(log_loss(te_y, pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br>        <span class="hljs-keyword">elif</span> clf_name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;lgb&quot;</span>]:<br>            train_matrix = clf.Dataset(tr_x, label=tr_y)<br>            test_matrix = clf.Dataset(te_x, label=te_y)<br>            params = &#123;<br>                      <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,<br>                      <span class="hljs-comment">#&#x27;boosting_type&#x27;: &#x27;dart&#x27;,</span><br>                      <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;multiclass&#x27;</span>,<br>                      <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;multi_logloss&#x27;</span>,<br>                      <span class="hljs-string">&#x27;min_child_weight&#x27;</span>: <span class="hljs-number">1.5</span>,<br>                      <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">2</span>**<span class="hljs-number">5</span>,<br>                      <span class="hljs-string">&#x27;lambda_l2&#x27;</span>: <span class="hljs-number">10</span>,<br>                      <span class="hljs-string">&#x27;subsample&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;colsample_bylevel&#x27;</span>: <span class="hljs-number">0.7</span>,<br>                      <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.03</span>,<br>                      <span class="hljs-string">&#x27;tree_method&#x27;</span>: <span class="hljs-string">&#x27;exact&#x27;</span>,<br>                      <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">2017</span>,<br>                      <span class="hljs-string">&quot;num_class&quot;</span>: <span class="hljs-number">2</span>,<br>                      <span class="hljs-string">&#x27;silent&#x27;</span>: <span class="hljs-literal">True</span>,<br>                      &#125;<br>            num_round = <span class="hljs-number">10000</span><br>            <span class="hljs-comment">#early_stopping_rounds = 100</span><br>            <span class="hljs-comment">#callbacks=[lightgbm.log_evaluation(period=100), lightgbm.early_stopping(stopping_rounds=100)]</span><br>            callbacks=[lightgbm.early_stopping(stopping_rounds=<span class="hljs-number">100</span>)]<br>            <span class="hljs-keyword">if</span> test_matrix:<br>                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,<br>                                  <span class="hljs-comment">#early_stopping_rounds=early_stopping_rounds</span><br>                                  callbacks=callbacks<br>                                  )<br>                pre= model.predict(te_x,num_iteration=model.best_iteration)<br>                train[test_index]=pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration)[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>                cv_scores.append(log_loss(te_y, pre[:,<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> IOError(<span class="hljs-string">&quot;Please add new clf.&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s now score is:&quot;</span>%clf_name,cv_scores)<br>    test[:]=test_pre.mean(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_list:&quot;</span>%clf_name,cv_scores)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s_score_mean:&quot;</span>%clf_name,np.mean(cv_scores))<br>    <span class="hljs-keyword">return</span> train.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),test.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rf_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    randomforest = RandomForestClassifier(n_estimators=<span class="hljs-number">1200</span>, max_depth=<span class="hljs-number">20</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>,verbose=<span class="hljs-number">1</span>)<br>    rf_train, rf_test = stacking_clf(randomforest, x_train, y_train, x_valid, <span class="hljs-string">&quot;rf&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> rf_train, rf_test,<span class="hljs-string">&quot;rf&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ada_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    adaboost = AdaBoostClassifier(n_estimators=<span class="hljs-number">50</span>, random_state=<span class="hljs-number">2017</span>, learning_rate=<span class="hljs-number">0.01</span>)<br>    ada_train, ada_test = stacking_clf(adaboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;ada&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> ada_train, ada_test,<span class="hljs-string">&quot;ada&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gb_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    gbdt = GradientBoostingClassifier(learning_rate=<span class="hljs-number">0.04</span>, n_estimators=<span class="hljs-number">100</span>, subsample=<span class="hljs-number">0.8</span>, random_state=<span class="hljs-number">2017</span>,max_depth=<span class="hljs-number">5</span>,verbose=<span class="hljs-number">1</span>)<br>    gbdt_train, gbdt_test = stacking_clf(gbdt, x_train, y_train, x_valid, <span class="hljs-string">&quot;gb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> gbdt_train, gbdt_test,<span class="hljs-string">&quot;gb&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">et_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    extratree = ExtraTreesClassifier(n_estimators=<span class="hljs-number">1200</span>, max_depth=<span class="hljs-number">35</span>, max_features=<span class="hljs-string">&quot;auto&quot;</span>, n_jobs=-<span class="hljs-number">1</span>, random_state=<span class="hljs-number">2017</span>,verbose=<span class="hljs-number">1</span>)<br>    et_train, et_test = stacking_clf(extratree, x_train, y_train, x_valid, <span class="hljs-string">&quot;et&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> et_train, et_test,<span class="hljs-string">&quot;et&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xgb_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    xgb_train, xgb_test = stacking_clf(xgboost, x_train, y_train, x_valid, <span class="hljs-string">&quot;xgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> xgb_train, xgb_test,<span class="hljs-string">&quot;xgb&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lgb_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    xgb_train, xgb_test = stacking_clf(lightgbm, x_train, y_train, x_valid, <span class="hljs-string">&quot;lgb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> xgb_train, xgb_test,<span class="hljs-string">&quot;lgb&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gnb_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    gnb=GaussianNB()<br>    gnb_train, gnb_test = stacking_clf(gnb, x_train, y_train, x_valid, <span class="hljs-string">&quot;gnb&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> gnb_train, gnb_test,<span class="hljs-string">&quot;gnb&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    logisticregression=LogisticRegression(n_jobs=-<span class="hljs-number">1</span>,random_state=<span class="hljs-number">2017</span>,C=<span class="hljs-number">0.1</span>,max_iter=<span class="hljs-number">200</span>)<br>    lr_train, lr_test = stacking_clf(logisticregression, x_train, y_train, x_valid, <span class="hljs-string">&quot;lr&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> lr_train, lr_test, <span class="hljs-string">&quot;lr&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">knn_clf</span>(<span class="hljs-params">x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span></span>):<br>    kneighbors=KNeighborsClassifier(n_neighbors=<span class="hljs-number">200</span>,n_jobs=-<span class="hljs-number">1</span>)<br>    knn_train, knn_test = stacking_clf(kneighbors, x_train, y_train, x_valid, <span class="hljs-string">&quot;lr&quot;</span>, kf, label_split=label_split)<br>    <span class="hljs-keyword">return</span> knn_train, knn_test, <span class="hljs-string">&quot;knn&quot;</span><br></code></pre></td></tr></table></figure><h3 id="获取训练和验证数据">(3) 获取训练和验证数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">features_columns = [c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> all_data_test.columns <span class="hljs-keyword">if</span> c <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;prob&#x27;</span>, <span class="hljs-string">&#x27;seller_path&#x27;</span>, <span class="hljs-string">&#x27;cat_path&#x27;</span>, <span class="hljs-string">&#x27;brand_path&#x27;</span>, <span class="hljs-string">&#x27;action_type_path&#x27;</span>, <span class="hljs-string">&#x27;item_path&#x27;</span>, <span class="hljs-string">&#x27;time_stamp_path&#x27;</span>]]<br>x_train = all_data_test[~all_data_test[<span class="hljs-string">&#x27;label&#x27;</span>].isna()][features_columns].values<br>y_train = all_data_test[~all_data_test[<span class="hljs-string">&#x27;label&#x27;</span>].isna()][<span class="hljs-string">&#x27;label&#x27;</span>].values<br>x_valid = all_data_test[all_data_test[<span class="hljs-string">&#x27;label&#x27;</span>].isna()][features_columns].values<br></code></pre></td></tr></table></figure><p>处理函数值inf以及nan，为特征工程做准备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_matrix</span>(<span class="hljs-params">data</span>):<br>    where_are_nan = np.isnan(data)<br>    where_are_inf = np.isinf(data)<br>    data[where_are_nan] = <span class="hljs-number">0</span><br>    data[where_are_inf] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> data<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x_train = np.float_(get_matrix(np.float_(x_train)))<br>y_train = np.int_(y_train)<br>x_valid = x_train<br></code></pre></td></tr></table></figure><h3 id="使用lgb和xgb分类模型构造stacking特征">(4) 使用lgb和xgb分类模型构造stacking特征</h3><p>1）使用5折交叉验证</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold, KFold<br>folds = <span class="hljs-number">5</span><br>seed = <span class="hljs-number">1</span><br>kf = KFold(n_splits=<span class="hljs-number">5</span>, shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>2）选择1gb和xgb分类模型作为基模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># clf_list = [lgb_clf, xgb_clf, lgb_reg, xgb_reg]</span><br><span class="hljs-comment"># clf_list_col = [&#x27;lgb_clf&#x27;, &#x27;xgb_clf&#x27;, &#x27;lgb_reg&#x27;, &#x27;xgb_reg&#x27;]</span><br><br>clf_list = [lgb_clf, xgb_clf]<br>clf_list_col = [<span class="hljs-string">&#x27;lgb_clf&#x27;</span>, <span class="hljs-string">&#x27;xgb_clf&#x27;</span>]<br></code></pre></td></tr></table></figure><p>3）训练模型，获取stacking特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">clf_list = clf_list<br>column_list = []<br>train_data_list=[]<br>test_data_list=[]<br><span class="hljs-keyword">for</span> clf <span class="hljs-keyword">in</span> clf_list:<br>    train_data,test_data,clf_name=clf(x_train, y_train, x_valid, kf, label_split=<span class="hljs-literal">None</span>)<br>    train_data_list.append(train_data)<br>    test_data_list.append(test_data)<br>train_stacking = np.concatenate(train_data_list, axis=<span class="hljs-number">1</span>)<br>test_stacking = np.concatenate(test_data_list, axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">xgb now score is: [2.627641465068789, 2.5421163955938, 2.4962673833575, 2.393391320956645, 2.488317792597411]
xgb_score_list: [2.627641465068789, 2.5421163955938, 2.4962673833575, 2.393391320956645, 2.488317792597411]
xgb_score_mean: 2.5095468715148295</code></pre><h3 id="原始特征和stacking特征合并">（5）原始特征和stacking特征合并</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 合并所有特征</span><br>train = pd.DataFrame(np.concatenate([x_train, train_stacking], axis=<span class="hljs-number">1</span>))<br>test = np.concatenate([x_valid, test_stacking], axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 特征重命名</span><br>df_train_all = pd.DataFrame(train)<br>df_train_all.columns = features_columns + clf_list_col<br>df_test_all = pd.DataFrame(test)<br>df_test_all.columns = features_columns + clf_list_col<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获取数据ID以及特征标签label</span><br>df_train_all[<span class="hljs-string">&#x27;label&#x27;</span>] = all_data_test[<span class="hljs-string">&#x27;label&#x27;</span>]<br></code></pre></td></tr></table></figure><h2 id="保存特征数据">10 保存特征数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train_all.to_csv(<span class="hljs-string">&#x27;./data/train_all.csv&#x27;</span>,header=<span class="hljs-literal">True</span>,index=<span class="hljs-literal">False</span>)<br>df_test_all.to_csv(<span class="hljs-string">&#x27;./data/test_all.csv&#x27;</span>,header=<span class="hljs-literal">True</span>,index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/" class="category-chain-item">机器学习实战入门</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>天猫重复购买预测-03特征工程</div><div>http://zhou1317fe5.link/2024/02/15/天猫重复购买预测-03特征工程/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhou1317fe5</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年2月15日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2024/02/12/Jupyter-Notebook-%E6%97%A0%E6%B3%95%E8%B7%B3%E8%BD%AC%E7%BD%91%E9%A1%B5%E7%9A%84%E9%97%AE%E9%A2%98/" title="Jupyter Notebook 无法跳转网页的问题"><span class="hidden-mobile">Jupyter Notebook 无法跳转网页的问题</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>